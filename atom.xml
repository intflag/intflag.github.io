<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>云端笑猿</title>
  
  <subtitle>现实中的那些纷纷扰扰，都无非是过眼云烟；你在人生的战场上追名逐利，不得解脱；我在我的代码世界中，宁静致远，深藏功与名。</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-12-26T09:34:36.500Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>云端笑猿</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Docker系列003-在Docker中安装Centos镜像</title>
    <link href="http://yoursite.com/Docker%E7%B3%BB%E5%88%97003-%E5%9C%A8Docker%E4%B8%AD%E5%AE%89%E8%A3%85Centos%E9%95%9C%E5%83%8F.html"/>
    <id>http://yoursite.com/Docker系列003-在Docker中安装Centos镜像.html</id>
    <published>2019-12-26T08:22:05.739Z</published>
    <updated>2019-12-26T09:34:36.500Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本人微信公众号，欢迎扫码关注！</p></blockquote><p><img src="http://images.intflag.com/bigdata002.jpg" alt=""></p><h3 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h3><ul><li>centos 7</li><li>已安装Docker</li></ul><h3 id="Centos镜像下载安装"><a href="#Centos镜像下载安装" class="headerlink" title="Centos镜像下载安装"></a>Centos镜像下载安装</h3><p>步骤<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 从镜像仓库拉取centos镜像</span><br><span class="line">docker pull docker.io/centos</span><br><span class="line"></span><br><span class="line"># 查看本地镜像</span><br><span class="line">docker image ls</span><br></pre></td></tr></table></figure></p><p><img src="http://images.intflag.com/collection02-001.jpg" alt=""></p><h3 id="运行一个centos容器"><a href="#运行一个centos容器" class="headerlink" title="运行一个centos容器"></a>运行一个centos容器</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -it --name centosTest --privileged=true -v /opt/software/:/opt/software/ -p 9908:8080 docker.io/centos /sbin/init</span><br></pre></td></tr></table></figure><p>命令解释</p><ul><li><code>-it</code>：控制台交互，支持终端登录</li><li><code>--name centosTest</code>：对容器命名</li><li><code>--privileged=true</code>：大约在0.6版，privileged被引入docker，使用该参数，container内的root拥有真正的root权限。否则，container内的root只是外部的一个普通用户权限，privileged启动的容器，可以看到很多host上的设备，并且可以执行mount。甚至允许你在docker容器中启动docker容器。</li><li><code>-v /opt/software/:/opt/software/</code>：给容器挂载存储卷，挂载到容器的某个目录，将本地的/opt/software/目录挂载到容器中centos的/opt/software/目录下。</li><li><code>-p 9908:8080</code>：容器端口映射，将容器中的8080端口映射到本地9908端口，注意：使用<code>-p</code>参数进行的端口映射，会自动在iptables中建立规则，绕过firewalld，有些情况下这对于端口级的黑白名单控制管理是很不利的，所以我们需要对iptables进行手动修改，详见<a href="https://www.cnblogs.com/qjfoidnh/p/11567309.html" target="_blank" rel="noopener">https://www.cnblogs.com/qjfoidnh/p/11567309.html</a></li><li><code>docker.io/centos</code>：使用哪个镜像</li><li><code>/sbin/init</code>：初始化</li></ul><p>查看是否启动成功<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker ps</span><br></pre></td></tr></table></figure></p><p><img src="http://images.intflag.com/docker03-001.jpeg" alt=""></p><h3 id="进入某个容器中"><a href="#进入某个容器中" class="headerlink" title="进入某个容器中"></a>进入某个容器中</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker exec -it centosTest /bin/bash</span><br></pre></td></tr></table></figure><p>命令执行成功后，命令行会变成如：<code>[root@3583b13c3b3e /]#</code>模式，说明已经成功进入我们启动的容器中了。<br><img src="http://images.intflag.com/docker03-002.jpeg" alt=""></p><h3 id="常用命令执行报错问题"><a href="#常用命令执行报错问题" class="headerlink" title="常用命令执行报错问题"></a>常用命令执行报错问题</h3><ul><li>执行<code>ifconfig</code>命令报错：执行后出现<code>bash: ifconfig: command not found</code>错误提示。<br>使用docker pull centos命令下载下来的centos镜像是centos7的最小安装包，里面并没有携带ifconfig命令，所以我们要知道<code>ifconfig</code>命令在哪个工具包下，然后我们安装该工具包，该命令自然就可以使用了。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 查看命令详细信息</span><br><span class="line">yum provides ifconfig</span><br></pre></td></tr></table></figure></li></ul><p><img src="http://images.intflag.com/docker03-003.jpeg" alt=""></p><p>由上图我们得知，<code>ifconfig</code>命令在<code>net-tools</code>这个工具包下，然后我们使用<code>yum install net-tools</code>命令安卓即可，效果如下图。<br><img src="http://images.intflag.com/docker03-004.jpeg" alt=""></p><ul><li>执行<code>ll</code>命令报错：执行后会出现<code>bash: ll: command not found</code>错误提示。<br>首先我们应该知道，<code>ll</code>是<code>ls -l</code>的简写方式，而错误提示说该命令没找到，其实是因为<code>bashrc</code>文件中没有该命令的配置，所以我们配置上就好了。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 对.bashrc配置文件进行编辑</span><br><span class="line">vi ~/.bashrc</span><br><span class="line"></span><br><span class="line"># 插入我们要的命令脚本</span><br><span class="line">alias ll=&apos;ls -lrt&apos;</span><br><span class="line"></span><br><span class="line"># 保存退出，然后千万别忘了刷新配置，不然没反应</span><br><span class="line">source ~/.bashrc</span><br></pre></td></tr></table></figure></li></ul><p><img src="http://images.intflag.com/docker03-005.jpeg" alt=""></p><p>其他命令失效的错误，解决思路大多与上面这两种类似，因为使用<code>docker pull centos</code>命令下载下来的centos镜像是centos7的最小安装包，所以部分配置或命令是没有的。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;本人微信公众号，欢迎扫码关注！&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;http://images.intflag.com/bigdata002.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;环境准备&quot;&gt;&lt;a href=&quot;
      
    
    </summary>
    
      <category term="Docker" scheme="http://yoursite.com/categories/Docker/"/>
    
    
      <category term="Docker" scheme="http://yoursite.com/tags/Docker/"/>
    
      <category term="Centos" scheme="http://yoursite.com/tags/Centos/"/>
    
  </entry>
  
  <entry>
    <title>Docker系列002-Docker入门</title>
    <link href="http://yoursite.com/Docker%E7%B3%BB%E5%88%97002-Docker%E5%85%A5%E9%97%A8.html"/>
    <id>http://yoursite.com/Docker系列002-Docker入门.html</id>
    <published>2019-12-26T08:10:20.702Z</published>
    <updated>2019-12-26T09:34:31.369Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本人微信公众号，欢迎扫码关注！</p></blockquote><p><img src="http://images.intflag.com/bigdata002.jpg" alt=""></p><h3 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h3><ul><li>centos 7</li></ul><h3 id="Docker下载安装"><a href="#Docker下载安装" class="headerlink" title="Docker下载安装"></a>Docker下载安装</h3><p>步骤：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">1、检查内核版本，必须是3.10及以上</span><br><span class="line">uname -r</span><br><span class="line">2、安装docker</span><br><span class="line">yum install docker</span><br><span class="line">3、输入y确认安装</span><br><span class="line">4、启动docker</span><br><span class="line">[root@localhost ~]# systemctl start docker</span><br><span class="line">[root@localhost ~]# docker -v</span><br><span class="line">Docker version 1.12.6, build 3e8e77d/1.12.6</span><br><span class="line">5、开机启动docker</span><br><span class="line">[root@localhost ~]# systemctl enable docker</span><br><span class="line">Created symlink from /etc/systemd/system/multi-user.target.wants/docker.service to /usr/lib/systemd/system/docker.service.</span><br><span class="line">6、停止docker</span><br><span class="line">systemctl stop docker</span><br></pre></td></tr></table></figure><h3 id="Docker常用命令及操作"><a href="#Docker常用命令及操作" class="headerlink" title="Docker常用命令及操作"></a>Docker常用命令及操作</h3><h4 id="镜像操作"><a href="#镜像操作" class="headerlink" title="镜像操作"></a>镜像操作</h4><table><thead><tr><th>操作</th><th>命令</th><th>说明</th></tr></thead><tbody><tr><td>检索</td><td>docker  search 关键字  eg：docker  search redis</td><td>我们经常去docker  hub上检索镜像的详细信息，如镜像的TAG。</td></tr><tr><td>拉取</td><td>docker pull 镜像名:tag</td><td>:tag是可选的，tag表示标签，多为软件的版本，默认是latest</td></tr><tr><td>列表</td><td>docker images</td><td>查看所有本地镜像</td></tr><tr><td>删除</td><td>docker rmi image-id</td><td>删除指定的本地镜像</td></tr></tbody></table><p>官方镜像市场：<a href="https://hub.docker.com/" target="_blank" rel="noopener">https://hub.docker.com/</a></p><h4 id="容器操作"><a href="#容器操作" class="headerlink" title="容器操作"></a>容器操作</h4><p>软件镜像（QQ安装程序）—-运行镜像—-产生一个容器（正在运行的软件，运行的QQ）；</p><p>步骤：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">1、搜索镜像</span><br><span class="line">[root@localhost ~]# docker search tomcat</span><br><span class="line">2、拉取镜像</span><br><span class="line">[root@localhost ~]# docker pull tomcat</span><br><span class="line">3、根据镜像启动容器</span><br><span class="line">docker run --name mytomcat -d tomcat:latest</span><br><span class="line">4、docker ps  </span><br><span class="line">查看运行中的容器</span><br><span class="line">5、 停止运行中的容器</span><br><span class="line">docker stop  容器的id</span><br><span class="line">6、查看所有的容器</span><br><span class="line">docker ps -a</span><br><span class="line">7、启动容器</span><br><span class="line">docker start 容器id</span><br><span class="line">8、删除一个容器</span><br><span class="line"> docker rm 容器id</span><br><span class="line">9、启动一个做了端口映射的tomcat</span><br><span class="line">[root@localhost ~]# docker run -d -p 8888:8080 tomcat</span><br><span class="line">-d：后台运行</span><br><span class="line">-p: 将主机的端口映射到容器的一个端口    主机端口:容器内部的端口</span><br><span class="line"></span><br><span class="line">10、为了演示简单关闭了linux的防火墙</span><br><span class="line">service firewalld status ；查看防火墙状态</span><br><span class="line">service firewalld stop：关闭防火墙</span><br><span class="line">11、查看容器的日志</span><br><span class="line">docker logs container-name/container-id</span><br><span class="line"></span><br><span class="line">更多命令参看</span><br><span class="line">https://docs.docker.com/engine/reference/commandline/docker/</span><br><span class="line">可以参考每一个镜像的文档</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;本人微信公众号，欢迎扫码关注！&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;http://images.intflag.com/bigdata002.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;环境准备&quot;&gt;&lt;a href=&quot;
      
    
    </summary>
    
      <category term="Docker" scheme="http://yoursite.com/categories/Docker/"/>
    
    
      <category term="Docker" scheme="http://yoursite.com/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>Docker系列001-Docker概述</title>
    <link href="http://yoursite.com/Docker%E7%B3%BB%E5%88%97001-Docker%E6%A6%82%E8%BF%B0.html"/>
    <id>http://yoursite.com/Docker系列001-Docker概述.html</id>
    <published>2019-12-26T07:15:45.618Z</published>
    <updated>2019-12-26T09:34:25.652Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本人微信公众号，欢迎扫码关注！</p></blockquote><p><img src="http://images.intflag.com/bigdata002.jpg" alt=""></p><h3 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h3><p>Docker是一个开源的容器引擎，在搞清楚它是什么之前，必须先了解什么是<strong>容器</strong>。</p><h3 id="什么是容器"><a href="#什么是容器" class="headerlink" title="什么是容器"></a>什么是容器</h3><p>先看一下官方介绍：</p><blockquote><p>容器就是将软件打包成标准化单元，以用于开发、交付和部署。</p></blockquote><ul><li>容器镜像是轻量的、可执行的独立软件包 ，包含软件运行所需的所有内容：代码、运行时环境、系统工具、系统库和设置。</li><li>容器化软件适用于基于Linux和Windows的应用，在任何环境中都能够始终如一地运行。</li><li>容器赋予了软件独立性，使其免受外在环境差异（例如，开发和预演环境的差异）的影响，从而有助于减少团队间在相同基础设施上运行不同软件时的冲突。</li></ul><p><img src="http://images.intflag.com/docker01-001.png" alt=""></p><h3 id="什么是Docker"><a href="#什么是Docker" class="headerlink" title="什么是Docker"></a>什么是Docker</h3><ul><li>Docker是世界领先的软件容器平台。</li><li>Docker使用Google公司推出的Go语言进行开发实现，基于Linux内核的cgroup，namespace，以及AUFS类的UnionFS等技术，对进程进行封装隔离，属于操作系统层面的虚拟化技术。 由于隔离的进程独立于宿主和其它的隔离的进程，因此也称其为容器。Docke最初实现是基于LXC。</li><li>Docker能够自动执行重复性任务，例如搭建和配置开发环境，从而解放了开发人员以便他们专注在真正重要的事情上：构建杰出的软件。</li><li>用户可以方便地创建和使用容器，把自己的应用放入容器。容器还可以进行版本管理、复制、分享、修改，就像管理普通的代码一样。</li></ul><p><img src="http://images.intflag.com/docker01-002.jpeg" alt=""></p><h3 id="Docker思想"><a href="#Docker思想" class="headerlink" title="Docker思想"></a>Docker思想</h3><ul><li>集装箱</li><li>标准化： ①运输方式、②存储方式、 ③API接口</li><li>隔离</li></ul><h1 id="Docker容器的特点"><a href="#Docker容器的特点" class="headerlink" title="Docker容器的特点"></a>Docker容器的特点</h1><ul><li>轻量，在一台机器上运行的多个Docker容器可以共享这台机器的操作系统内核；它们能够迅速启动，只需占用很少的计算和内存资源。镜像是通过文件系统层进行构造的，并共享一些公共文件。这样就能尽量降低磁盘用量，并能更快地下载镜像。</li><li>标准，Docker容器基于开放式标准，能够在所有主流Linux版本、Microsoft Windows以及包括VM、裸机服务器和云在内的任何基础设施上运行。</li><li>安全，Docker赋予应用的隔离性不仅限于彼此隔离，还独立于底层的基础设施。Docker默认提供最强的隔离，因此应用出现问题，也只是单个容器的问题，而不会波及到整台机器。</li></ul><h3 id="为什么要用Docker"><a href="#为什么要用Docker" class="headerlink" title="为什么要用Docker"></a>为什么要用Docker</h3><ul><li>Docker的镜像提供了除内核外完整的运行时环境，确保了应用运行环境一致性，从而不会再出现“这段代码在我机器上没问题啊”这类问题；——一致的运行环境</li><li>可以做到秒级、甚至毫秒级的启动时间。大大的节约了开发、测试、部署的时间。——更快速的启动时间</li><li>避免公用的服务器，资源会容易受到其他用户的影响。——隔离性</li><li>善于处理集中爆发的服务器使用压力；——弹性伸缩，快速扩展</li><li>可以很轻易的将在一个平台上运行的应用，迁移到另一个平台上，而不用担心运行环境的变化导致应用无法正常运行的情况。——迁移方便</li><li>使用Docker可以通过定制应用镜像来实现持续集成、持续交付、部署。——持续交付和部署</li></ul><h3 id="容器-VS-虚拟机"><a href="#容器-VS-虚拟机" class="headerlink" title="容器 VS 虚拟机"></a>容器 VS 虚拟机</h3><p>每当说起容器，我们不得不将其与虚拟机做一个比较。</p><ul><li>简单来说： 容器和虚拟机具有相似的资源隔离和分配优势，但功能有所不同，因为容器虚拟化的是操作系统，而不是硬件，因此容器更容易移植，效率也更高。</li><li>两者对比图</li></ul><p><img src="http://images.intflag.com/docker01-003.png" alt=""></p><p>传统虚拟机技术是虚拟出一套硬件后，在其上运行一个完整操作系统，在该系统上再运行所需应用进程；而容器内的应用进程直接运行于宿主的内核，容器内没有自己的内核，而且也没有进行硬件虚拟。因此容器要比传统虚拟机更为轻便。</p><h3 id="容器与虚拟机-VM-总结"><a href="#容器与虚拟机-VM-总结" class="headerlink" title="容器与虚拟机 (VM) 总结"></a>容器与虚拟机 (VM) 总结</h3><p><img src="http://images.intflag.com/docker01-004.png" alt=""></p><ul><li>容器是一个应用层抽象，用于将代码和依赖资源打包在一起。 多个容器可以在同一台机器上运行，共享操作系统内核，但各自作为独立的进程在用户空间中运行 。与虚拟机相比， 容器占用的空间较少（容器镜像大小通常只有几十兆），瞬间就能完成启动 。</li><li>虚拟机（VM）是一个物理硬件层抽象，用于将一台服务器变成多台服务器。 管理程序允许多个VM在一台机器上运行。每个VM都包含一整套操作系统、一个或多个应用、必要的二进制文件和库资源，因此占用大量空间。而且VM启动也十分缓慢 。</li></ul><p>通过Docker官网，我们知道了这么多Docker的优势，但是大家也没有必要完全否定虚拟机技术，因为两者有不同的使用场景。虚拟机更擅长于彻底隔离整个运行环境。例如，云服务提供商通常采用虚拟机技术隔离不同的用户。而Docker通常用于隔离不同的应用 ，例如前端，后端以及数据库。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;本人微信公众号，欢迎扫码关注！&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;http://images.intflag.com/bigdata002.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;引言&quot;&gt;&lt;a href=&quot;#引
      
    
    </summary>
    
      <category term="Docker" scheme="http://yoursite.com/categories/Docker/"/>
    
    
      <category term="Docker" scheme="http://yoursite.com/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop-CHD学习001-环境准备</title>
    <link href="http://yoursite.com/Hadoop-CHD%E5%AD%A6%E4%B9%A0001-%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87.html"/>
    <id>http://yoursite.com/Hadoop-CHD学习001-环境准备.html</id>
    <published>2019-05-02T01:56:49.795Z</published>
    <updated>2019-05-02T02:08:56.361Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本人微信公众号，欢迎扫码关注！</p></blockquote><p><img src="http://images.intflag.com/bigdata002.jpg" alt=""></p><h3 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h3><ul><li>Linux：7</li><li>Hadoop-CDH：hadoop-2.6.0-cdh5.15</li><li>下载：在linux下执行命令   <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Hadoop-CDH</span><br><span class="line">wget https://archive.cloudera.com/cdh5/cdh/5/hadoop-2.6.0-cdh5.15.1.tar.gz</span><br><span class="line"></span><br><span class="line">Hive</span><br><span class="line">wget https://archive.cloudera.com/cdh5/cdh/5/hive-1.1.0-cdh5.15.1.tar.gz</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;本人微信公众号，欢迎扫码关注！&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;http://images.intflag.com/bigdata002.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;环境准备&quot;&gt;&lt;a href=&quot;
      
    
    </summary>
    
      <category term="Hadoop" scheme="http://yoursite.com/categories/Hadoop/"/>
    
    
      <category term="Hadoop" scheme="http://yoursite.com/tags/Hadoop/"/>
    
      <category term="大数据" scheme="http://yoursite.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop系列003-1-Hadoop运行环境搭建</title>
    <link href="http://yoursite.com/Hadoop%E7%B3%BB%E5%88%97003-1-Hadoop%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA.html"/>
    <id>http://yoursite.com/Hadoop系列003-1-Hadoop运行环境搭建.html</id>
    <published>2019-04-28T03:06:19.000Z</published>
    <updated>2019-04-28T03:06:23.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本人微信公众号，欢迎扫码关注！</p></blockquote><p><img src="http://images.intflag.com/bigdata002.jpg" alt=""></p><h2 id="Hadoop运行环境搭建详细过程"><a href="#Hadoop运行环境搭建详细过程" class="headerlink" title="Hadoop运行环境搭建详细过程"></a>Hadoop运行环境搭建详细过程</h2><h3 id="1、准备"><a href="#1、准备" class="headerlink" title="1、准备"></a>1、准备</h3><ul><li>操作系统：Windows 10</li><li>虚拟机：VM</li><li>CentOS版本：6.10_Final</li><li>通过镜像安装CentOS到虚拟机中</li><li>设置虚拟机网络模式为NAT<h3 id="2、克隆虚拟机"><a href="#2、克隆虚拟机" class="headerlink" title="2、克隆虚拟机"></a>2、克隆虚拟机</h3></li><li>在VM中选中要克隆的虚拟机</li><li>鼠标右键 -&gt; 管理 -&gt; 克隆</li><li>在弹出的克隆界面 -&gt; 下一步 -&gt; 克隆源选择虚拟机当前状态下一步 -&gt; 创建完整克隆 -&gt; 命名并且选择存放位置 —&gt; 完成</li><li>完成后开机 -&gt; 使用root用户登录</li><li><p>删除原来的网卡</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/udev/rules.d/70-persistent-net.rules</span><br><span class="line">光标移动到原始网卡所在行，输入dd，删除该行</span><br><span class="line">移动光标或者直接按 shift+$ 移动到行尾</span><br><span class="line">将新网卡的NAME值由eth1改为rth0</span><br><span class="line">将MAC地址00:0c:29:c2:48:d5复制（接下来要用）</span><br><span class="line">ESC shift + : 输入wq 保存并退出</span><br></pre></td></tr></table></figure></li><li><p>修改网卡配置</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/sysconfig/network-scripts/ifcfg-eth0</span><br><span class="line">将HWADDR处替换为刚刚复制的MAC地址</span><br><span class="line">修改IPADDRR为指定的ip，避免与原始的虚拟机冲突</span><br><span class="line">修改hosthome：vi /etc/sysconfig/network</span><br><span class="line">修改为指定的主机名称</span><br><span class="line">修改本地host列表：vi /etc/hosts</span><br><span class="line">配置多个指定的host，例如下面：</span><br><span class="line">192.168.25.111 hadoop111</span><br><span class="line">192.168.25.112 hadoop112</span><br><span class="line">192.168.25.113 hadoop113</span><br><span class="line">192.168.25.114 hadoop114</span><br><span class="line">192.168.25.115 hadoop115</span><br><span class="line">192.168.25.116 hadoop116</span><br><span class="line">192.168.25.117 hadoop117</span><br><span class="line">192.168.25.118 hadoop118</span><br></pre></td></tr></table></figure></li><li><p>同步配置：输入sync</p></li><li>重启机器：reboot</li><li>重启后输出：ifconfig验证，是否能显示出网卡信息</li><li>测试虚拟机的网络是否和外面的主机连通：ping 10.12.2.109</li><li>关闭防火墙  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">查看防火墙开机启动状态：chkconfig iptables --list</span><br><span class="line">关闭防火墙：chkconfig iptables off</span><br></pre></td></tr></table></figure></li></ul><h3 id="3、创建工作空间"><a href="#3、创建工作空间" class="headerlink" title="3、创建工作空间"></a>3、创建工作空间</h3><ul><li><p>普通用户提升root权限</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/sudoers</span><br><span class="line">在次数找到root，复制一行，将用户改成intflag</span><br><span class="line">## Allow root to run any commands anywhere</span><br><span class="line">root    ALL=(ALL)       ALL</span><br><span class="line">intflag ALL=(ALL)       AL</span><br></pre></td></tr></table></figure></li><li><p>创建工作文件夹</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo mkdir module</span><br><span class="line">sudo mkdir software</span><br></pre></td></tr></table></figure></li><li><p>将工作文件的拥有者换成普通用户</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo chown intflag:intflag module/ software/</span><br></pre></td></tr></table></figure></li></ul><h3 id="4、安装JDK"><a href="#4、安装JDK" class="headerlink" title="4、安装JDK"></a>4、安装JDK</h3><ul><li><p>卸载原有JDK</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">查找JDK：rpm -qa | grep java</span><br><span class="line">卸载软件包：rpm -e 软件包名称</span><br></pre></td></tr></table></figure></li><li><p>通过FTP软件将JDK软件包上传到software目录下</p></li><li><p>解压到module目录下</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf jdk-7u79-linux-x64.gz -C /opt/module/</span><br></pre></td></tr></table></figure></li><li><p>复制jdk目录：/opt/module/jdk1.7.0_79</p></li><li><p>配置JDK环境变量</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sudo vi /etc/profile</span><br><span class="line">按shift + G 到文件最后一行</span><br><span class="line"></span><br><span class="line">输入下面配置</span><br><span class="line">#JAVA_HOME</span><br><span class="line">export JAVA_HOME=/opt/module/jdk1.7.0_79</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br></pre></td></tr></table></figure></li><li><p>刷新配置</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure></li><li><p>验证JDK是否安装成功：输入java -version</p><h3 id="5、安装Hadoop"><a href="#5、安装Hadoop" class="headerlink" title="5、安装Hadoop"></a>5、安装Hadoop</h3></li><li>通过FTP软件将Hadoop编译后的、编译后的、编译后的软件包上传到software目录下</li><li><p>解压到module目录下</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf hadoop-2.7.2.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure></li><li><p>复制jdk目录：/opt/module/hadoop-2.7.2</p></li><li><p>配置Hadoop环境变量</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sudo vi /etc/profile</span><br><span class="line">按shift + G 到文件最后一行</span><br><span class="line"></span><br><span class="line">输入下面配置</span><br><span class="line">#HADOOP_HOME</span><br><span class="line">export HADOOP_HOME=/opt/module/hadoop-2.7.2</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/sbin</span><br></pre></td></tr></table></figure></li><li><p>刷新配置</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure></li><li><p>验证Hadoop是否安装成功：输入hadoop</p></li><li>配置/opt/module/hadoop-2.7.2/etc/hadoop/hadoop-env.sh（可以不配置）  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo vi /opt/module/hadoop-2.7.2/etc/hadoop/hadoop-env.sh</span><br><span class="line">将JAVA_HOME地址配置成固定的地址</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;本人微信公众号，欢迎扫码关注！&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;http://images.intflag.com/bigdata002.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;Hadoop运行环境搭建详细过
      
    
    </summary>
    
      <category term="Hadoop" scheme="http://yoursite.com/categories/Hadoop/"/>
    
    
      <category term="Hadoop" scheme="http://yoursite.com/tags/Hadoop/"/>
    
      <category term="框架" scheme="http://yoursite.com/tags/%E6%A1%86%E6%9E%B6/"/>
    
      <category term="环境搭建" scheme="http://yoursite.com/tags/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    
  </entry>
  
  <entry>
    <title>Java设计模式01-策略模式</title>
    <link href="http://yoursite.com/Java%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F01-%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F.html"/>
    <id>http://yoursite.com/Java设计模式01-策略模式.html</id>
    <published>2019-04-26T09:36:59.000Z</published>
    <updated>2019-04-26T09:36:59.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>转载自本人微信公众号，欢迎扫码关注！</p></blockquote><p><img src="http://images.intflag.com/introduce2.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;转载自本人微信公众号，欢迎扫码关注！&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;http://images.intflag.com/introduce2.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;

      
    
    </summary>
    
      <category term="Java设计模式" scheme="http://yoursite.com/categories/Java%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
    
      <category term="设计模式" scheme="http://yoursite.com/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
      <category term="策略模式" scheme="http://yoursite.com/tags/%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>使用jdbc拼接条件查询语句时如何防止sql注入</title>
    <link href="http://yoursite.com/%E4%BD%BF%E7%94%A8JDBC%E6%8B%BC%E6%8E%A5%E6%9D%A1%E4%BB%B6%E6%9F%A5%E8%AF%A2%E6%97%B6%E5%A6%82%E4%BD%95%E9%98%B2%E6%AD%A2SQL%E6%B3%A8%E5%85%A5.html"/>
    <id>http://yoursite.com/使用JDBC拼接条件查询时如何防止SQL注入.html</id>
    <published>2019-04-22T11:16:09.000Z</published>
    <updated>2019-04-22T11:16:09.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本人微信公众号，欢迎扫码关注！</p></blockquote><p><img src="http://images.intflag.com/bigdata002.jpg" alt=""></p><h2 id="使用jdbc拼接条件查询语句时如何防止sql注入"><a href="#使用jdbc拼接条件查询语句时如何防止sql注入" class="headerlink" title="使用jdbc拼接条件查询语句时如何防止sql注入"></a>使用jdbc拼接条件查询语句时如何防止sql注入</h2><ul><li>最近公司的项目在上线时需要进行安全扫描，但是有几个项目中含有部分老代码，操作数据库时使用的是jdbc，并且竟然好多都是拼接的SQL语句，真是令人抓狂。</li><li>在具体改造时，必须使用PreparedStatement来防止SQL注入，普通SQL语句比较容易改造，本重点探讨在拼接查询条件的时候如何方式SQL注入，具体思路请参考下面的示例代码。<h3 id="1-数据库示例数据"><a href="#1-数据库示例数据" class="headerlink" title="1 数据库示例数据"></a>1 数据库示例数据</h3><img src="http://images.intflag.com/%E4%BD%BF%E7%94%A8JDBC%E6%8B%BC%E6%8E%A5%E6%9D%A1%E4%BB%B6%E6%9F%A5%E8%AF%A2%E6%97%B6%E5%A6%82%E4%BD%95%E9%98%B2%E6%AD%A2SQL%E6%B3%A8%E5%85%A5001.png" alt=""><h3 id="2-使用statement（不防止SQL注入）"><a href="#2-使用statement（不防止SQL注入）" class="headerlink" title="2 使用statement（不防止SQL注入）"></a>2 使用statement（不防止SQL注入）</h3><h4 id="2-1-示例代码"><a href="#2-1-示例代码" class="headerlink" title="2.1 示例代码"></a>2.1 示例代码</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">@Test</span><br><span class="line">public void statementTest() &#123;</span><br><span class="line">    String username = &quot;tom&quot;;</span><br><span class="line">    String sex = &quot;1&quot;;</span><br><span class="line">    String address = &quot;&apos; or &apos;1&apos;=&apos;1&quot;;</span><br><span class="line">    Statement stat = null;</span><br><span class="line">    ResultSet res = null;</span><br><span class="line"></span><br><span class="line">    Connection conn = ConnectionFactory.getConnection();</span><br><span class="line">    String sql = &quot;SELECT * FROM user WHERE 1 = 1&quot;;</span><br><span class="line"></span><br><span class="line">    sql += username == null ? &quot;&quot; : &quot; AND username = &apos;&quot; + username + &quot;&apos;&quot;;</span><br><span class="line">    sql += sex == null ? &quot;&quot; : &quot; AND sex = &apos;&quot; + sex + &quot;&apos;&quot;;</span><br><span class="line">    sql += address == null ? &quot;&quot; : &quot; AND address = &apos;&quot; + address + &quot;&apos;&quot;;</span><br><span class="line"></span><br><span class="line">    System.out.println(sql);</span><br><span class="line"></span><br><span class="line">    try &#123;</span><br><span class="line">        stat = conn.createStatement();</span><br><span class="line">        res = stat.executeQuery(sql);</span><br><span class="line">        printRes(res);</span><br><span class="line">    &#125; catch (SQLException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">        ResourceClose.close(res, stat, conn);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h4 id="2-2-控制台结果"><a href="#2-2-控制台结果" class="headerlink" title="2.2 控制台结果"></a>2.2 控制台结果</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM user WHERE 1 = 1 AND username = &apos;tom&apos; AND sex = &apos;1&apos; AND address = &apos;&apos; or &apos;1&apos;=&apos;1&apos;</span><br><span class="line">10 tom 2014-07-10 1 beijing </span><br><span class="line">16 tom 2018-07-31 1 shanghai </span><br><span class="line">22 tom 2019-04-16 2 shanghai </span><br><span class="line">24 tom 2019-06-22 1 guangzhou </span><br><span class="line">25 tom 2019-01-22 2 guangzhou </span><br><span class="line">28 tom 2018-07-31 1 shenzhen</span><br></pre></td></tr></table></figure><h4 id="2-3-小结"><a href="#2-3-小结" class="headerlink" title="2.3 小结"></a>2.3 小结</h4><ul><li>经过上面的示例代码我们可以发现，单纯拼接SQL语句是非常危险的，特别容易被SQL注入，但是如果使用prepareStatement的话，像这种条件查询我们预先并不能确定到底有多少个？（占位符），也就不能使用按照？（占位符）索引去设置参数了，那怎么办呢？</li><li>别担心，此时我们使用一个小小的技巧，具体参考下面的示例代码<h3 id="3-使用prepareStatement（可以防止SQL注入）"><a href="#3-使用prepareStatement（可以防止SQL注入）" class="headerlink" title="3 使用prepareStatement（可以防止SQL注入）"></a>3 使用prepareStatement（可以防止SQL注入）</h3><h4 id="3-1-示例代码"><a href="#3-1-示例代码" class="headerlink" title="3.1 示例代码"></a>3.1 示例代码</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">@Test</span><br><span class="line">public void prepareStatementTest() &#123;</span><br><span class="line">    String username = &quot;tom&quot;;</span><br><span class="line">    String sex = null;</span><br><span class="line">    String address = &quot;&apos; or &apos;1&apos;=&apos;1&quot;;</span><br><span class="line">    PreparedStatement stat = null;</span><br><span class="line">    ResultSet res = null;</span><br><span class="line"></span><br><span class="line">    Connection conn = ConnectionFactory.getConnection();</span><br><span class="line">    String sql = &quot;SELECT * FROM user WHERE 1 = 1&quot;;</span><br><span class="line"></span><br><span class="line">    List&lt;Object&gt; param = new ArrayList&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    if (username != null) &#123;</span><br><span class="line">        sql += &quot; AND username = ?&quot;;</span><br><span class="line">        param.add(username);</span><br><span class="line">    &#125;</span><br><span class="line">    if (sex != null) &#123;</span><br><span class="line">        sql += &quot; AND sex = ?&quot;;</span><br><span class="line">        param.add(sex);</span><br><span class="line">    &#125;</span><br><span class="line">    if (address != null) &#123;</span><br><span class="line">        sql += &quot; AND address = ?&quot;;</span><br><span class="line">        param.add(address);</span><br><span class="line">    &#125;</span><br><span class="line">    System.out.println(sql);</span><br><span class="line"></span><br><span class="line">    try &#123;</span><br><span class="line">        stat = conn.prepareStatement(sql);</span><br><span class="line">        for (int i = 0; i &lt; param.size(); i++) &#123;</span><br><span class="line">            stat.setObject(i+1,param.get(i));</span><br><span class="line">        &#125;</span><br><span class="line">        res = stat.executeQuery();</span><br><span class="line">        printRes(res);</span><br><span class="line">    &#125; catch (SQLException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">        ResourceClose.close(res, stat, conn);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h4 id="3-2-控制台结果"><a href="#3-2-控制台结果" class="headerlink" title="3.2 控制台结果"></a>3.2 控制台结果</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM user WHERE 1 = 1 AND username = ? AND address = ?</span><br></pre></td></tr></table></figure><h4 id="3-3-小结"><a href="#3-3-小结" class="headerlink" title="3.3 小结"></a>3.3 小结</h4><ul><li>可以看出，使用prepareStatement是可以防止SQL注入的。</li><li>但进行类似条件拼接这种操作时，可以先把参数放入一个集合中，然后遍历集合，同时利用setObject(index,obj)这个方法就可以动态的获取参数的索引了，而且不用关心参数是何种类型。<h3 id="4-问题总结"><a href="#4-问题总结" class="headerlink" title="4 问题总结"></a>4 问题总结</h3></li><li>如今在进行项目开发时已经很少使用原生的jdbc了，大多数都用功能强大的框架去完成，他们帮我们简化了很多操作，如获取数据库连接、封装结果集、SQL预编译（可以防止SQL注入）</li><li>如果实在避免不了使用的话一定要使用可以需编译的prepareStatement对象，避免被SQL注入带来的风险。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;本人微信公众号，欢迎扫码关注！&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;http://images.intflag.com/bigdata002.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;使用jdbc拼接条件查询语句时
      
    
    </summary>
    
      <category term="问题排查" scheme="http://yoursite.com/categories/%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/"/>
    
    
      <category term="jdbc" scheme="http://yoursite.com/tags/jdbc/"/>
    
      <category term="条件查询" scheme="http://yoursite.com/tags/%E6%9D%A1%E4%BB%B6%E6%9F%A5%E8%AF%A2/"/>
    
      <category term="sql注入" scheme="http://yoursite.com/tags/sql%E6%B3%A8%E5%85%A5/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop系列009-NameNode工作机制</title>
    <link href="http://yoursite.com/Hadoop%E7%B3%BB%E5%88%97009-NameNode%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6.html"/>
    <id>http://yoursite.com/Hadoop系列009-NameNode工作机制.html</id>
    <published>2019-01-24T02:34:18.000Z</published>
    <updated>2019-01-24T02:34:18.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本人微信公众号，欢迎扫码关注！</p></blockquote><p><img src="http://images.intflag.com/bigdata002.jpg" alt=""></p><h2 id="NameNode工作机制"><a href="#NameNode工作机制" class="headerlink" title="NameNode工作机制"></a>NameNode工作机制</h2><h3 id="1-NameNode-amp-SecondaryNameNode工作机制"><a href="#1-NameNode-amp-SecondaryNameNode工作机制" class="headerlink" title="1 NameNode &amp; SecondaryNameNode工作机制"></a>1 NameNode &amp; SecondaryNameNode工作机制</h3><p><img src="http://images.intflag.com/NameNode%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6001.jpg" alt=""></p><h4 id="1-1-第一阶段：namenode启动"><a href="#1-1-第一阶段：namenode启动" class="headerlink" title="1.1 第一阶段：namenode启动"></a>1.1 第一阶段：namenode启动</h4><p>1）第一次启动namenode格式化后，创建fsimage和edits文件。如果不是第一次启动，直接加载编辑日志和镜像文件到内存。</p><p>2）客户端对元数据进行增删改查的请求</p><p>3）namenode记录操作日志，更新滚动日志。</p><p>4）namenode在内存中对数据进行增删改查</p><h4 id="1-2-第二阶段：Secondary-NameNode工作"><a href="#1-2-第二阶段：Secondary-NameNode工作" class="headerlink" title="1.2 第二阶段：Secondary NameNode工作"></a>1.2 第二阶段：Secondary NameNode工作</h4><p>1）Secondary NameNode询问namenode是否需要checkpoint。直接带回namenode是否检查结果。</p><p>2）Secondary NameNode请求执行checkpoint。</p><p>3）namenode滚动正在写的edits日志</p><p>4）将滚动前的编辑日志和镜像文件拷贝到Secondary NameNode</p><p>5）Secondary NameNode加载编辑日志和镜像文件到内存，并合并。</p><p>6）生成新的镜像文件fsimage.chkpoint</p><p>7）拷贝fsimage.chkpoint到namenode</p><p>8）namenode将fsimage.chkpoint重新命名成fsimage</p><h4 id="1-3-参数设置"><a href="#1-3-参数设置" class="headerlink" title="1.3 参数设置"></a>1.3 参数设置</h4><p>（1）通常情况下，SecondaryNameNode每隔一小时执行一次。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[hdfs-default.xml]</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.namenode.checkpoint.period&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;3600&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><p>（2）一分钟检查一次操作次数，当操作次数达到1百万时，SecondaryNameNode执行一次。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.namenode.checkpoint.txns&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;1000000&lt;/value&gt;</span><br><span class="line">  &lt;description&gt;操作动作次数&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;dfs.namenode.checkpoint.check.period&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;60&lt;/value&gt;</span><br><span class="line">  &lt;description&gt; 1分钟检查一次操作次数&lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><h3 id="2-NameNode版本号"><a href="#2-NameNode版本号" class="headerlink" title="2 NameNode版本号"></a>2 NameNode版本号</h3><h4 id="2-1-查看namenode版本号"><a href="#2-1-查看namenode版本号" class="headerlink" title="2.1 查看namenode版本号"></a>2.1 查看namenode版本号</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">在/opt/module/hadoop-2.7.2/data/tmp/dfs/name/current这个目录下查看VERSION</span><br><span class="line"></span><br><span class="line">namespaceID=1933630176</span><br><span class="line">clusterID=CID-1f2bf8d1-5ad2-4202-af1c-6713ab381175</span><br><span class="line">cTime=0</span><br><span class="line">storageType=NAME_NODE</span><br><span class="line">blockpoolID=BP-97847618-192.168.10.102-1493726072779</span><br><span class="line">layoutVersion=-63</span><br></pre></td></tr></table></figure><h4 id="namenode版本号具体解释"><a href="#namenode版本号具体解释" class="headerlink" title="namenode版本号具体解释"></a>namenode版本号具体解释</h4><p>（1）namespaceID在HDFS上，会有多个Namenode，所以不同Namenode的namespaceID是不同的，分别管理一组blockpoolID。</p><p>（2）clusterID集群id，全局唯一</p><p>（3）cTime属性标记了namenode存储系统的创建时间，对于刚刚格式化的存储系统，这个属性为0；但是在文件系统升级之后，该值会更新到新的时间戳。</p><p>（4）storageType属性说明该存储目录包含的是namenode的数据结构。</p><p>（5）blockpoolID：一个block pool id标识一个block pool，并且是跨集群的全局唯一。当一个新的Namespace被创建的时候(format过程的一部分)会创建并持久化一个唯一ID。在创建过程构建全局唯一的BlockPoolID比人为的配置更可靠一些。NN将BlockPoolID持久化到磁盘中，在后续的启动过程中，会再次load并使用。</p><p>（6）layoutVersion是一个负整数。通常只有HDFS增加新特性时才会更新这个版本号。</p><h3 id="3-镜像文件和编辑日志文件"><a href="#3-镜像文件和编辑日志文件" class="headerlink" title="3 镜像文件和编辑日志文件"></a>3 镜像文件和编辑日志文件</h3><h4 id="3-1-概念"><a href="#3-1-概念" class="headerlink" title="3.1 概念"></a>3.1 概念</h4><h5 id="3-1-1-Fsimage文件"><a href="#3-1-1-Fsimage文件" class="headerlink" title="3.1.1 Fsimage文件"></a>3.1.1 Fsimage文件</h5><p>HDFS文件系统元数据的一个永久性的检查点，其中包含HDFS文件系统的所有目录和文件idnode的序列化信息。</p><h5 id="3-1-2-Edits文件"><a href="#3-1-2-Edits文件" class="headerlink" title="3.1.2 Edits文件"></a>3.1.2 Edits文件</h5><p>存放HDFS文件系统的所有更新操作的路径，文件系统客户端执行的所有写操作首先会被记录到edits文件中。</p><h5 id="3-1-3-namenode格式化，具体做什么事"><a href="#3-1-3-namenode格式化，具体做什么事" class="headerlink" title="3.1.3 namenode格式化，具体做什么事"></a>3.1.3 namenode格式化，具体做什么事</h5><p>（1）创建fsimage文件，存储fsimage信息</p><p>（2）创建edits文件</p><p>（3）namenode被格式化之后，将产生如下所示的目录结构</p><p><img src="http://images.intflag.com/NameNode%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6002.jpg" alt=""></p><h4 id="3-2-oiv查看fsimage文件"><a href="#3-2-oiv查看fsimage文件" class="headerlink" title="3.2 oiv查看fsimage文件"></a>3.2 oiv查看fsimage文件</h4><p>（1）查看oiv和oev命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 current]$ hdfs</span><br><span class="line">oiv                  apply the offline fsimage viewer to an fsimage</span><br><span class="line">oev                  apply the offline edits viewer to an edits file</span><br></pre></td></tr></table></figure><p>（2）基本语法</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs oiv -p 文件类型 -i镜像文件 -o 转换后文件输出路径</span><br></pre></td></tr></table></figure><p>（3）案例实操</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 current]$ pwd</span><br><span class="line">/opt/module/hadoop-2.7.2/data/tmp/dfs/name/current</span><br><span class="line"></span><br><span class="line">[atguigu@hadoop102 current]$ hdfs oiv -p XML -i fsimage_0000000000000000025 -o /opt/module/hadoop-2.7.2/fsimage.xml</span><br><span class="line"></span><br><span class="line">[atguigu@hadoop102 current]$ cat /opt/module/hadoop-2.7.2/fsimage.xml</span><br><span class="line">将显示的xml文件内容拷贝到eclipse中创建的xml文件中，并格式化。</span><br></pre></td></tr></table></figure><h4 id="3-3-oev查看fsimage文件"><a href="#3-3-oev查看fsimage文件" class="headerlink" title="3.3 oev查看fsimage文件"></a>3.3 oev查看fsimage文件</h4><p>（1）基本语法</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs oev -p 文件类型 -i编辑日志 -o 转换后文件输出路径</span><br></pre></td></tr></table></figure><p>（2）案例实操</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 current]$ hdfs oev -p XML -i </span><br><span class="line">edits_0000000000000000012-0000000000000000013 -o /opt/module/hadoop-2.7.2/edits.xml</span><br><span class="line"></span><br><span class="line">[atguigu@hadoop102 current]$ cat /opt/module/hadoop-2.7.2/edits.xml</span><br><span class="line">将显示的xml文件内容拷贝到eclipse中创建的xml文件中，并格式化。</span><br></pre></td></tr></table></figure><h3 id="4-滚动编辑日志"><a href="#4-滚动编辑日志" class="headerlink" title="4 滚动编辑日志"></a>4 滚动编辑日志</h3><p>正常情况HDFS文件系统有更新操作时，就会滚动编辑日志。也可以用命令强制滚动编辑日志。</p><p>1）滚动编辑日志（前提必须启动集群）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfsadmin -rollEdits</span><br></pre></td></tr></table></figure><p>2）镜像文件什么时候产生</p><p>Namenode启动时加载镜像文件和编辑日志</p><p><img src="http://images.intflag.com/NameNode%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6003.jpg" alt=""></p><h3 id="5-SecondaryNameNode目录结构"><a href="#5-SecondaryNameNode目录结构" class="headerlink" title="5 SecondaryNameNode目录结构"></a>5 SecondaryNameNode目录结构</h3><p>Secondary NameNode用来监控HDFS状态的辅助后台程序，每隔一段时间获取HDFS元数据的快照。</p><p>在/opt/module/hadoop-2.7.2/data/tmp/dfs/namesecondary/current这个目录中查看SecondaryNameNode目录结构。</p><p>SecondaryNameNode在previous.checkpoint子目录中备份了主namenode节点中的数据</p><p><img src="http://images.intflag.com/NameNode%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6004.jpg" alt=""></p><p>SecondaryNameNode的previous.checkpoint目录、SecondaryNameNode的current目录和主namenode的current目录的布局相同。</p><p>好处：在主namenode发生故障时（假设没有及时备份数据），可以从SecondaryNameNode恢复数据。</p><p>方法一：将相关存储目录复制到新的namenode中；</p><p>方法二：使用-importCheckpoint选项启动namenode守护进程，从而将SecondaryNameNode用作新的主namenode。</p><h3 id="6-集群安全模式操作"><a href="#6-集群安全模式操作" class="headerlink" title="6 集群安全模式操作"></a>6 集群安全模式操作</h3><h4 id="6-2-概述"><a href="#6-2-概述" class="headerlink" title="6.2 概述"></a>6.2 概述</h4><p>Namenode启动时，首先将映像文件（fsimage）载入内存，并执行编辑日志（edits）中的各项操作。一旦在内存中成功建立文件系统元数据的映像，则创建一个新的fsimage文件和一个空的编辑日志。此时，namenode开始监听datanode请求。但是此刻，namenode运行在安全模式，即namenode的文件系统对于客户端来说是只读的。</p><p>系统中的数据块的位置并不是由namenode维护的，而是以块列表的形式存储在datanode中。在系统的正常操作期间，namenode会在内存中保留所有块位置的映射信息。在安全模式下，各个datanode会向namenode发送最新的块列表信息，namenode了解到足够多的块位置信息之后，即可高效运行文件系统。</p><p>如果满足“最小复本条件”，namenode会在30秒钟之后就退出安全模式。所谓的最小复本条件指的是在整个文件系统中99.9%的块满足最小复本级别（默认值：dfs.replication.min=1）。在启动一个刚刚格式化的HDFS集群时，因为系统中还没有任何块，所以namenode不会进入安全模式。</p><h4 id="6-3-基本语法"><a href="#6-3-基本语法" class="headerlink" title="6.3 基本语法"></a>6.3 基本语法</h4><p>集群处于安全模式，不能执行重要操作（写操作）。集群启动完成后，自动退出安全模式。</p><p>（1）bin/hdfs dfsadmin -safemode get        （功能描述：查看安全模式状态）</p><p>（2）bin/hdfs dfsadmin -safemode enter      （功能描述：进入安全模式状态）</p><p>（3）bin/hdfs dfsadmin -safemode leave    （功能描述：离开安全模式状态）</p><p>（4）bin/hdfs dfsadmin -safemode wait    （功能描述：等待安全模式状态）</p><h4 id="6-3-案例"><a href="#6-3-案例" class="headerlink" title="6.3 案例"></a>6.3 案例</h4><p>编辑一个脚本</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">bin/hdfs dfsadmin -safemode wait</span><br><span class="line">bin/hdfs dfs –put ~/hello.txt /root/hello.txt</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;本人微信公众号，欢迎扫码关注！&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;http://images.intflag.com/bigdata002.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;NameNode工作机制&quot;&gt;&lt;
      
    
    </summary>
    
      <category term="Hadoop" scheme="http://yoursite.com/categories/Hadoop/"/>
    
    
      <category term="Hadoop" scheme="http://yoursite.com/tags/Hadoop/"/>
    
      <category term="HDFS" scheme="http://yoursite.com/tags/HDFS/"/>
    
      <category term="NameNode" scheme="http://yoursite.com/tags/NameNode/"/>
    
      <category term="工作机制" scheme="http://yoursite.com/tags/%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop系列008-HDFS的数据流</title>
    <link href="http://yoursite.com/Hadoop%E7%B3%BB%E5%88%97008-HDFS%E7%9A%84%E6%95%B0%E6%8D%AE%E6%B5%81.html"/>
    <id>http://yoursite.com/Hadoop系列008-HDFS的数据流.html</id>
    <published>2019-01-10T06:44:37.000Z</published>
    <updated>2019-01-10T06:44:37.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本人微信公众号，欢迎扫码关注！</p></blockquote><p><img src="http://images.intflag.com/bigdata002.jpg" alt=""></p><h2 id="HDFS的数据流"><a href="#HDFS的数据流" class="headerlink" title="HDFS的数据流"></a>HDFS的数据流</h2><h3 id="1-HDFS写数据流程"><a href="#1-HDFS写数据流程" class="headerlink" title="1 HDFS写数据流程"></a>1 HDFS写数据流程</h3><h4 id="1-1-剖析文件写入"><a href="#1-1-剖析文件写入" class="headerlink" title="1.1 剖析文件写入"></a>1.1 剖析文件写入</h4><p><img src="http://images.intflag.com/HDFS%E7%9A%84%E6%95%B0%E6%8D%AE%E6%B5%81001.jpg" alt=""></p><p>1）客户端向namenode请求上传文件，namenode检查目标文件是否已存在，父目录是否存在。</p><p>2）namenode返回是否可以上传。</p><p>3）客户端请求第一个 block上传到哪几个datanode服务器上。</p><p>4）namenode返回3个datanode节点，分别为dn1、dn2、dn3。</p><p>5）客户端请求dn1上传数据，dn1收到请求会继续调用dn2，然后dn2调用dn3，将这个通信管道建立完成</p><p>6）dn1、dn2、dn3逐级应答客户端</p><p>7）客户端开始往dn1上传第一个block（先从磁盘读取数据放到一个本地内存缓存），以packet为单位，dn1收到一个packet就会传给dn2，dn2传给dn3；dn1每传一个packet会放入一个应答队列等待应答</p><p>8）当一个block传输完成之后，客户端再次请求namenode上传第二个block的服务器。（重复执行3-7步）</p><h4 id="1-2-网络拓扑概念"><a href="#1-2-网络拓扑概念" class="headerlink" title="1.2 网络拓扑概念"></a>1.2 网络拓扑概念</h4><p><img src="http://images.intflag.com/HDFS%E7%9A%84%E6%95%B0%E6%8D%AE%E6%B5%81002.jpg" alt=""></p><pre><code>在本地网络中，两个节点被称为“彼此近邻”是什么意思？在海量数据处理中，其主要限制因素是节点之间数据的传输速率——带宽很稀缺。这里的想法是将两个节点间的带宽作为距离的衡量标准。节点距离：两个节点到达最近的共同祖先的距离总和。例如，假设有数据中心d1机架r1中的节点n1。该节点可以表示为/d1/r1/n1。利用这种标记，这里给出四种距离描述。Distance(/d1/r1/n1, /d1/r1/n1)=0（同一节点上的进程）Distance(/d1/r1/n1, /d1/r1/n2)=2（同一机架上的不同节点）Distance(/d1/r1/n1, /d1/r3/n2)=4（同一数据中心不同机架上的节点）Distance(/d1/r1/n1, /d2/r4/n2)=6（不同数据中心的节点）</code></pre><h4 id="1-3-机架感知（副本节点选择）"><a href="#1-3-机架感知（副本节点选择）" class="headerlink" title="1.3 机架感知（副本节点选择）"></a>1.3 机架感知（副本节点选择）</h4><h5 id="1-3-1-官方地址"><a href="#1-3-1-官方地址" class="headerlink" title="1.3.1 官方地址"></a>1.3.1 官方地址</h5><p><a href="http://hadoop.apache.org/docs/r2.7.3/hadoop-project-dist/hadoop-common/RackAwareness.html" target="_blank" rel="noopener">http://hadoop.apache.org/docs/r2.7.3/hadoop-project-dist/hadoop-common/RackAwareness.html</a></p><h5 id="1-3-2-低版本Hadoop复本节点选择"><a href="#1-3-2-低版本Hadoop复本节点选择" class="headerlink" title="1.3.2 低版本Hadoop复本节点选择"></a>1.3.2 低版本Hadoop复本节点选择</h5><p><img src="http://images.intflag.com/HDFS%E7%9A%84%E6%95%B0%E6%8D%AE%E6%B5%81003.jpg" alt=""></p><ul><li>第一个复本在client所处的节点上。如果客户端在集群外，随机选一个。</li><li>第二个复本和第一个复本位于不相同机架的随机节点上。</li><li>第三个复本和第二个复本位于相同机架，节点随机。</li></ul><h5 id="1-3-3-Hadoop2-7-2副本节点选择"><a href="#1-3-3-Hadoop2-7-2副本节点选择" class="headerlink" title="1.3.3 Hadoop2.7.2副本节点选择"></a>1.3.3 Hadoop2.7.2副本节点选择</h5><p><img src="http://images.intflag.com/HDFS%E7%9A%84%E6%95%B0%E6%8D%AE%E6%B5%81004.jpg" alt=""></p><ul><li>第一个副本在client所处的节点上。如果客户端在集群外，随机选一个。</li><li>第二个副本和第一个副本位于相同机架，随机节点。</li><li>第三个副本位于不同机架，随机节点。</li></ul><h5 id="1-3-4-自定义机架感知"><a href="#1-3-4-自定义机架感知" class="headerlink" title="1.3.4 自定义机架感知"></a>1.3.4 自定义机架感知</h5><ul><li><p>（0）环境准备</p><ul><li><p>（a）数据节点的量</p><p>[rack1]：hadoop102、hadoop103</p><p>[rack2]：hadoop104、hadoop105</p></li><li><p>（b）增加一个数据节点</p><p>（1）克隆一个节点</p><p>（2）启动新节点</p><p>（3）修改克隆的ip和主机名</p><p>（4）在hadoop102上ssh到新节点</p><p>（5）修改xsync.sh和xcall.sh文件</p><p>（6）修改hadoop102 slaves文件，再分发</p></li></ul></li><li><p>（1）创建类实现DNSToSwitchMapping接口</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">public class MyDNSToSwichMapping implements DNSToSwitchMapping &#123;</span><br><span class="line">// 传递的是客户端的ip列表，返回机架感知的路径列表</span><br><span class="line">public List&lt;String&gt; resolve(List&lt;String&gt; names) &#123;</span><br><span class="line"></span><br><span class="line">ArrayList&lt;String&gt; lists = new ArrayList&lt;String&gt;();</span><br><span class="line">if (names != null &amp;&amp; names.size() &gt; 0) &#123;</span><br><span class="line">for (String name : names) &#123;</span><br><span class="line">int ip = 0;</span><br><span class="line">                // 获取ip地址</span><br><span class="line">if (name.startsWith(&quot;hadoop&quot;)) &#123;</span><br><span class="line">String no = name.substring(6);</span><br><span class="line">// hadoop102</span><br><span class="line">ip = Integer.parseInt(no);</span><br><span class="line">&#125; else if (name.startsWith(&quot;192&quot;)) &#123;</span><br><span class="line">// 192.168.10.102</span><br><span class="line">ip = Integer.parseInt(name.substring(name.lastIndexOf(&quot;.&quot;) + 1));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">                // 定义机架</span><br><span class="line">if (ip &lt; 104) &#123;</span><br><span class="line">lists.add(&quot;/rack1/&quot; + ip);</span><br><span class="line">&#125; else &#123;</span><br><span class="line">lists.add(&quot;/rack2/&quot; + ip);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">        </span><br><span class="line">        // 把ip地址打印出来</span><br><span class="line">try &#123;</span><br><span class="line">FileOutputStream fos = new FileOutputStream(&quot;/home/atguigu/name.txt&quot;);</span><br><span class="line"></span><br><span class="line">for (String name : lists) &#123;</span><br><span class="line">fos.write((name + &quot;\r\n&quot;).getBytes());</span><br><span class="line">&#125;</span><br><span class="line">fos.close();</span><br><span class="line">&#125; catch (Exception e) &#123;</span><br><span class="line">e.printStackTrace();</span><br><span class="line">&#125;</span><br><span class="line">return lists;</span><br><span class="line">&#125;</span><br><span class="line">public void reloadCachedMappings() &#123;</span><br><span class="line">&#125;</span><br><span class="line">public void reloadCachedMappings(List&lt;String&gt; names) &#123;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>（2）配置core-site.xml</p><ul><li><p>默认的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- Topology Configuration --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;net.topology.node.switch.mapping.impl&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;org.apache.hadoop.net.ScriptBasedMapping&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></li><li><p>配置后的</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- Topology Configuration --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;net.topology.node.switch.mapping.impl&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;com.atguigu.hdfs.MyDNSToSwichMapping&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>（3）分发core-site.xml</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xsync /opt/module/hadoop-2.7.2/etc/hadoop/core-site.xml</span><br></pre></td></tr></table></figure></li><li><p>（4）编译程序，打成jar，分发到所有节点的hadoop的classpath下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/module/hadoop-2.7.2/share/hadoop/common/lib</span><br><span class="line">xsync MyDNSSwitchToMapping.jar</span><br></pre></td></tr></table></figure></li><li><p>（5）重新启动集群</p></li><li><p>（6）在名称节点hadoop103主机上查看名称</p></li><li><p>（7）查看结果</p><ul><li><p>（1）在hadoop105节点上传文件到hdfs文件系统，查看复本存放位置</p><p><img src="http://images.intflag.com/HDFS%E7%9A%84%E6%95%B0%E6%8D%AE%E6%B5%81005.jpg" alt=""></p></li><li><p>（2）在hadoop102节点上传文件到hdfs文件系统，查看复本存放位置</p><p><img src="http://images.intflag.com/HDFS%E7%9A%84%E6%95%B0%E6%8D%AE%E6%B5%81006.jpg" alt=""></p></li><li><p>（3）结论</p><p>第一个副本在client所处的节点上。如果客户端在集群外，随机选一个。</p><p>第二个副本和第一个副本位于相同机架，随机节点。</p><p>第三个副本位于不同机架，随机节点。</p></li></ul></li></ul><h3 id="2-HDFS读数据流程"><a href="#2-HDFS读数据流程" class="headerlink" title="2 HDFS读数据流程"></a>2 HDFS读数据流程</h3><p><img src="http://images.intflag.com/HDFS%E7%9A%84%E6%95%B0%E6%8D%AE%E6%B5%81007.jpg" alt=""></p><p>1）客户端向namenode请求下载文件，namenode通过查询元数据，找到文件块所在的datanode地址。</p><p>2）挑选一台datanode（就近原则，然后随机）服务器，请求读取数据。</p><p>3）datanode开始传输数据给客户端（从磁盘里面读取数据放入流，以packet为单位来做校验）。</p><p>4）客户端以packet为单位接收，先在本地缓存，然后写入目标文件。</p><h3 id="3-一致性模型"><a href="#3-一致性模型" class="headerlink" title="3 一致性模型"></a>3 一致性模型</h3><h4 id="3-1-debug调试如下代码"><a href="#3-1-debug调试如下代码" class="headerlink" title="3.1 debug调试如下代码"></a>3.1 debug调试如下代码</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">@Test</span><br><span class="line">public void writeFile() throws Exception&#123;</span><br><span class="line">// 1 创建配置信息对象</span><br><span class="line">Configuration configuration = new Configuration();</span><br><span class="line">fs = FileSystem.get(configuration);</span><br><span class="line"></span><br><span class="line">// 2 创建文件输出流</span><br><span class="line">Path path = new Path(&quot;hdfs://hadoop102:8020/user/atguigu/hello.txt&quot;);</span><br><span class="line">FSDataOutputStream fos = fs.create(path);</span><br><span class="line"></span><br><span class="line">// 3 写数据</span><br><span class="line">fos.write(&quot;hello&quot;.getBytes());</span><br><span class="line">//fos.flush();</span><br><span class="line">fos.hflush();</span><br><span class="line">//</span><br><span class="line">//fos.write(&quot;welcome to atguigu&quot;.getBytes());</span><br><span class="line">//fos.hsync();</span><br><span class="line"></span><br><span class="line">fos.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="3-2-总结"><a href="#3-2-总结" class="headerlink" title="3.2 总结"></a>3.2 总结</h4><ul><li>写入数据时，如果希望数据被其他client立即可见，调用如下方法</li><li>FsDataOutputStream.hflus();        //清理客户端缓冲区数据，被其他client立即可见</li><li>FsDataOutputStream.hsync();        //清理客户端缓冲区数据，被其他client不能立即可见</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;本人微信公众号，欢迎扫码关注！&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;http://images.intflag.com/bigdata002.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;HDFS的数据流&quot;&gt;&lt;a hr
      
    
    </summary>
    
      <category term="Hadoop" scheme="http://yoursite.com/categories/Hadoop/"/>
    
    
      <category term="Hadoop" scheme="http://yoursite.com/tags/Hadoop/"/>
    
      <category term="HDFS" scheme="http://yoursite.com/tags/HDFS/"/>
    
      <category term="HDFS数据流" scheme="http://yoursite.com/tags/HDFS%E6%95%B0%E6%8D%AE%E6%B5%81/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop系列007-HDFS客户端操作</title>
    <link href="http://yoursite.com/Hadoop%E7%B3%BB%E5%88%97007-HDFS%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%93%8D%E4%BD%9C.html"/>
    <id>http://yoursite.com/Hadoop系列007-HDFS客户端操作.html</id>
    <published>2018-12-06T07:52:55.000Z</published>
    <updated>2018-12-06T07:52:55.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本人微信公众号，欢迎扫码关注！</p></blockquote><p><img src="http://images.intflag.com/bigdata002.jpg" alt=""></p><h2 id="HDFS客户端操作"><a href="#HDFS客户端操作" class="headerlink" title="HDFS客户端操作"></a>HDFS客户端操作</h2><h4 id="1-环境准备"><a href="#1-环境准备" class="headerlink" title="1 环境准备"></a>1 环境准备</h4><h5 id="1-1-Jar包准备"><a href="#1-1-Jar包准备" class="headerlink" title="1.1 Jar包准备"></a>1.1 Jar包准备</h5><p>1）解压hadoop-2.7.2.tar.gz到非中文目录</p><p><strong>注意1：如果使用WinRAR解压报错的话，就使用超级管理员权限打开DOS窗口，然后cd到解压包所在位置，执行start winrar x -y xxx.tar.gz命令，即可成功</strong></p><p><strong>注意2：使用对应平台下编译后的hadoop源码包，即win7系统使用在win7下编译后的源码包，win10同理。</strong></p><p><img src="http://images.intflag.com/HDFS%E5%AE%A2%E6%88%B7%E7%AB%AF002.jpg" alt=""></p><p>2）进入share文件夹，查找所有jar包，并把jar包拷贝到_lib文件夹下</p><p>3）在全部jar包中查找.source.jar，并剪切到_source文件夹。</p><p>4）在全部jar包中查找tests.jar，并剪切到_test文件夹。</p><p><img src="http://images.intflag.com/HDFS%E5%AE%A2%E6%88%B7%E7%AB%AF001.jpg" alt=""></p><h5 id="1-2-IDEA准备"><a href="#1-2-IDEA准备" class="headerlink" title="1.2 IDEA准备"></a>1.2 IDEA准备</h5><p>1）配置HADOOP_HOME环境变量</p><p><img src="http://images.intflag.com/HDFS%E5%AE%A2%E6%88%B7%E7%AB%AF003.jpg" alt=""></p><p>2）建立工程并且添加依赖</p><p><img src="http://images.intflag.com/HDFS%E5%AE%A2%E6%88%B7%E7%AB%AF004.jpg" alt=""></p><p><strong>注意：Eclipse全选Jar包右键Add Build Path</strong></p><p>3）编写代码测试</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//1 加载配置</span></span><br><span class="line">    Configuration configuration = <span class="keyword">new</span> Configuration();</span><br><span class="line">    configuration.set(<span class="string">"fs.defaultFS"</span>, <span class="string">"hdfs://hadoop102:8020"</span>);</span><br><span class="line"></span><br><span class="line">    FileSystem fileSystem = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">//2 获取文件系统</span></span><br><span class="line">        fileSystem = FileSystem.get(configuration);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3 上传文件到HDFS指定位置</span></span><br><span class="line">        fileSystem.copyFromLocalFile(<span class="keyword">new</span> Path(<span class="string">"D:/test/asd.txt"</span>), <span class="keyword">new</span> Path(<span class="string">"/user/intflag/input/asd.txt"</span>));</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        closeFileSystem(fileSystem);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>4）执行程序</p><p><strong>客户端去操作hdfs时，是有一个用户身份的。默认情况下，hdfs客户端api会从jvm中获取一个参数来作为自己的用户身份：-DHADOOP_USER_NAME=atguigu，atguigu为用户名称。</strong></p><p><img src="http://images.intflag.com/HDFS%E5%AE%A2%E6%88%B7%E7%AB%AF005.jpg" alt=""></p><p><img src="http://images.intflag.com/HDFS%E5%AE%A2%E6%88%B7%E7%AB%AF006.jpg" alt=""></p><p>5）验证</p><p><img src="http://images.intflag.com/HDFS%E5%AE%A2%E6%88%B7%E7%AB%AF007.jpg" alt=""></p><h4 id="2-通过API操作HDFS"><a href="#2-通过API操作HDFS" class="headerlink" title="2 通过API操作HDFS"></a>2 通过API操作HDFS</h4><h5 id="2-1-HDFS获取文件系统"><a href="#2-1-HDFS获取文件系统" class="headerlink" title="2.1 HDFS获取文件系统"></a>2.1 HDFS获取文件系统</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">@Test</span><br><span class="line">public void getFileSystem() &#123;</span><br><span class="line">    // 1 创建配置对象</span><br><span class="line">    Configuration conf = new Configuration();</span><br><span class="line">    // 2 获取文件系统</span><br><span class="line">    FileSystem fs = null;</span><br><span class="line">    try &#123;</span><br><span class="line">        fs = FileSystem.get(new URI(&quot;hdfs://hadoop102:8020&quot;), conf, &quot;intflag&quot;);</span><br><span class="line"></span><br><span class="line">        // 3 打印文件系统</span><br><span class="line">        System.out.println(fs);</span><br><span class="line">    &#125; catch (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125; catch (InterruptedException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125; catch (URISyntaxException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">        if (fs != null) &#123;</span><br><span class="line">            try &#123;</span><br><span class="line">                fs.close();</span><br><span class="line">            &#125; catch (IOException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="http://images.intflag.com/HDFS%E5%AE%A2%E6%88%B7%E7%AB%AF008.jpg" alt=""></p><h5 id="2-2-HDFS文件上传"><a href="#2-2-HDFS文件上传" class="headerlink" title="2.2 HDFS文件上传"></a>2.2 HDFS文件上传</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">@Test</span><br><span class="line">public void putFileToHDFS() &#123;</span><br><span class="line">    // 1 获取文件系统</span><br><span class="line">    FileSystem fs = getFileSystem();</span><br><span class="line">    // 2 上传文件</span><br><span class="line">    try &#123;</span><br><span class="line">        fs.copyFromLocalFile(true,new Path(&quot;D:/test/x3.000&quot;), new Path(&quot;/user/intflag/input/x3.000&quot;));</span><br><span class="line">    &#125; catch (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">        // 3 关闭资源</span><br><span class="line">        closeFileSystem(fs);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="2-3-HDFS文件下载"><a href="#2-3-HDFS文件下载" class="headerlink" title="2.3 HDFS文件下载"></a>2.3 HDFS文件下载</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">@Test</span><br><span class="line">public void getFileFromHDFS() &#123;</span><br><span class="line">    // 1 获取文件系统</span><br><span class="line">    FileSystem fs = getFileSystem();</span><br><span class="line">    // 2 下载文件</span><br><span class="line">    try &#123;</span><br><span class="line">        fs.copyToLocalFile(new Path(&quot;/user/intflag/input/x3.000&quot;),new Path(&quot;D:/test/x3.000&quot;));</span><br><span class="line">    &#125; catch (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">        // 3 关闭资源</span><br><span class="line">        closeFileSystem(fs);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="2-4-HDFS目录创建"><a href="#2-4-HDFS目录创建" class="headerlink" title="2.4 HDFS目录创建"></a>2.4 HDFS目录创建</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * 在HDFS上创建文件夹</span><br><span class="line"> */</span><br><span class="line">@Test</span><br><span class="line">public void mkdirAtHDFS() &#123;</span><br><span class="line">    // 1 获取文件系统</span><br><span class="line">    FileSystem fs = getFileSystem();</span><br><span class="line">    // 2 创建文件夹</span><br><span class="line">    try &#123;</span><br><span class="line">        fs.mkdirs(new Path(&quot;/user/intflag/test&quot;));</span><br><span class="line">    &#125; catch (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">        // 3 关闭资源</span><br><span class="line">        closeFileSystem(fs);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="2-5-HDFS文件夹删除"><a href="#2-5-HDFS文件夹删除" class="headerlink" title="2.5 HDFS文件夹删除"></a>2.5 HDFS文件夹删除</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * 删除HDFS上的文件夹</span><br><span class="line"> */</span><br><span class="line">@Test</span><br><span class="line">public void deleteDirAtHDFS() &#123;</span><br><span class="line">    // 1 获取文件系统</span><br><span class="line">    FileSystem fs = getFileSystem();</span><br><span class="line">    // 2 删除文件夹</span><br><span class="line">    try &#123;</span><br><span class="line">        //fs.delete(new Path(&quot;/user/intflag/test&quot;));</span><br><span class="line">        fs.delete(new Path(&quot;/user/intflag/test&quot;),true);</span><br><span class="line">    &#125; catch (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">        // 3 关闭资源</span><br><span class="line">        closeFileSystem(fs);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="2-6-HDFS文件名更改"><a href="#2-6-HDFS文件名更改" class="headerlink" title="2.6 HDFS文件名更改"></a>2.6 HDFS文件名更改</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * 重命名HDFS上的文件夹</span><br><span class="line"> */</span><br><span class="line">@Test</span><br><span class="line">public void renameDirAtHDFS() &#123;</span><br><span class="line">    // 1 获取文件系统</span><br><span class="line">    FileSystem fs = getFileSystem();</span><br><span class="line">    // 2 重命名文件夹</span><br><span class="line">    try &#123;</span><br><span class="line">        fs.rename(new Path(&quot;/user/intflag/test&quot;), new Path(&quot;/user/intflag/test22&quot;));</span><br><span class="line">    &#125; catch (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">        // 3 关闭资源</span><br><span class="line">        closeFileSystem(fs);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="2-7-HDFS文件详情查看"><a href="#2-7-HDFS文件详情查看" class="headerlink" title="2.7 HDFS文件详情查看"></a>2.7 HDFS文件详情查看</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * 读取HDFS上的文件信息</span><br><span class="line"> */</span><br><span class="line">@Test</span><br><span class="line">public void readFileAtHDFS() &#123;</span><br><span class="line">    // 1 获取文件系统</span><br><span class="line">    FileSystem fs = getFileSystem();</span><br><span class="line">    // 2 读取文件信息</span><br><span class="line">    try &#123;</span><br><span class="line">        RemoteIterator&lt;LocatedFileStatus&gt; listFiles = fs.listFiles(new Path(&quot;/&quot;), true);</span><br><span class="line">        while (listFiles.hasNext()) &#123;</span><br><span class="line">            LocatedFileStatus status = listFiles.next();</span><br><span class="line">            System.out.println(&quot;-----------------------------------&quot;);</span><br><span class="line">            System.out.println(&quot;文件名称：&quot;+status.getPath().getName());</span><br><span class="line">            System.out.println(&quot;块的大小：&quot;+status.getBlockSize());</span><br><span class="line">            System.out.println(&quot;内容长度：&quot;+status.getLen());</span><br><span class="line">            System.out.println(&quot;文件权限：&quot;+status.getPermission());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; catch (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">        // 3 关闭资源</span><br><span class="line">        closeFileSystem(fs);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">-----------------------------------</span><br><span class="line">文件名称：asd.txt</span><br><span class="line">块的大小：134217728</span><br><span class="line">内容长度：34</span><br><span class="line">文件权限：rw-r--r--</span><br><span class="line">-----------------------------------</span><br><span class="line">文件名称：hadoop-2.7.2.tar.gz</span><br><span class="line">块的大小：134217728</span><br><span class="line">内容长度：197657687</span><br><span class="line">文件权限：rw-r--r--</span><br><span class="line">-----------------------------------</span><br><span class="line">文件名称：liugx.txt</span><br><span class="line">块的大小：134217728</span><br><span class="line">内容长度：64</span><br><span class="line">文件权限：rw-r--r--</span><br><span class="line">-----------------------------------</span><br><span class="line">文件名称：x3.000</span><br><span class="line">块的大小：134217728</span><br><span class="line">内容长度：592</span><br><span class="line">文件权限：rw-r--r--</span><br><span class="line"></span><br><span class="line">Process finished with exit code 0</span><br></pre></td></tr></table></figure><h5 id="2-8-HDFS文件夹查看"><a href="#2-8-HDFS文件夹查看" class="headerlink" title="2.8 HDFS文件夹查看"></a>2.8 HDFS文件夹查看</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * 读取文件夹信息</span><br><span class="line"> */</span><br><span class="line">@Test</span><br><span class="line">public void readFfolderAtHDFS() &#123;</span><br><span class="line">    // 1 获取文件系统</span><br><span class="line">    FileSystem fs = getFileSystem();</span><br><span class="line">    // 2 读取文件夹信息</span><br><span class="line">    try &#123;</span><br><span class="line">        FileStatus[] listStatus = fs.listStatus(new Path(&quot;/user/intflag/&quot;));</span><br><span class="line">        for (FileStatus status : listStatus) &#123;</span><br><span class="line">            if (status.isFile()) &#123;</span><br><span class="line">                System.out.println(&quot;f----&quot;+status.getPath().getName());</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                System.out.println(&quot;d----&quot;+status.getPath().getName());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; catch (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">        // 3 关闭资源</span><br><span class="line">        closeFileSystem(fs);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="3-通过IO流操作HDFS"><a href="#3-通过IO流操作HDFS" class="headerlink" title="3 通过IO流操作HDFS"></a>3 通过IO流操作HDFS</h4><h5 id="3-1-HDFS文件上传"><a href="#3-1-HDFS文件上传" class="headerlink" title="3.1 HDFS文件上传"></a>3.1 HDFS文件上传</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * 文件上传到HDFS</span><br><span class="line"> */</span><br><span class="line">@Test</span><br><span class="line">public void putFileToHDFS() &#123;</span><br><span class="line">    // 1 获取HDFS</span><br><span class="line">    FileSystem fs = getFileSystem();</span><br><span class="line"></span><br><span class="line">    try &#123;</span><br><span class="line">        // 2 获取输出流</span><br><span class="line">        FSDataOutputStream fos = fs.create(new Path(&quot;/user/intflag/input/x3.000&quot;));</span><br><span class="line">        // 3 获取输入流</span><br><span class="line">        FileInputStream fis = new FileInputStream(new File(&quot;D:/test/x3.000&quot;));</span><br><span class="line">        // 4 流对接</span><br><span class="line">        IOUtils.copyBytes(fis, fos, new Configuration());</span><br><span class="line">        // 5 关闭流</span><br><span class="line">        IOUtils.closeStream(fis);</span><br><span class="line">        IOUtils.closeStream(fos);</span><br><span class="line">    &#125; catch (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">        // 5 关闭资源</span><br><span class="line">        closeFileSystem(fs);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="3-2-HDFS文件下载"><a href="#3-2-HDFS文件下载" class="headerlink" title="3.2 HDFS文件下载"></a>3.2 HDFS文件下载</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * 下载文件</span><br><span class="line"> */</span><br><span class="line">@Test</span><br><span class="line">public void getFileFromHDFS() &#123;</span><br><span class="line">    // 1 获取HDFS</span><br><span class="line">    FileSystem fs = getFileSystem();</span><br><span class="line"></span><br><span class="line">    try &#123;</span><br><span class="line">        // 2 获取输入流</span><br><span class="line">        FSDataInputStream fis = fs.open(new Path(&quot;/user/intflag/input/liugx.txt&quot;));</span><br><span class="line"></span><br><span class="line">        // 3 获取输出流</span><br><span class="line">        FileOutputStream fos = new FileOutputStream(new File(&quot;D:/test/liugx.txt&quot;));</span><br><span class="line"></span><br><span class="line">        // 4 流对接</span><br><span class="line">        IOUtils.copyBytes(fis, fos, new Configuration());</span><br><span class="line">        // 5 关闭流</span><br><span class="line">        IOUtils.closeStream(fis);</span><br><span class="line">        IOUtils.closeStream(fos);</span><br><span class="line">    &#125; catch (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">        // 5 关闭资源</span><br><span class="line">        closeFileSystem(fs);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="3-3-定位文件读取"><a href="#3-3-定位文件读取" class="headerlink" title="3.3 定位文件读取"></a>3.3 定位文件读取</h5><p>下载第一块</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * 下载大文件-下载第一块</span><br><span class="line"> */</span><br><span class="line">@Test</span><br><span class="line">public void getFileFromHDFSSeek1() &#123;</span><br><span class="line">    // 1 获取HDFS</span><br><span class="line">    FileSystem fs = getFileSystem();</span><br><span class="line"></span><br><span class="line">    try &#123;</span><br><span class="line">        // 2 获取输入流</span><br><span class="line">        FSDataInputStream fis = fs.open(new Path(&quot;/user/intflag/input/hadoop-2.7.2.tar.gz&quot;));</span><br><span class="line"></span><br><span class="line">        // 3 获取输出流</span><br><span class="line">        FileOutputStream fos = new FileOutputStream(new File(&quot;D:/test/hadoop-2.7.2.tar.gz.part1&quot;));</span><br><span class="line"></span><br><span class="line">        // 4 流对接（只读取128m）</span><br><span class="line">        byte[] buff = new byte[1024];</span><br><span class="line">        //1024 * 1024 * 128</span><br><span class="line">        int len = 1024 * 128;</span><br><span class="line">        for (int i = 0; i &lt; len; i++) &#123;</span><br><span class="line">            fis.read(buff);</span><br><span class="line">            fos.write(buff);</span><br><span class="line">        &#125;</span><br><span class="line">        // 5 关闭流</span><br><span class="line">        IOUtils.closeStream(fis);</span><br><span class="line">        IOUtils.closeStream(fos);</span><br><span class="line">    &#125; catch (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">        // 5 关闭资源</span><br><span class="line">        closeFileSystem(fs);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>下载第二块</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * 下载大文件-下载第二块</span><br><span class="line"> */</span><br><span class="line">@Test</span><br><span class="line">public void getFileFromHDFSSeek2() &#123;</span><br><span class="line">    // 1 获取HDFS</span><br><span class="line">    FileSystem fs = getFileSystem();</span><br><span class="line"></span><br><span class="line">    try &#123;</span><br><span class="line">        // 2 获取输入流</span><br><span class="line">        FSDataInputStream fis = fs.open(new Path(&quot;/user/intflag/input/hadoop-2.7.2.tar.gz&quot;));</span><br><span class="line"></span><br><span class="line">        // 3 获取输出流</span><br><span class="line">        FileOutputStream fos = new FileOutputStream(new File(&quot;D:/test/hadoop-2.7.2.tar.gz.part2&quot;));</span><br><span class="line"></span><br><span class="line">        // 4 流对接（只读取128m）</span><br><span class="line">        // 定位到128m</span><br><span class="line">        int len = 1024 * 1024 * 128;</span><br><span class="line">        fis.seek(len);</span><br><span class="line">        IOUtils.copyBytes(fis,fos,new Configuration());</span><br><span class="line"></span><br><span class="line">        // 5 关闭流</span><br><span class="line">        IOUtils.closeStream(fis);</span><br><span class="line">        IOUtils.closeStream(fos);</span><br><span class="line">    &#125; catch (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">        // 5 关闭资源</span><br><span class="line">        closeFileSystem(fs);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>合并文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">打开DOS窗口，定位到下载后的位置，输入以下命令合并文件</span><br><span class="line">type hadoop-2.7.2.tar.gz.part2 &gt;&gt; hadoop-2.7.2.tar.gz.part1</span><br><span class="line">然后重命名文件hadoop-2.7.2.tar.gz.part1，将文件.part1去掉</span><br><span class="line">打开文件验证</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;本人微信公众号，欢迎扫码关注！&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;http://images.intflag.com/bigdata002.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;HDFS客户端操作&quot;&gt;&lt;a h
      
    
    </summary>
    
      <category term="Hadoop" scheme="http://yoursite.com/categories/Hadoop/"/>
    
    
      <category term="Hadoop" scheme="http://yoursite.com/tags/Hadoop/"/>
    
      <category term="HDFS" scheme="http://yoursite.com/tags/HDFS/"/>
    
      <category term="HDFS客户端" scheme="http://yoursite.com/tags/HDFS%E5%AE%A2%E6%88%B7%E7%AB%AF/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop系列006-HDFS概念及命令行操作</title>
    <link href="http://yoursite.com/Hadoop%E7%B3%BB%E5%88%97006-HDFS%E6%A6%82%E5%BF%B5%E5%8F%8A%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%93%8D%E4%BD%9C.html"/>
    <id>http://yoursite.com/Hadoop系列006-HDFS概念及命令行操作.html</id>
    <published>2018-12-03T06:14:06.000Z</published>
    <updated>2018-12-03T06:14:06.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本人微信公众号，欢迎扫码关注！</p></blockquote><p><img src="http://images.intflag.com/bigdata002.jpg" alt=""></p><h2 id="HDFS概念及命令行操作"><a href="#HDFS概念及命令行操作" class="headerlink" title="HDFS概念及命令行操作"></a>HDFS概念及命令行操作</h2><h3 id="一、HDFS概念"><a href="#一、HDFS概念" class="headerlink" title="一、HDFS概念"></a>一、HDFS概念</h3><h4 id="1-1-概念"><a href="#1-1-概念" class="headerlink" title="1.1 概念"></a>1.1 概念</h4><p>HDFS，它是一个文件系统，用于存储文件，通过目录树来定位文件；其次，它是分布式的，由很多服务器联合起来实现其功能，集群中的服务器有各自的角色。</p><p>HDFS的设计适合一次写入，多次读出的场景，且不支持文件的修改。适合用来做数据分析，并不适合用来做网盘应用。</p><h4 id="1-2-组成"><a href="#1-2-组成" class="headerlink" title="1.2 组成"></a>1.2 组成</h4><p>1）HDFS集群包括，NameNode和DataNode以及Secondary Namenode。</p><p>2）NameNode负责管理整个文件系统的元数据，以及每一个路径（文件）所对应的数据块信息。</p><p>3）DataNode 负责管理用户的文件数据块，每一个数据块都可以在多个datanode上存储多个副本。</p><p>4）Secondary NameNode用来监控HDFS状态的辅助后台程序，每隔一段时间获取HDFS元数据的快照。</p><h4 id="1-3-HDFS-文件块大小"><a href="#1-3-HDFS-文件块大小" class="headerlink" title="1.3 HDFS 文件块大小"></a>1.3 HDFS 文件块大小</h4><ul><li><p>HDFS中的文件在物理上是分块存储（block），块的大小可以通过配置参数( dfs.blocksize)来规定，默认大小在hadoop2.x版本中是128M，老版本中是64M</p></li><li><p>HDFS的块比磁盘的块大，其目的是为了最小化寻址开销。如果块设置得足够大，从磁盘传输数据的时间会明显大于定位这个块开始位置所需的时间。因而，传输一个由多个块组成的文件的时间取决于磁盘传输速率。</p></li><li><p>如果寻址时间约为10ms，而传输速率为100MB/s，为了使寻址时间仅占传输时间的1%，我们要将块大小设置约为100MB。默认的块大小实际为64MB，但是很多情况下HDFS使用128MB的块设置。</p></li><li><p>块的大小：10ms x 100 x 100M/s = 100M</p></li></ul><p><img src="http://images.intflag.com/HDFS001.jpg" alt="计算规则"></p><h3 id="二、HFDS命令行操作"><a href="#二、HFDS命令行操作" class="headerlink" title="二、HFDS命令行操作"></a>二、HFDS命令行操作</h3><h4 id="2-1-基本语法"><a href="#2-1-基本语法" class="headerlink" title="2.1 基本语法"></a>2.1 基本语法</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hadoop fs 具体命令</span><br></pre></td></tr></table></figure><h4 id="2-2-参数大全"><a href="#2-2-参数大全" class="headerlink" title="2.2 参数大全"></a>2.2 参数大全</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">bin/hadoop fs</span><br><span class="line">[-appendToFile &lt;localsrc&gt; ... &lt;dst&gt;]</span><br><span class="line">        [-cat [-ignoreCrc] &lt;src&gt; ...]</span><br><span class="line">        [-checksum &lt;src&gt; ...]</span><br><span class="line">        [-chgrp [-R] GROUP PATH...]</span><br><span class="line">        [-chmod [-R] &lt;MODE[,MODE]... | OCTALMODE&gt; PATH...]</span><br><span class="line">        [-chown [-R] [OWNER][:[GROUP]] PATH...]</span><br><span class="line">        [-copyFromLocal [-f] [-p] &lt;localsrc&gt; ... &lt;dst&gt;]</span><br><span class="line">        [-copyToLocal [-p] [-ignoreCrc] [-crc] &lt;src&gt; ... &lt;localdst&gt;]</span><br><span class="line">        [-count [-q] &lt;path&gt; ...]</span><br><span class="line">        [-cp [-f] [-p] &lt;src&gt; ... &lt;dst&gt;]</span><br><span class="line">        [-createSnapshot &lt;snapshotDir&gt; [&lt;snapshotName&gt;]]</span><br><span class="line">        [-deleteSnapshot &lt;snapshotDir&gt; &lt;snapshotName&gt;]</span><br><span class="line">        [-df [-h] [&lt;path&gt; ...]]</span><br><span class="line">        [-du [-s] [-h] &lt;path&gt; ...]</span><br><span class="line">        [-expunge]</span><br><span class="line">        [-get [-p] [-ignoreCrc] [-crc] &lt;src&gt; ... &lt;localdst&gt;]</span><br><span class="line">        [-getfacl [-R] &lt;path&gt;]</span><br><span class="line">        [-getmerge [-nl] &lt;src&gt; &lt;localdst&gt;]</span><br><span class="line">        [-help [cmd ...]]</span><br><span class="line">        [-ls [-d] [-h] [-R] [&lt;path&gt; ...]]</span><br><span class="line">        [-mkdir [-p] &lt;path&gt; ...]</span><br><span class="line">        [-moveFromLocal &lt;localsrc&gt; ... &lt;dst&gt;]</span><br><span class="line">        [-moveToLocal &lt;src&gt; &lt;localdst&gt;]</span><br><span class="line">        [-mv &lt;src&gt; ... &lt;dst&gt;]</span><br><span class="line">        [-put [-f] [-p] &lt;localsrc&gt; ... &lt;dst&gt;]</span><br><span class="line">        [-renameSnapshot &lt;snapshotDir&gt; &lt;oldName&gt; &lt;newName&gt;]</span><br><span class="line">        [-rm [-f] [-r|-R] [-skipTrash] &lt;src&gt; ...]</span><br><span class="line">        [-rmdir [--ignore-fail-on-non-empty] &lt;dir&gt; ...]</span><br><span class="line">        [-setfacl [-R] [&#123;-b|-k&#125; &#123;-m|-x &lt;acl_spec&gt;&#125; &lt;path&gt;]|[--set &lt;acl_spec&gt; &lt;path&gt;]]</span><br><span class="line">        [-setrep [-R] [-w] &lt;rep&gt; &lt;path&gt; ...]</span><br><span class="line">        [-stat [format] &lt;path&gt; ...]</span><br><span class="line">        [-tail [-f] &lt;file&gt;]</span><br><span class="line">        [-test -[defsz] &lt;path&gt;]</span><br><span class="line">        [-text [-ignoreCrc] &lt;src&gt; ...]</span><br><span class="line">        [-touchz &lt;path&gt; ...]</span><br><span class="line">        [-usage [cmd ...]]</span><br></pre></td></tr></table></figure><h4 id="3-3-常用命令实操"><a href="#3-3-常用命令实操" class="headerlink" title="3.3 常用命令实操"></a>3.3 常用命令实操</h4><h5 id="（1）-help：输出这个命令参数"><a href="#（1）-help：输出这个命令参数" class="headerlink" title="（1）-help：输出这个命令参数"></a>（1）-help：输出这个命令参数</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hdfs dfs -help rm</span><br></pre></td></tr></table></figure><h5 id="（2）-ls-显示目录信息"><a href="#（2）-ls-显示目录信息" class="headerlink" title="（2）-ls: 显示目录信息"></a>（2）-ls: 显示目录信息</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -ls /</span><br></pre></td></tr></table></figure><h5 id="（3）-mkdir：在hdfs上创建目录"><a href="#（3）-mkdir：在hdfs上创建目录" class="headerlink" title="（3）-mkdir：在hdfs上创建目录"></a>（3）-mkdir：在hdfs上创建目录</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs  -mkdir  -p  /aaa/bbb/cc/dd</span><br></pre></td></tr></table></figure><h5 id="（4）-moveFromLocal从本地剪切粘贴到hdfs"><a href="#（4）-moveFromLocal从本地剪切粘贴到hdfs" class="headerlink" title="（4）-moveFromLocal从本地剪切粘贴到hdfs"></a>（4）-moveFromLocal从本地剪切粘贴到hdfs</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop  fs  - moveFromLocal  /home/hadoop/a.txt  /aaa/bbb/cc/dd</span><br></pre></td></tr></table></figure><h5 id="（5）-moveToLocal：从hdfs剪切粘贴到本地"><a href="#（5）-moveToLocal：从hdfs剪切粘贴到本地" class="headerlink" title="（5）-moveToLocal：从hdfs剪切粘贴到本地"></a>（5）-moveToLocal：从hdfs剪切粘贴到本地</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop  fs  - moveToLocal   /aaa/bbb/cc/dd  /home/hadoop/a.txt</span><br></pre></td></tr></table></figure><h5 id="（6）-appendToFile-：追加一个文件到已经存在的文件末尾"><a href="#（6）-appendToFile-：追加一个文件到已经存在的文件末尾" class="headerlink" title="（6）-appendToFile  ：追加一个文件到已经存在的文件末尾"></a>（6）-appendToFile  ：追加一个文件到已经存在的文件末尾</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop  fs  -appendToFile  ./hello.txt  /hello.txt</span><br></pre></td></tr></table></figure><h5 id="（7）-cat-：显示文件内容"><a href="#（7）-cat-：显示文件内容" class="headerlink" title="（7）-cat ：显示文件内容"></a>（7）-cat ：显示文件内容</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -cat /user/intflag/input/liugx.txt</span><br></pre></td></tr></table></figure><h5 id="（8）-tail：显示一个文件的末尾"><a href="#（8）-tail：显示一个文件的末尾" class="headerlink" title="（8）-tail：显示一个文件的末尾"></a>（8）-tail：显示一个文件的末尾</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop  fs  -tail  /weblog/access_log.1</span><br></pre></td></tr></table></figure><h5 id="（9）-text：以字符形式打印一个文件的内容"><a href="#（9）-text：以字符形式打印一个文件的内容" class="headerlink" title="（9）-text：以字符形式打印一个文件的内容"></a>（9）-text：以字符形式打印一个文件的内容</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop  fs  -text  /weblog/access_log.1</span><br></pre></td></tr></table></figure><h5 id="（10）-chgrp-、-chmod、-chown：linux文件系统中的用法一样，修改文件所属权限"><a href="#（10）-chgrp-、-chmod、-chown：linux文件系统中的用法一样，修改文件所属权限" class="headerlink" title="（10）-chgrp 、-chmod、-chown：linux文件系统中的用法一样，修改文件所属权限"></a>（10）-chgrp 、-chmod、-chown：linux文件系统中的用法一样，修改文件所属权限</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop  fs  -chmod  666  /hello.txt</span><br><span class="line">hadoop  fs  -chown  someuser:somegrp   /hello.txt</span><br></pre></td></tr></table></figure><h5 id="（11）-copyFromLocal：从本地文件系统中拷贝文件到hdfs路径去"><a href="#（11）-copyFromLocal：从本地文件系统中拷贝文件到hdfs路径去" class="headerlink" title="（11）-copyFromLocal：从本地文件系统中拷贝文件到hdfs路径去"></a>（11）-copyFromLocal：从本地文件系统中拷贝文件到hdfs路径去</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop  fs  -copyFromLocal  ./jdk.tar.gz  /aaa/</span><br></pre></td></tr></table></figure><h5 id="（12）-copyToLocal：从hdfs拷贝到本地"><a href="#（12）-copyToLocal：从hdfs拷贝到本地" class="headerlink" title="（12）-copyToLocal：从hdfs拷贝到本地"></a>（12）-copyToLocal：从hdfs拷贝到本地</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -copyToLocal /aaa/jdk.tar.gz</span><br></pre></td></tr></table></figure><h5 id="（13）-cp-：从hdfs的一个路径拷贝到hdfs的另一个路径"><a href="#（13）-cp-：从hdfs的一个路径拷贝到hdfs的另一个路径" class="headerlink" title="（13）-cp ：从hdfs的一个路径拷贝到hdfs的另一个路径"></a>（13）-cp ：从hdfs的一个路径拷贝到hdfs的另一个路径</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop  fs  -cp  /aaa/jdk.tar.gz  /bbb/jdk.tar.gz.2</span><br></pre></td></tr></table></figure><h5 id="（14）-mv：在hdfs目录中移动文件"><a href="#（14）-mv：在hdfs目录中移动文件" class="headerlink" title="（14）-mv：在hdfs目录中移动文件"></a>（14）-mv：在hdfs目录中移动文件</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop  fs  -mv  /aaa/jdk.tar.gz  /</span><br></pre></td></tr></table></figure><h5 id="（15）-get：等同于copyToLocal，就是从hdfs下载文件到本地"><a href="#（15）-get：等同于copyToLocal，就是从hdfs下载文件到本地" class="headerlink" title="（15）-get：等同于copyToLocal，就是从hdfs下载文件到本地"></a>（15）-get：等同于copyToLocal，就是从hdfs下载文件到本地</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">（15）-get：等同于copyToLocal，就是从hdfs下载文件到本地</span><br></pre></td></tr></table></figure><h5 id="（16）-getmerge-：合并下载多个文件，比如hdfs的目录-aaa-下有多个文件-log-1-log-2-log-3-…"><a href="#（16）-getmerge-：合并下载多个文件，比如hdfs的目录-aaa-下有多个文件-log-1-log-2-log-3-…" class="headerlink" title="（16）-getmerge  ：合并下载多个文件，比如hdfs的目录 /aaa/下有多个文件:log.1, log.2,log.3,…"></a>（16）-getmerge  ：合并下载多个文件，比如hdfs的目录 /aaa/下有多个文件:log.1, log.2,log.3,…</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -getmerge /aaa/log.* ./log.sum</span><br></pre></td></tr></table></figure><h5 id="（17）-put：等同于copyFromLocal"><a href="#（17）-put：等同于copyFromLocal" class="headerlink" title="（17）-put：等同于copyFromLocal"></a>（17）-put：等同于copyFromLocal</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop  fs  -put  /aaa/jdk.tar.gz  /bbb/jdk.tar.gz.2</span><br></pre></td></tr></table></figure><h5 id="（18）-rm：删除文件或文件夹"><a href="#（18）-rm：删除文件或文件夹" class="headerlink" title="（18）-rm：删除文件或文件夹"></a>（18）-rm：删除文件或文件夹</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -rm -r /aaa/bbb/</span><br></pre></td></tr></table></figure><h5 id="（19）-rmdir：删除空目录"><a href="#（19）-rmdir：删除空目录" class="headerlink" title="（19）-rmdir：删除空目录"></a>（19）-rmdir：删除空目录</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop  fs  -rmdir   /aaa/bbb/ccc</span><br></pre></td></tr></table></figure><h5 id="（20）-df-：统计文件系统的可用空间信息"><a href="#（20）-df-：统计文件系统的可用空间信息" class="headerlink" title="（20）-df ：统计文件系统的可用空间信息"></a>（20）-df ：统计文件系统的可用空间信息</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop  fs  -df  -h  /</span><br></pre></td></tr></table></figure><h5 id="（21）-du统计文件夹的大小信息"><a href="#（21）-du统计文件夹的大小信息" class="headerlink" title="（21）-du统计文件夹的大小信息"></a>（21）-du统计文件夹的大小信息</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop  fs  -du  -s  -h /aaa/*</span><br></pre></td></tr></table></figure><h5 id="（22）-count：统计一个指定目录下的文件节点数量"><a href="#（22）-count：统计一个指定目录下的文件节点数量" class="headerlink" title="（22）-count：统计一个指定目录下的文件节点数量"></a>（22）-count：统计一个指定目录下的文件节点数量</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -count /aaa/</span><br></pre></td></tr></table></figure><h5 id="（23）-setrep：设置hdfs中文件的副本数量"><a href="#（23）-setrep：设置hdfs中文件的副本数量" class="headerlink" title="（23）-setrep：设置hdfs中文件的副本数量"></a>（23）-setrep：设置hdfs中文件的副本数量</h5><p><strong>注意：这里设置的副本数只是记录在namenode的元数据中，是否真的会有这么多副本，还得看datanode的数量。因为目前只有3台设备，最多也就3个副本，只有节点数的增加到10台时，副本数才能达到10。</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -setrep 3 /aaa/jdk.tar.gz</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;本人微信公众号，欢迎扫码关注！&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;http://images.intflag.com/bigdata002.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;HDFS概念及命令行操作&quot;&gt;&lt;
      
    
    </summary>
    
      <category term="Hadoop" scheme="http://yoursite.com/categories/Hadoop/"/>
    
    
      <category term="Hadoop" scheme="http://yoursite.com/tags/Hadoop/"/>
    
      <category term="HDFS" scheme="http://yoursite.com/tags/HDFS/"/>
    
      <category term="文件系统" scheme="http://yoursite.com/tags/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop系列005-Hadoop运行模式（下）</title>
    <link href="http://yoursite.com/Hadoop%E7%B3%BB%E5%88%97005-Hadoop%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F%EF%BC%88%E4%B8%8B%EF%BC%89.html"/>
    <id>http://yoursite.com/Hadoop系列005-Hadoop运行模式（下）.html</id>
    <published>2018-11-22T07:21:15.000Z</published>
    <updated>2018-11-22T07:21:15.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本人微信公众号，欢迎扫码关注！</p></blockquote><p><img src="http://images.intflag.com/bigdata002.jpg" alt=""></p><h2 id="Hadoop运行模式（下）"><a href="#Hadoop运行模式（下）" class="headerlink" title="Hadoop运行模式（下）"></a>Hadoop运行模式（下）</h2><h5 id="2-3、完全分布式部署Hadoop"><a href="#2-3、完全分布式部署Hadoop" class="headerlink" title="2.3、完全分布式部署Hadoop"></a>2.3、完全分布式部署Hadoop</h5><ul><li>1）分析：<ul><li>1）准备3台客户机（关闭防火墙、静态ip、主机名称）</li><li>2）安装jdk</li><li>3）配置环境变量</li><li>4）安装hadoop</li><li>5）配置环境变量</li><li>6）安装ssh</li><li>7）配置集群</li><li>8）启动测试集群</li></ul></li><li><p>2）操作</p><ul><li><p>（1） 虚拟机准备</p><ul><li>克隆三台干净的虚拟机</li></ul></li><li><p>（2） 主机名设置</p></li><li><p>（3） scp</p><ul><li><p>1）scp可以实现服务器与服务器之间的数据拷贝。</p></li><li><p>2）案例实操</p><ul><li><p>（1）将hadoop101中/opt/module和/opt/software文件拷贝到hadoop102、hadoop103和hadoop104上。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop101 /]# scp -r /opt/module/  root@hadoop102:/opt</span><br><span class="line">[root@hadoop101 /]# scp -r /opt/software/  root@hadoop102:/opt</span><br><span class="line">[root@hadoop101 /]# scp -r /opt/module/  root@hadoop103:/opt</span><br><span class="line">[root@hadoop101 /]# scp -r /opt/software/  root@hadoop103:/opt</span><br><span class="line">[root@hadoop101 /]# scp -r /opt/module/  root@hadoop104:/opt</span><br><span class="line">[root@hadoop101 /]# scp -r /opt/software/  root@hadoop105:/opt</span><br></pre></td></tr></table></figure></li><li><p>（2）将192.168.1.102服务器上的文件拷贝到当前用户下。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop101 opt]# scp  root@hadoop102:/etc/profile  /opt/tmp/</span><br></pre></td></tr></table></figure></li><li><p>（3）实现两台远程机器之间的文件传输（hadoop103主机文件拷贝到hadoop104主机上）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 test]$ scp atguigu@hadoop103:/opt/test/haha atguigu@hadoop104:/opt/test/</span><br></pre></td></tr></table></figure></li></ul></li></ul></li><li><p>（4）SSH无密码登录</p><ul><li><p>1）配置ssh</p><ul><li><p>（1）基本语法</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh 另一台电脑的ip地址</span><br></pre></td></tr></table></figure></li><li><p>（2）ssh连接时出现Host key verification failed的解决方法</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">问题再现</span><br><span class="line">[root@hadoop2 opt]# ssh 192.168.1.103</span><br><span class="line">The authenticity of host &apos;192.168.1.103 (192.168.1.103)&apos; can&apos;t be established.</span><br><span class="line">RSA key fingerprint is cf:1e:de:d7:d0:4c:2d:98:60:b4:fd:ae:b1:2d:ad:06.</span><br><span class="line">Are you sure you want to continue connecting (yes/no)? </span><br><span class="line">Host key verification failed.</span><br><span class="line"></span><br><span class="line">解决办法</span><br><span class="line">输入yes，然后输入目标机器的密码即可</span><br></pre></td></tr></table></figure></li></ul></li><li><p>2）无密钥配置</p><ul><li><p>（1）进入到我的home目录</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd  ~/.ssh</span><br></pre></td></tr></table></figure></li><li><p>（2）生成公钥和私钥：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa </span><br><span class="line">然后敲（三个回车），就会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）</span><br></pre></td></tr></table></figure></li><li><p>（3）将公钥拷贝到要免密登录的目标机器上</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-copy-id 目标机器主机名或IP地址</span><br></pre></td></tr></table></figure></li></ul></li><li><p>3）.ssh文件夹下的文件功能解释</p><ul><li>（1）~/.ssh/known_hosts    ：记录ssh访问过计算机的公钥(public key)</li><li>（2）id_rsa    ：生成的私钥</li><li>（3）id_rsa.pub    ：生成的公钥</li><li>（4）authorized_keys    ：存放授权过得无秘登录服务器公钥</li></ul></li></ul></li><li><p>（5）rsync</p><p>rsync远程同步工具，主要用于备份和镜像。具有速度快、避免复制相同内容和支持符号链接的优点。</p><ul><li><p>1）查看rsync使用说明</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">man rsync | more</span><br></pre></td></tr></table></figure></li><li><p>2）基本语法</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rsync  -rvl                 $pdir/$fname                       $user@hadoop$host:$pdir</span><br><span class="line">命令   命令参数   要拷贝的文件路径/名称   目的用户@主机:目的路径</span><br></pre></td></tr></table></figure></li><li><p>3）案例实操</p><p>把本机/opt/tmp目录同步到hadoop103服务器的root用户下的/opt/tmp目录</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rsync –rvl /opt/tmp/*  root@hadoop103:/opt/tmp</span><br></pre></td></tr></table></figure></li></ul></li><li><p>（6）编写集群分发脚本xsync</p><ul><li><p>1）需求分析：循环复制文件到所有节点的相同目录下。</p><ul><li><p>（1）原始拷贝：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rsync  –rvl     /opt/module  root@hadoop103:/opt/</span><br></pre></td></tr></table></figure></li><li><p>（2）期望脚本：</p><p>xsync 要同步的文件名称</p></li><li><p>（3）在/usr/local/bin这个目录下存放的脚本，可以在系统任何地方直接执行，需要制定路径。</p></li></ul></li><li><p>2）案例实操：</p><ul><li><p>（1）在/usr/local/bin目录下创建xsync文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">#1 获取输入参数个数，如果没有参数，直接退出</span><br><span class="line">pcount=$#</span><br><span class="line">if((pcount==0)); then</span><br><span class="line">echo no args;</span><br><span class="line">exit;</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">#2 获取文件名称</span><br><span class="line">p1=$1</span><br><span class="line">fname=`basename $p1`</span><br><span class="line">echo fname=$fname</span><br><span class="line"></span><br><span class="line">#3 获取上级目录到绝对路径</span><br><span class="line">pdir=`cd -P $(dirname $p1); pwd`</span><br><span class="line">echo pdir=$pdir</span><br><span class="line"></span><br><span class="line">#4 获取当前用户名称</span><br><span class="line">user=`whoami`</span><br><span class="line"></span><br><span class="line">#5 循环</span><br><span class="line">for((host=103; host&lt;105; host++)); do</span><br><span class="line">        #echo $pdir/$fname $user@hadoop$host:$pdir</span><br><span class="line">        echo --------------- hadoop$host ----------------</span><br><span class="line">        rsync -rvl $pdir/$fname $user@hadoop$host:$pdir</span><br><span class="line">done</span><br></pre></td></tr></table></figure></li><li><p>（2）修改脚本 xsync 具有执行权限</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 bin]# chmod 777 xsync</span><br></pre></td></tr></table></figure></li><li><p>（3）调用脚本形式：xsync 文件名称</p></li></ul></li></ul></li><li><p>（7）编写分发脚本xcall</p><ul><li><p>1）需求分析：在所有主机上同时执行相同的命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xcall +命令</span><br></pre></td></tr></table></figure></li><li><p>2）具体实现</p><ul><li><p>（1）在/usr/local/bin目录下创建xcall文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">pcount=$#</span><br><span class="line">if((pcount==0));then</span><br><span class="line">        echo no args;</span><br><span class="line">        exit;</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">echo -------------localhost----------</span><br><span class="line">$@</span><br><span class="line">for((host=101; host&lt;=108; host++)); do</span><br><span class="line">        echo ----------hadoop$host---------</span><br><span class="line">        ssh hadoop$host $@</span><br><span class="line">done</span><br></pre></td></tr></table></figure></li><li><p>（2）修改脚本 xcall 具有执行权限</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 bin]# chmod 777 xcall</span><br></pre></td></tr></table></figure></li><li><p>（3）调用脚本形式： xcall 操作命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop102 ~]# xcall rm -rf /opt/tmp/profile</span><br></pre></td></tr></table></figure></li></ul></li></ul></li><li><p>（8） 基于伪分布式部署集群</p><ul><li><p>1）集群部署规划</p><p><strong>规划原则：尽量将耗内存的任务分散开来</strong></p><p>|          | Hadoop102   | Hadoop103       | Hadoop104         |<br>| ——– | ———– | ————— | —————– |<br>| <strong>HDFS</strong> | NameNode    |                 | SecondaryNameNode |<br>|          | DataNode    | DataNode        | DataNode          |<br>| <strong>YARN</strong> |             | ResourceManager |                   |<br>|          | NodeManager | NodeManager     | NodeManager       |</p></li><li><p>2）配置文件</p><ul><li><p>（1）core-site.xml</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 指定HDFS中NameNode的地址 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">&lt;value&gt;hdfs://hadoop102:8020&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 指定hadoop运行时产生文件的存储目录 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">&lt;value&gt;/opt/module/hadoop-2.7.2/data/tmp&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></li><li><p>（2）Hdfs</p><ul><li><p>hadoop-env.sh</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/module/jdk1.7.0_79</span><br></pre></td></tr></table></figure></li><li><p>hdfs-site.xml</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">&lt;value&gt;3&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">          </span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;</span><br><span class="line">&lt;value&gt;hadoop104:50090&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></li><li><p>slaves</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop102</span><br><span class="line">hadoop103</span><br><span class="line">hadoop104</span><br></pre></td></tr></table></figure></li></ul></li><li><p>（3）yarn</p><ul><li><p>yarn-env.sh</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/module/jdk1.7.0_79</span><br></pre></td></tr></table></figure></li><li><p>yarn-site.xml</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- Site specific YARN configuration properties --&gt;</span><br><span class="line">&lt;!-- reducer获取数据的方式 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">&lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">          </span><br><span class="line">&lt;!-- 指定YARN的ResourceManager的地址 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</span><br><span class="line">&lt;value&gt;hadoop103&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>（4）mapreduce</p><ul><li><p>mapred-env.sh</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/module/jdk1.7.0_79</span><br></pre></td></tr></table></figure></li><li><p>mapred-site.xml</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 指定mr运行在yarn上 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></li></ul></li></ul></li><li><p>3）在集群上分发以上所有文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/module/hadoop-2.7.2/etc</span><br><span class="line">xsync hadoop/</span><br></pre></td></tr></table></figure></li><li><p>4）查看文件分发情况</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xcall cat /opt/module/hadoop-2.7.2/etc/hadoop/slaves</span><br></pre></td></tr></table></figure></li></ul></li><li><p>（9）集群启动及测试</p><ul><li><p>1）启动集群</p><ul><li><p>（0）如果集群是第一次启动，需要格式化namenode</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop2 hadoop-2.7.2]# bin/hdfs namenode –format</span><br></pre></td></tr></table></figure></li><li><p>（1）启动HDFS</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[intflag@hadoop102 hadoop-2.7.2]$ sbin/start-dfs.sh</span><br><span class="line"></span><br><span class="line">启动之后验证</span><br><span class="line">[intflag@hadoop102 hadoop-2.7.2]$ jps</span><br><span class="line">3690 DataNode</span><br><span class="line">9550 Jps</span><br><span class="line">3583 NameNode</span><br><span class="line"></span><br><span class="line">[intflag@hadoop103 hadoop-2.7.2]$ jps</span><br><span class="line">9095 Jps</span><br><span class="line">3435 DataNode</span><br><span class="line"></span><br><span class="line">[intflag@hadoop104 hadoop-2.7.2]$ jps</span><br><span class="line">3432 DataNode</span><br><span class="line">9371 Jps</span><br><span class="line">3518 SecondaryNameNode</span><br></pre></td></tr></table></figure></li><li><p>（2）启动yarn</p><p><strong>注意：Namenode和ResourceManger如果不是同一台机器，不能在NameNode上启动 yarn，应该在ResouceManager所在的机器上启动yarn。</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/start-yarn.sh</span><br></pre></td></tr></table></figure></li></ul></li><li><p>2）集群基本测试</p><ul><li><p>（1）上传文件到集群</p><ul><li><p>上传小文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bin/hdfs dfs –mkdir –p /user/atguigu/tmp/conf</span><br><span class="line">bin/hdfs dfs –put etc/hadoop/*-site.xml /user/atguigu/tmp/conf</span><br></pre></td></tr></table></figure></li><li><p>上传大文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop-2.7.2]$ bin/hadoop fs -put /opt/software/hadoop-2.7.2.tar.gz  /user/atguigu/input</span><br></pre></td></tr></table></figure></li></ul></li><li><p>（2）上传文件后查看文件存放在什么位置</p><ul><li><p>文件存储路径</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop103 subdir0]$ pwd</span><br><span class="line">/opt/module/hadoop-2.7.2/data/tmp/dfs/data/current/BP-938951106-192.168.10.107-1495462844069/current/finalized/subdir0/subdir0</span><br></pre></td></tr></table></figure></li><li><p>查看文件内容</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop108 subdir0]$ cat blk_1073741825</span><br><span class="line">hadoop</span><br><span class="line">atguigu</span><br><span class="line">atguigu</span><br></pre></td></tr></table></figure></li></ul></li><li><p>（3）拼接</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">-rw-rw-r--. 1 atguigu atguigu 134217728 5月  23 16:01 blk_1073741836</span><br><span class="line">-rw-rw-r--. 1 atguigu atguigu   1048583 5月  23 16:01 blk_1073741836_1012.meta</span><br><span class="line">-rw-rw-r--. 1 atguigu atguigu  63439959 5月  23 16:01 blk_1073741837</span><br><span class="line">-rw-rw-r--. 1 atguigu atguigu    495635 5月  23 16:01 blk_1073741837_1013.meta</span><br><span class="line">[atguigu@hadoop107 subdir0]$ cat blk_1073741836&gt;&gt;tmp.file</span><br><span class="line">[atguigu@hadoop107 subdir0]$ cat blk_1073741837&gt;&gt;tmp.file</span><br><span class="line">[atguigu@hadoop107 subdir0]$ tar -zxvf tmp.file</span><br></pre></td></tr></table></figure></li><li><p>（4）下载</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop107 hadoop-2.7.2]$ bin/hadoop fs -get /user/atguigu/input/hadoop-2.7.2.tar.gz</span><br></pre></td></tr></table></figure></li></ul></li><li><p>3）集群性能测试</p><ul><li>写海量数据</li><li>读海量数据</li></ul></li></ul></li><li><p>（9）Hadoop启动停止方式</p><ul><li><p>1）各个服务组件逐一启动</p><ul><li><p>（1）分别启动hdfs组件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop-daemon.sh  start|stop  namenode|datanode|secondarynamenode</span><br></pre></td></tr></table></figure></li><li><p>（2）启动yarn</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yarn-daemon.sh  start|stop  resourcemanager|nodemanager</span><br></pre></td></tr></table></figure></li></ul></li><li><p>2）各个模块分开启动（配置ssh是前提）常用</p><ul><li><p>（1）整体启动/停止hdfs</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">start-dfs.sh</span><br><span class="line">stop-dfs.sh</span><br></pre></td></tr></table></figure></li><li><p>（2）整体启动/停止yarn</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">start-yarn.sh</span><br><span class="line">stop-yarn.sh</span><br></pre></td></tr></table></figure></li><li><p>3）全部启动（不建议使用）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">start-all.sh</span><br><span class="line">stop-all.sh</span><br></pre></td></tr></table></figure></li></ul></li></ul></li><li><p>（11）配置集群常见问题</p><ul><li><p>1）防火墙没关闭、或者没有启动yarn</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INFO client.RMProxy: Connecting to ResourceManager at hadoop108/192.168.10.108:8032</span><br></pre></td></tr></table></figure></li><li><p>2）主机名称配置错误</p></li><li><p>3）ip地址配置错误</p></li><li><p>4）ssh没有配置好</p></li><li><p>5）root用户和atguigu两个用户启动集群不统一</p></li><li><p>6）配置文件修改不细心</p></li><li><p>7）未编译源码</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">17/05/22 15:38:58 INFO client.RMProxy: Connecting to ResourceManager at hadoop108/192.168.10.108:8032</span><br></pre></td></tr></table></figure></li><li><p>8）datanode不被namenode识别问题</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Namenode在format初始化的时候会形成两个标识，blockPoolId和clusterId。新的datanode加入时，会获取这两个标识作为自己工作目录中的标识。</span><br><span class="line"></span><br><span class="line">一旦namenode重新format后，namenode的身份标识已变，而datanode如果依然持有原来的id，就不会被namenode识别。</span><br><span class="line"></span><br><span class="line">解决办法，删除datanode节点中的数据后，再次重新格式化namenode。</span><br></pre></td></tr></table></figure></li></ul></li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;本人微信公众号，欢迎扫码关注！&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;http://images.intflag.com/bigdata002.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;Hadoop运行模式（下）&quot;&gt;
      
    
    </summary>
    
      <category term="Hadoop" scheme="http://yoursite.com/categories/Hadoop/"/>
    
    
      <category term="Hadoop" scheme="http://yoursite.com/tags/Hadoop/"/>
    
      <category term="框架" scheme="http://yoursite.com/tags/%E6%A1%86%E6%9E%B6/"/>
    
      <category term="运行模式" scheme="http://yoursite.com/tags/%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop系列004-Hadoop运行模式（上）</title>
    <link href="http://yoursite.com/Hadoop%E7%B3%BB%E5%88%97004-Hadoop%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F%EF%BC%88%E4%B8%8A%EF%BC%89.html"/>
    <id>http://yoursite.com/Hadoop系列004-Hadoop运行模式（上）.html</id>
    <published>2018-11-20T06:27:00.000Z</published>
    <updated>2018-11-20T06:27:00.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本人微信公众号，欢迎扫码关注！</p></blockquote><p><img src="http://images.intflag.com/bigdata002.jpg" alt=""></p><h3 id="Hadoop运行模式"><a href="#Hadoop运行模式" class="headerlink" title="Hadoop运行模式"></a>Hadoop运行模式</h3><h4 id="1、概述"><a href="#1、概述" class="headerlink" title="1、概述"></a>1、概述</h4><p>1）官方网址</p><ul><li>官方网站：<a href="http://hadoop.apache.org/" target="_blank" rel="noopener">http://hadoop.apache.org/</a></li><li>各个版本归档库地址：<a href="https://archive.apache.org/dist/hadoop/common/hadoop-2.7.2/" target="_blank" rel="noopener">https://archive.apache.org/dist/hadoop/common/hadoop-2.7.2/</a></li><li>hadoop2.7.2版本详情介绍：<a href="http://hadoop.apache.org/docs/r2.7.2/" target="_blank" rel="noopener">http://hadoop.apache.org/docs/r2.7.2/</a></li></ul><p>2）Hadoop运行模式</p><ul><li>本地模式（默认模式）：不需要启用单独进程，直接可以运行，测试和开发时使用。</li><li>伪分布式模式：等同于完全分布式，只有一个节点。</li><li>完全分布式模式：多个节点一起运行。</li></ul><h4 id="2、案例"><a href="#2、案例" class="headerlink" title="2、案例"></a>2、案例</h4><h5 id="2-1、本地文件运行Hadoop-案例"><a href="#2-1、本地文件运行Hadoop-案例" class="headerlink" title="2.1、本地文件运行Hadoop 案例"></a>2.1、本地文件运行Hadoop 案例</h5><ul><li><p>官方grep案例</p><ul><li><p>1）创建在hadoop-2.7.2文件下面创建一个input文件夹</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[intflag@hadoop101 hadoop-2.7.2]$mkdir input</span><br></pre></td></tr></table></figure></li><li><p>2）将hadoop的xml配置文件复制到input</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[intflag@hadoop101 hadoop-2.7.2]$cp etc/hadoop/*.xml input</span><br></pre></td></tr></table></figure></li><li><p>3）执行share目录下的mapreduce程序</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[intflag@hadoop101 hadoop-2.7.2]$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar grep input output &apos;dfs[a-z.]+&apos;</span><br></pre></td></tr></table></figure></li><li><p>4）查看输出结果</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[intflag@hadoop101 hadoop-2.7.2]$ cat output/*</span><br></pre></td></tr></table></figure></li></ul></li><li><p>官方wordcount案例</p><ul><li><p>1）创建在hadoop-2.7.2文件下面创建一个wcinput文件夹</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[intflag@hadoop101 hadoop-2.7.2]$mkdir wcinput</span><br></pre></td></tr></table></figure></li><li><p>2）在wcinput文件下创建一个wc.input文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[intflag@hadoop101 hadoop-2.7.2]$cd wcinput</span><br><span class="line">[intflag@hadoop101 wcinput]$touch wc.input</span><br></pre></td></tr></table></figure></li><li><p>3）编辑wc.input文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[intflag@hadoop101 wcinput]$vim wc.input</span><br><span class="line">在文件中输入如下内容</span><br><span class="line">hadoop yarn</span><br><span class="line">hadoop mapreduce </span><br><span class="line">intflag</span><br><span class="line">intflag</span><br><span class="line"></span><br><span class="line">保存退出：：wq</span><br></pre></td></tr></table></figure></li><li><p>4）回到hadoop目录/opt/module/hadoop-2.7.2</p></li><li><p>5）执行程序</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[intflag@hadoop101 hadoop-2.7.2]$hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount wcinput wcoutput</span><br></pre></td></tr></table></figure></li><li><p>6）查看结果</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[intflag@hadoop101 hadoop-2.7.2]$cat wcoutput/part-r-00000</span><br><span class="line">intflag 2</span><br><span class="line">hadoop  2</span><br><span class="line">mapreduce       1</span><br><span class="line">yarn    1</span><br></pre></td></tr></table></figure></li></ul></li></ul><h5 id="2-2、伪分布式运行Hadoop-案例"><a href="#2-2、伪分布式运行Hadoop-案例" class="headerlink" title="2.2、伪分布式运行Hadoop 案例"></a>2.2、伪分布式运行Hadoop 案例</h5><ul><li><p>HDFS上运行MapReduce 程序</p><ul><li><p>1）分析：</p><ul><li>（1）准备1台客户机</li><li>（2）安装jdk</li><li>（3）配置环境变量</li><li>（4）安装hadoop</li><li>（5）配置环境变量</li><li>（6）配置集群</li><li>（7）启动、测试集群增、删、查</li><li>（8）在HDFS上执行wordcount案例</li></ul></li><li><p>2）执行步骤</p><ul><li><p>（1）配置集群</p><ul><li><p>（a）配置：hadoop-env.sh</p><ul><li><p>Linux系统中获取jdk的安装路径</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@ hadoop101 ~]# echo $JAVA_HOME</span><br><span class="line">/opt/module/jdk1.7.0_79</span><br></pre></td></tr></table></figure></li><li><p>修改JAVA_HOME 路径</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/module/jdk1.7.0_79</span><br></pre></td></tr></table></figure></li></ul></li><li><p>（b）配置：/etc/hadoop/下的core-site.xml</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 指定HDFS中NameNode的地址 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;hdfs://hadoop101:8020&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 指定hadoop运行时产生文件的存储目录 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">&lt;value&gt;/opt/module/hadoop-2.7.2/data/tmp&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></li><li><p>（c）配置：hdfs-site.xml </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 指定HDFS副本的数量 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;1&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>（2）启动集群</p><ul><li><p>（a）格式化namenode（第一次启动时格式化，以后就不要总格式化）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hdfs namenode -format</span><br></pre></td></tr></table></figure></li><li><p>（b）启动namenode</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/hadoop-daemon.sh start namenode</span><br></pre></td></tr></table></figure></li><li><p>（c）启动datanode</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/hadoop-daemon.sh start datanode</span><br></pre></td></tr></table></figure></li></ul></li><li><p>（3）查看集群</p><ul><li><p>（a）查看是否启动成功</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop ~]# jps</span><br><span class="line">13586 NameNode</span><br><span class="line">13668 DataNode</span><br><span class="line">13786 Jps</span><br></pre></td></tr></table></figure></li><li><p>（b）查看产生的log日志</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">当前目录：/opt/module/hadoop-2.7.2/logs</span><br><span class="line"></span><br><span class="line">[root@hadoop101 logs]# ls</span><br><span class="line"></span><br><span class="line">hadoop-root-datanode-hadoop.intflag.com.log</span><br><span class="line">hadoop-root-datanode-hadoop.intflag.com.out</span><br><span class="line">hadoop-root-namenode-hadoop.intflag.com.log</span><br><span class="line">hadoop-root-namenode-hadoop.intflag.com.out</span><br><span class="line">SecurityAuth-intflag.audit</span><br><span class="line"></span><br><span class="line">[root@hadoop101 logs]# cat hadoop-root-datanode-hadoop.intflag.com.log</span><br></pre></td></tr></table></figure></li><li><p>（c）web端查看HDFS文件系统</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">http://192.168.25.101:50070/dfshealth.html#tab-overview</span><br><span class="line"></span><br><span class="line">注意：如果不能查看，看如下帖子处理</span><br><span class="line">http://www.cnblogs.com/zlslch/p/6604189.html</span><br></pre></td></tr></table></figure></li></ul></li><li><p>（4）操作集群</p><ul><li><p>（a）在hdfs文件系统上创建一个input文件夹</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[intflag@hadoop101 hadoop-2.7.2]$ hadoop fs -mkdir -p /user/intflag/input</span><br><span class="line"></span><br><span class="line">或</span><br><span class="line"></span><br><span class="line">[intflag@hadoop101 hadoop-2.7.2]$ hdfs dfs -mkdir -p /user/intflag/input</span><br></pre></td></tr></table></figure></li><li><p>（b）将测试文件内容上传到文件系统上</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[intflag@hadoop101 hadoop-2.7.2]$ hadoop fs -put wcinput/wc.input /user/intflag/input</span><br><span class="line"></span><br><span class="line">或</span><br><span class="line"></span><br><span class="line">[intflag@hadoop101 hadoop-2.7.2]$ hdfs dfs -put wcinput/wc.input  /user/intflag/input</span><br></pre></td></tr></table></figure></li><li><p>（c）查看上传的文件是否正确</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[intflag@hadoop101 hadoop-2.7.2]$ hadoop fs -ls -R /</span><br></pre></td></tr></table></figure></li><li><p>（d）在Hdfs上运行mapreduce程序</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[intflag@hadoop101 hadoop-2.7.2]$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/intflag/input/wc.input /user/intflag/output</span><br></pre></td></tr></table></figure></li><li><p>（e）查看输出结果</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[intflag@hadoop101 hadoop-2.7.2]$ hadoop fs -cat /user/intflag/output/part-r-00000</span><br><span class="line">intflag 2</span><br><span class="line">doop    1</span><br><span class="line">hadoop  1</span><br><span class="line">mapreduce       1</span><br><span class="line">yarn    1</span><br></pre></td></tr></table></figure></li><li><p>（f）将测试文件内容下载到本地</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[intflag@hadoop101 hadoop-2.7.2]$ hadoop fs -get /user/intflag/output/part-r-00000 ./wcoutput/</span><br></pre></td></tr></table></figure></li><li><p>（g）删除输出结果</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[intflag@hadoop101 hadoop-2.7.2]$ hadoop fs -rm -r /user/intflag/output</span><br><span class="line">18/11/21 10:17:43 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.</span><br><span class="line">Deleted /user/intflag/output</span><br></pre></td></tr></table></figure></li><li><p>（H）hadoop fs、hadoop dfs与hdfs dfs命令的区别</p><ul><li>hadoop fs：使用面最广，可以操作任何文件系统。</li><li>hadoop dfs与hdfs dfs：只能操作HDFS文件系统相关（包括与Local FS间的操作），前者已经Deprecated，一般使用后者。</li></ul></li></ul></li></ul></li></ul></li><li><p>YARN上运行MapReduce 程序</p><ul><li><p>1）分析：</p><ul><li>（1）准备1台客户机</li><li>（2）安装jdk</li><li>（3）配置环境变量</li><li>（4）安装hadoop</li><li>（5）配置环境变量</li><li>（6）配置集群yarn上运行</li><li>（7）启动、测试集群增、删、查</li><li>（8）在yarn上执行wordcount案例</li></ul></li><li><p>2）执行步骤</p><ul><li><p>（1）配置集群</p><ul><li><p>（a）配置yarn-env.sh</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">配置一下JAVA_HOME</span><br><span class="line">export JAVA_HOME=/opt/module/jdk1.7.0_79</span><br></pre></td></tr></table></figure></li><li><p>（b）配置：mapred-env.sh</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">配置一下JAVA_HOME</span><br><span class="line">export JAVA_HOME=/opt/module/jdk1.7.0_79</span><br></pre></td></tr></table></figure></li><li><p>（c）配置yarn-site.xml</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- reducer获取数据的方式 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line"> &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line"> &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 指定YARN的ResourceManager的地址 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</span><br><span class="line">&lt;value&gt;hadoop101&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></li><li><p>（d）配置： (对mapred-site.xml.template重新命名为) mapred-site.xml</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 指定mr运行在yarn上 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">&lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>（2）启动集群</p><ul><li><p>（a）启动namenode和datanode（先用jps查看，若已启动则不需要再启）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sbin/hadoop-daemon.sh start namenode</span><br><span class="line">sbin/hadoop-daemon.sh start datanode</span><br></pre></td></tr></table></figure></li><li><p>（b）启动resourcemanager</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/yarn-daemon.sh start resourcemanager</span><br></pre></td></tr></table></figure></li><li><p>（c）启动nodemanager</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/yarn-daemon.sh start nodemanager</span><br></pre></td></tr></table></figure></li></ul></li><li><p>（3）集群操作</p><ul><li><p>（a）yarn的浏览器页面查看：<a href="http://hadoop101:8088/cluster（需要配置host，不配置可用ip地址访问）" target="_blank" rel="noopener">http://hadoop101:8088/cluster（需要配置host，不配置可用ip地址访问）</a></p></li><li><p>（b）删除文件系统上的output文件（若无则不用删除）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hdfs dfs -rm -R /user/mapreduce/wordcount/output</span><br></pre></td></tr></table></figure></li><li><p>（c）执行mapreduce程序</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/intflag/input /user/intflag/output</span><br></pre></td></tr></table></figure></li><li><p>（d）查看运行结果</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[intflag@hadoop101 hadoop-2.7.2]$ hadoop fs -cat /user/intflag/output/part-r-00000</span><br><span class="line">intflag 2</span><br><span class="line">doop    1</span><br><span class="line">hadoop  1</span><br><span class="line">mapreduce       1</span><br><span class="line">yarn    1</span><br></pre></td></tr></table></figure></li></ul></li></ul></li></ul></li><li><p>修改本地临时文件存储目录</p><ul><li><p>1）停止进程</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[intflag@hadoop101 hadoop-2.7.2]$ sbin/yarn-daemon.sh stop nodemanager</span><br><span class="line">stopping nodemanager</span><br><span class="line">[intflag@hadoop101 hadoop-2.7.2]$ sbin/yarn-daemon.sh stop resourcemanager</span><br><span class="line">stopping resourcemanager</span><br><span class="line">[intflag@hadoop101 hadoop-2.7.2]$ sbin/hadoop-daemon.sh stop namenode</span><br><span class="line">stopping namenode</span><br><span class="line">[intflag@hadoop101 hadoop-2.7.2]$ sbin/hadoop-daemon.sh stop datanode</span><br><span class="line">stopping datanode</span><br><span class="line">[intflag@hadoop101 hadoop-2.7.2]$</span><br></pre></td></tr></table></figure></li><li><p>2）修改hadoop.tmp.dir</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 指定hadoop运行时产生文件的存储目录 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">&lt;value&gt;/opt/module/hadoop-2.7.2/data/tmp&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></li><li><p>3）删除旧的临时文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[intflag@hadoop101 tmp]$ rm -rf hadoop-intflag</span><br><span class="line">[intflag@hadoop101 tmp]$ rm -rf hadoop-intflag-namenode.pid </span><br><span class="line">[intflag@hadoop101 hadoop-2.7.2]$ rm -rf logs/</span><br></pre></td></tr></table></figure></li><li><p>4）格式化NameNode</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[intflag@hadoop101 hadoop-2.7.2]$ hadoop namenode -format</span><br></pre></td></tr></table></figure></li><li><p>5）启动所有进程</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[intflag@hadoop101 hadoop-2.7.2]$ sbin/hadoop-daemon.sh start namenode</span><br><span class="line">[intflag@hadoop101 hadoop-2.7.2]$ sbin/hadoop-daemon.sh start datanode</span><br><span class="line">[intflag@hadoop101 hadoop-2.7.2]$ sbin/yarn-daemon.sh start resourcemanager</span><br><span class="line">[intflag@hadoop101 hadoop-2.7.2]$ sbin/yarn-daemon.sh start nodemanager</span><br></pre></td></tr></table></figure></li><li><p>6）查看/opt/module/hadoop-2.7.2/data/tmp这个目录下的内容。</p></li></ul></li><li><p>Hadoop配置文件说明</p><ul><li><p>Hadoop配置文件分两类：默认配置文件和自定义配置文件，只有用户想修改某一默认配置值时，才需要修改自定义配置文件，更改相应属性值。</p></li><li><p>（1）默认配置文件：存放在hadoop相应的jar包中</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[core-default.xml]</span><br><span class="line">hadoop-common-2.7.2.jar/ core-default.xml</span><br><span class="line"></span><br><span class="line">[hdfs-default.xml]</span><br><span class="line">hadoop-hdfs-2.7.2.jar/ hdfs-default.xml</span><br><span class="line"></span><br><span class="line">[yarn-default.xml]</span><br><span class="line">hadoop-yarn-common-2.7.2.jar/ yarn-default.xml</span><br><span class="line"></span><br><span class="line">[core-default.xml]</span><br><span class="line">hadoop-mapreduce-client-core-2.7.2.jar/ core-default.xml</span><br></pre></td></tr></table></figure></li><li><p>（2）自定义配置文件：存放在$HADOOP_HOME/etc/hadoop</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">core-site.xml</span><br><span class="line"></span><br><span class="line">hdfs-site.xml</span><br><span class="line"></span><br><span class="line">yarn-site.xml</span><br><span class="line"></span><br><span class="line">mapred-site.xml</span><br></pre></td></tr></table></figure></li></ul></li></ul><h5 id="2-3、完全分布式部署Hadoop"><a href="#2-3、完全分布式部署Hadoop" class="headerlink" title="2.3、完全分布式部署Hadoop"></a>2.3、完全分布式部署Hadoop</h5><ul><li>见Hadoop系列005-Hadoop运行模式（下）</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;本人微信公众号，欢迎扫码关注！&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;http://images.intflag.com/bigdata002.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;Hadoop运行模式&quot;&gt;&lt;a 
      
    
    </summary>
    
      <category term="Hadoop" scheme="http://yoursite.com/categories/Hadoop/"/>
    
    
      <category term="Hadoop" scheme="http://yoursite.com/tags/Hadoop/"/>
    
      <category term="框架" scheme="http://yoursite.com/tags/%E6%A1%86%E6%9E%B6/"/>
    
      <category term="运行模式" scheme="http://yoursite.com/tags/%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop系列003-Hadoop运行环境搭建</title>
    <link href="http://yoursite.com/Hadoop%E7%B3%BB%E5%88%97003-Hadoop%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA.html"/>
    <id>http://yoursite.com/Hadoop系列003-Hadoop运行环境搭建.html</id>
    <published>2018-11-19T06:27:00.000Z</published>
    <updated>2018-11-19T06:27:00.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本人微信公众号，欢迎扫码关注！</p></blockquote><p><img src="http://images.intflag.com/bigdata002.jpg" alt=""></p><h3 id="Hadoop运行环境搭建"><a href="#Hadoop运行环境搭建" class="headerlink" title="Hadoop运行环境搭建"></a>Hadoop运行环境搭建</h3><h4 id="1、虚拟机网络模式设置为NAT"><a href="#1、虚拟机网络模式设置为NAT" class="headerlink" title="1、虚拟机网络模式设置为NAT"></a>1、虚拟机网络模式设置为NAT</h4><h4 id="2、克隆虚拟机"><a href="#2、克隆虚拟机" class="headerlink" title="2、克隆虚拟机"></a>2、克隆虚拟机</h4><h4 id="3、修改为静态ip"><a href="#3、修改为静态ip" class="headerlink" title="3、修改为静态ip"></a>3、修改为静态ip</h4><h4 id="4、-修改主机名"><a href="#4、-修改主机名" class="headerlink" title="4、 修改主机名"></a>4、 修改主机名</h4><h4 id="5、关闭防火墙"><a href="#5、关闭防火墙" class="headerlink" title="5、关闭防火墙"></a>5、关闭防火墙</h4><p>1）查看防火墙开机启动状态</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chkconfig iptables --list</span><br></pre></td></tr></table></figure><p>2）关闭防火墙</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chkconfig iptables off</span><br></pre></td></tr></table></figure><h4 id="6、在opt目录下创建文件"><a href="#6、在opt目录下创建文件" class="headerlink" title="6、在opt目录下创建文件"></a>6、在opt目录下创建文件</h4><h4 id="7、安装JDK"><a href="#7、安装JDK" class="headerlink" title="7、安装JDK"></a>7、安装JDK</h4><p>1）卸载现有jdk</p><ul><li><p>查询是否安装java软件：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rpm –qa|grep java</span><br></pre></td></tr></table></figure></li><li><p>如果安装的版本低于1.7，卸载该jdk：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rpm –e 软件包</span><br></pre></td></tr></table></figure></li></ul><p>2）用filezilla工具将jdk、Hadoop-2.7.2.tar.gz导入到opt目录下面的software文件夹下面</p><p>3）在linux系统下的opt目录中查看软件包是否导入成功。</p><p>4）解压jdk到/opt/module目录下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxf jdk-7u79-linux-x64.gz -C /opt/module/</span><br></pre></td></tr></table></figure><p>5）配置jdk环境变量</p><ul><li><p>先获取jdk路径</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop101jdk1.7.0_67]# pwd</span><br><span class="line">/opt/module/jdk1.7.0_79</span><br></pre></td></tr></table></figure></li><li><p>打开/etc/profile文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop101 jdk1.7.0_79]# vi /etc/profile</span><br><span class="line"></span><br><span class="line">在profie文件末尾添加jdk路径：</span><br><span class="line">#JAVA_HOME</span><br><span class="line">export JAVA_HOME=/opt/module/jdk1.7.0_79</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br></pre></td></tr></table></figure></li><li><p>保存后退出</p></li><li><p>让修改后的文件生效</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop101 jdk1.7.0_79]# source  /etc/profile</span><br></pre></td></tr></table></figure></li><li><p>重启（如果java –version可以用就不用重启）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop101 jdk1.7.0_79]# sync</span><br><span class="line">[root@hadoop101 jdk1.7.0_79]# reboot</span><br></pre></td></tr></table></figure></li></ul><p>6）测试jdk安装成功</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop101 jdk1.7.0_79]# java -version</span><br><span class="line">java version &quot;1.7.0_79&quot;</span><br></pre></td></tr></table></figure><h4 id="8、安装Hadoop"><a href="#8、安装Hadoop" class="headerlink" title="8、安装Hadoop"></a>8、安装Hadoop</h4><p>1）进入到Hadoop安装包路径下</p><p>2）解压安装文件到/opt/module下面</p><p>3）查看是否解压成功</p><p>4）配置hadoop中的hadoop-env.sh</p><ul><li><p>Linux系统中获取jdk的安装路径</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop101 jdk1.7.0_79]# echo $JAVA_HOME</span><br><span class="line">/opt/module/jdk1.7.0_79</span><br></pre></td></tr></table></figure></li><li><p>修改hadoop-env.sh文件中JAVA_HOME 路径</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/module/jdk1.7.0_79</span><br></pre></td></tr></table></figure></li></ul><p>5）将hadoop添加到环境变量</p><ul><li><p>获取hadoop安装路径</p></li><li><p>打开/etc/profile文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">root@ hadoop101 hadoop-2.7.2]# vi /etc/profile</span><br><span class="line">在profie文件末尾添加jdk路径：（shitf+g）</span><br><span class="line"></span><br><span class="line">##HADOOP_HOME</span><br><span class="line">export HADOOP_HOME=/opt/module/hadoop-2.7.2</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/sbin</span><br></pre></td></tr></table></figure></li><li><p>保存后退出</p></li><li><p>让修改后的文件生效</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@ hadoop101 hadoop-2.7.2]# source /etc/profile</span><br></pre></td></tr></table></figure></li><li><p>（5）重启(如果hadoop命令不能用再重启)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@ hadoop101 hadoop-2.7.2]# sync</span><br><span class="line">root@ hadoop101 hadoop-2.7.2]# reboot</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;本人微信公众号，欢迎扫码关注！&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;http://images.intflag.com/bigdata002.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;Hadoop运行环境搭建&quot;&gt;&lt;
      
    
    </summary>
    
      <category term="Hadoop" scheme="http://yoursite.com/categories/Hadoop/"/>
    
    
      <category term="Hadoop" scheme="http://yoursite.com/tags/Hadoop/"/>
    
      <category term="框架" scheme="http://yoursite.com/tags/%E6%A1%86%E6%9E%B6/"/>
    
      <category term="环境搭建" scheme="http://yoursite.com/tags/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    
  </entry>
  
  <entry>
    <title>分享几个能在大学赚钱的案例</title>
    <link href="http://yoursite.com/%E5%88%86%E4%BA%AB%E5%87%A0%E4%B8%AA%E8%83%BD%E5%9C%A8%E5%A4%A7%E5%AD%A6%E8%B5%9A%E9%92%B1%E7%9A%84%E6%A1%88%E4%BE%8B.html"/>
    <id>http://yoursite.com/分享几个能在大学赚钱的案例.html</id>
    <published>2018-11-19T03:02:30.000Z</published>
    <updated>2018-11-19T03:02:30.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>转载自本人微信公众号，欢迎扫码关注！</p></blockquote><p><img src="http://images.intflag.com/introduce2.jpg" alt=""></p><p>上次分享了一位朋友大学期间的赚钱经历，许多人看完之后都特别佩服，其中也包括我。其实在大学能够锻炼自己的机会有很多，有的同学参加了学生会和各种社团，也有的同学参加各种比赛来丰富自己的简历，还有的同学则是在业余时间做各种兼职来锻炼自己，这样不光能赚一些生活费，还能提前接触社会，提升自己各方面的能力。今天就和大家聊一聊我所了解的，能在大学里赚到钱的一些方法和案例。</p><h4 id="1、比赛奖金"><a href="#1、比赛奖金" class="headerlink" title="1、比赛奖金"></a>1、比赛奖金</h4><p>风险指数：无</p><p>难度指数：四颗星</p><p>案例说明：之所以把它放在第一位的原因是，我认为在大学只有把时间和精力花在自己身上才是回报最大的投资，所以，参加比赛无疑是最好的选择之一，它不仅可以锻炼自己各方面的能力，如果获奖的话，除了能丰富简历以外还能拿到素质学分，素质学分高的话就有机会申请国家励志奖学金（5000元），或者国家奖学金（8000元），还有一些校内奖学金等等。凡事有得必有失，这需要你有很强的自我控制能力，合理规划时间的能力，甚至要牺牲自己绝大部分的课余时间，所以我认为还是挺难的，但如果最后能够坚持下来了的话，那你的收获将会是巨大的。</p><h4 id="2、勤工助学"><a href="#2、勤工助学" class="headerlink" title="2、勤工助学"></a>2、勤工助学</h4><p>风险指数：无</p><p>难度指数：二颗星</p><p>案例说明：说到勤工助学，让我想起了中学时期的一位同学，记得有一次我和舍友到食堂有些晚了，吃饭的时候无意中看见他在食堂打扫卫生，他当时也看见了我们，但是让我们惊讶的是他竟然很热心的跟我们几个打了招呼，我当时真的很佩服他，如果换做自己绝对不会那么从容，后来我们才知道，他不是因为家庭条件不好才去做的勤工助学，而是因为他觉得自己已经有能力靠自己养活自己了，不该再向家里要钱了。这种精神真的让我们很敬佩，同样的年纪，思想境界竟然有这么大的差别。</p><p>所以，勤工助学不是一件什么丢人的事，在大学也有很多的勤工助学岗位，比如布置各种考试的考场，维护机房，做老师的助教等等，如果不知道的话，你可以去请教你的学姐学长或者老师。这样你不仅可以改善自己的生活，还可以学习到好多技能，接触一些你从未接触过的事物，对自己也有很大的提高。</p><h4 id="3、补习班、家教"><a href="#3、补习班、家教" class="headerlink" title="3、补习班、家教"></a>3、补习班、家教</h4><p>风险指数：一颗星</p><p>难度指数：三颗星</p><p>案例说明：这个就不用多说了，但是有一点千万要注意，就是学会辨别黑心中介，有些黑心中介打着介绍兼职的旗号专门骗大学生的钱，因为大学生涉世未深，心里防范度低，很容易被骗，如果遇到什么先交押金之类的千万别信，要学会保护自己。最好让你信任的并且做过的同学或者学长学姐推荐，因为他们有经验，所以你听过他们的评价之后再做决定也不迟。</p><h4 id="4、教育机构代理"><a href="#4、教育机构代理" class="headerlink" title="4、教育机构代理"></a>4、教育机构代理</h4><p>风险指数：一颗星</p><p>难度指数：三颗星</p><p>案例说明：这个相信大部分同学也有所了解，我简单再介绍一下，很多考研机构，计算机考试培训机构，公务员考试培训机构，·驾校等等，他们为了招收更多的学生，通常会在学校找一些人做代理，因为学生更了解学生的需求，但是最好做大品牌机构的代理，因为如果他们不靠谱，那么会大大损失你的信誉度，所以千万别坑你的同学，不然你在大学就混不下去了。</p><p>此外，别把代理想象成一件轻松的工作，任何赚钱的工作都不是轻松的，都是需要花费时间和经历的。做代理需要你不停的做宣传，维护你的人脉，和好多人去沟通。同样收入也是很可观的，我大学认识的人里面，做代理月入一万的大有人在。</p><h4 id="5、大学二手教材"><a href="#5、大学二手教材" class="headerlink" title="5、大学二手教材"></a>5、大学二手教材</h4><p>风险指数：二颗星</p><p>难度指数：三颗星</p><p>案例说明：通过废旧的二手教材月入20万，差点儿拿到投资。来自「stormzhang」的付费知识星球。</p><p><img src="http://images.intflag.com/%E5%88%86%E4%BA%AB%E5%87%A0%E4%B8%AA%E8%83%BD%E5%9C%A8%E5%A4%A7%E5%AD%A6%E8%B5%9A%E9%92%B1%E7%9A%84%E6%A1%88%E4%BE%8B005.png" alt=""></p><h4 id="6、新生入学指南"><a href="#6、新生入学指南" class="headerlink" title="6、新生入学指南"></a>6、新生入学指南</h4><p>风险指数：三颗星</p><p>难度指数：四颗星</p><p>案例说明：利用信息差赚钱，月入8万。来自「stormzhang」的付费知识星球。</p><p><img src="http://images.intflag.com/%E5%88%86%E4%BA%AB%E5%87%A0%E4%B8%AA%E8%83%BD%E5%9C%A8%E5%A4%A7%E5%AD%A6%E8%B5%9A%E9%92%B1%E7%9A%84%E6%A1%88%E4%BE%8B004.png" alt=""></p><h4 id="7、游戏"><a href="#7、游戏" class="headerlink" title="7、游戏"></a>7、游戏</h4><p>风险指数：三颗星</p><p>难度指数：五颗星</p><p>案例说明：说到游戏多人都不陌生，有的人甚至大学所有时间都花费在了游戏上面，投入了大量的精力和金钱，那是在玩游戏吗？不是，那是游戏在玩你！你既然那么爱玩游戏怎么不从里面找找商机呢？下面的案例来自「stormzhang」的付费知识星球，利用游戏日入上千。</p><p><img src="http://images.intflag.com/%E5%88%86%E4%BA%AB%E5%87%A0%E4%B8%AA%E8%83%BD%E5%9C%A8%E5%A4%A7%E5%AD%A6%E8%B5%9A%E9%92%B1%E7%9A%84%E6%A1%88%E4%BE%8B003.png" alt=""></p><h4 id="8、薅羊毛"><a href="#8、薅羊毛" class="headerlink" title="8、薅羊毛"></a>8、薅羊毛</h4><p>风险指数：四颗星</p><p>难度指数：五颗星</p><p>案例说明：你眼里普通的优惠券在别人眼里就是能月入30万的生意。来自「stormzhang」的付费知识星球。</p><p><img src="http://images.intflag.com/%E5%88%86%E4%BA%AB%E5%87%A0%E4%B8%AA%E8%83%BD%E5%9C%A8%E5%A4%A7%E5%AD%A6%E8%B5%9A%E9%92%B1%E7%9A%84%E6%A1%88%E4%BE%8B002.jpg" alt=""></p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>有些人在大学往往干什么都是成群结队，即使有自己想做的事最后也因为同伴不愿意而放弃了，然而还有些人总喜欢独来独往，看起来和我们不太一样，但正是这些「独行」的人往往非常优秀，往往更能守住自己的节奏。</p><p>所以，你想到什么就大胆的干吧，一刻也别犹豫，年轻就是资本，年轻就有了更多试错的机会，你本一无所有，还在乎失去吗？大不了重新来过！大学就应该无限精彩，千万别庸庸碌碌的度过。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;转载自本人微信公众号，欢迎扫码关注！&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;http://images.intflag.com/introduce2.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;上次分享了一位朋友大学期间的赚钱经
      
    
    </summary>
    
      <category term="云端笑猿" scheme="http://yoursite.com/categories/%E4%BA%91%E7%AB%AF%E7%AC%91%E7%8C%BF/"/>
    
    
      <category term="大学" scheme="http://yoursite.com/tags/%E5%A4%A7%E5%AD%A6/"/>
    
      <category term="赚钱" scheme="http://yoursite.com/tags/%E8%B5%9A%E9%92%B1/"/>
    
      <category term="兼职" scheme="http://yoursite.com/tags/%E5%85%BC%E8%81%8C/"/>
    
      <category term="案例" scheme="http://yoursite.com/tags/%E6%A1%88%E4%BE%8B/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop系列002-从Hadoop框架讨论大数据生态</title>
    <link href="http://yoursite.com/Hadoop%E7%B3%BB%E5%88%97002-%E4%BB%8EHadoop%E6%A1%86%E6%9E%B6%E8%AE%A8%E8%AE%BA%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%94%9F%E6%80%81.html"/>
    <id>http://yoursite.com/Hadoop系列002-从Hadoop框架讨论大数据生态.html</id>
    <published>2018-11-18T03:43:00.000Z</published>
    <updated>2018-11-18T03:43:00.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本人微信公众号，欢迎扫码关注！</p></blockquote><p><img src="http://images.intflag.com/bigdata002.jpg" alt=""></p><h3 id="从Hadoop框架讨论大数据生态"><a href="#从Hadoop框架讨论大数据生态" class="headerlink" title="从Hadoop框架讨论大数据生态"></a>从Hadoop框架讨论大数据生态</h3><h4 id="1、Hadoop是什么"><a href="#1、Hadoop是什么" class="headerlink" title="1、Hadoop是什么"></a>1、Hadoop是什么</h4><p>1）Hadoop是一个由Apache基金会所开发的分布式系统基础架构</p><p>2）主要解决，海量数据的存储和海量数据的分析计算问题。</p><p>3）广义上来说，HADOOP通常是指一个更广泛的概念——HADOOP生态圈</p><h4 id="2、Hadoop发展历史"><a href="#2、Hadoop发展历史" class="headerlink" title="2、Hadoop发展历史"></a>2、Hadoop发展历史</h4><p>1）Lucene–Doug Cutting开创的开源软件，用java书写代码，实现与Google类似的全文搜索功能，它提供了全文检索引擎的架构，包括完整的查询引擎和索引引擎 </p><p>2）2001年年底成为apache基金会的一个子项目</p><p>3）对于大数量的场景，Lucene面对与Google同样的困难</p><p>4）学习和模仿Google解决这些问题的办法 ：微型版Nutch</p><p>5）可以说Google是hadoop的思想之源(Google在大数据方面的三篇论文)</p><ul><li>GFS —&gt;HDFS</li><li>Map-Reduce —&gt;MR</li><li>BigTable —&gt;Hbase</li></ul><p>6）2003-2004年，Google公开了部分GFS和Mapreduce思想的细节，以此为基础Doug Cutting等人用了2年业余时间实现了DFS和Mapreduce机制，使Nutch性能飙升 </p><p>7）2005 年Hadoop 作为 Lucene的子项目 Nutch的一部分正式引入Apache基金会。2006 年 3 月份，Map-Reduce和Nutch Distributed File System (NDFS) 分别被纳入称为 Hadoop 的项目中 </p><p>8）名字来源于Doug Cutting儿子的玩具大象</p><p>9）Hadoop就此诞生并迅速发展，标志这云计算时代来临</p><h4 id="3、Hadoop三大发行版本"><a href="#3、Hadoop三大发行版本" class="headerlink" title="3、Hadoop三大发行版本"></a>3、Hadoop三大发行版本</h4><p>Apache、Cloudera、Hortonworks</p><p>1）Apache版本最原始（最基础）的版本，对于入门学习最好。</p><p>2）Cloudera在大型互联网企业中用的较多。</p><ul><li><p>2008年成立的Cloudera是最早将Hadoop商用的公司，为合作伙伴提供Hadoop的商用解决方案，主要是包括支持、咨询服务、培训。</p></li><li><p>2009年Hadoop的创始人Doug Cutting也加盟Cloudera公司。Cloudera产品主要为CDH，Cloudera Manager，Cloudera Support</p></li><li>CDH是Cloudera的Hadoop发行版，完全开源，比Apache Hadoop在兼容性，安全性，稳定性上有所增强</li><li>Cloudera Manager是集群的软件分发及管理监控平台，可以在几个小时内部署好一个Hadoop集群，并对集群的节点及服务进行实时监控。Cloudera Support即是对Hadoop的技术支持。</li><li>Cloudera的标价为每年每个节点4000美元。Cloudera开发并贡献了可实时处理大数据的Impala项目。</li></ul><p>3）Hortonworks文档较好。</p><ul><li>2011年成立的Hortonworks是雅虎与硅谷风投公司Benchmark Capital合资组建。</li><li>公司成立之初就吸纳了大约25名至30名专门研究Hadoop的雅虎工程师，上述工程师均在2005年开始协助雅虎开发Hadoop，贡献了Hadoop80%的代码。</li><li>雅虎工程副总裁、雅虎Hadoop开发团队负责人Eric Baldeschwieler出任Hortonworks的首席执行官。</li><li>Hortonworks的主打产品是Hortonworks Data Platform（HDP），也同样是100%开源的产品，HDP除常见的项目外还包括了Ambari，一款开源的安装和管理系统。</li><li>HCatalog，一个元数据管理系统，HCatalog现已集成到Facebook开源的Hive中。Hortonworks的Stinger开创性的极大的优化了Hive项目。Hortonworks为入门提供了一个非常好的，易于使用的沙盒。</li><li>Hortonworks开发了很多增强特性并提交至核心主干，这使得Apache Hadoop能够在包括Window Server和Windows Azure在内的microsoft Windows平台上本地运行。定价以集群为基础，每10个节点每年为12500美元。</li></ul><h4 id="4、Hadoop的优势"><a href="#4、Hadoop的优势" class="headerlink" title="4、Hadoop的优势"></a>4、Hadoop的优势</h4><p>1）<strong>高可靠性</strong>：因为Hadoop假设计算元素和存储会出现故障，因为它维护多个工作数据副本，在出现故障时可以对失败的节点重新分布处理。</p><p>2）<strong>高扩展性</strong>：在集群间分配任务数据，可方便的扩展数以千计的节点。</p><p>3）<strong>高效性</strong>：在MapReduce的思想下，Hadoop是并行工作的，以加快任务处理速度。</p><p>4）<strong>高容错性</strong>：自动保存多份副本数据，并且能够自动将失败的任务重新分配。</p><h4 id="5、Hadoop组成"><a href="#5、Hadoop组成" class="headerlink" title="5、Hadoop组成"></a>5、Hadoop组成</h4><h5 id="5-1-HDFS架构概述"><a href="#5-1-HDFS架构概述" class="headerlink" title="5.1 HDFS架构概述"></a>5.1 HDFS架构概述</h5><p>1）<strong>NameNode（nn）</strong>：存储文件的元数据，如文件名，文件目录结构，文件属性（生成时间、副本数、文件权限），以及每个文件的块列表和块所在的DataNode等。</p><p>2）<strong>DataNode(dn)</strong>：在本地文件系统存储文件块数据，以及块数据的校验和。</p><p>3）<strong>Secondary NameNode(2nn)</strong>：用来监控HDFS状态的辅助后台程序，每隔一段时间获取HDFS元数据的快照。</p><h5 id="5-2-YARN架构概述"><a href="#5-2-YARN架构概述" class="headerlink" title="5.2 YARN架构概述"></a>5.2 YARN架构概述</h5><p>1）<strong>ResourceManager(rm)</strong>：处理客户端请求、启动/监控ApplicationMaster、监控NodeManager、资源分配与调度。</p><p>2）<strong>NodeManager(nm)</strong>：单个节点上的资源管理、处理来自ResourceManager的命令、处理来自ApplicationMaster的命令。</p><p>3）<strong>ApplicationMaster</strong>：数据切分、为应用程序申请资源，并分配给内部任务、任务监控与容错。</p><p>4）<strong>Container</strong>：对任务运行环境的抽象，封装了CPU、内存等多维资源以及环境变量、启动命令等任务运行相关的信息。</p><h5 id="5-3-MapReduce架构概述"><a href="#5-3-MapReduce架构概述" class="headerlink" title="5.3 MapReduce架构概述"></a>5.3 MapReduce架构概述</h5><p>MapReduce将计算过程分为两个阶段：Map和Reduce</p><p>1）Map阶段并行处理输入数据</p><p>2）Reduce阶段对Map结果进行汇总</p><h4 id="6、大数据技术生态体系"><a href="#6、大数据技术生态体系" class="headerlink" title="6、大数据技术生态体系"></a>6、大数据技术生态体系</h4><p><img src="http://images.intflag.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E7%94%9F%E6%80%81%E4%BD%93%E7%B3%BB.jpg" alt=""></p><h4 id="7、推荐系统框架图"><a href="#7、推荐系统框架图" class="headerlink" title="7、推荐系统框架图"></a>7、推荐系统框架图</h4><p><img src="http://images.intflag.com/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E5%9B%BE.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;本人微信公众号，欢迎扫码关注！&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;http://images.intflag.com/bigdata002.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;从Hadoop框架讨论大数据生
      
    
    </summary>
    
      <category term="Hadoop" scheme="http://yoursite.com/categories/Hadoop/"/>
    
    
      <category term="Hadoop" scheme="http://yoursite.com/tags/Hadoop/"/>
    
      <category term="框架" scheme="http://yoursite.com/tags/%E6%A1%86%E6%9E%B6/"/>
    
      <category term="大数据生态" scheme="http://yoursite.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%94%9F%E6%80%81/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop系列001-大数据概论</title>
    <link href="http://yoursite.com/Hadoop%E7%B3%BB%E5%88%97001-%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A6%82%E8%AE%BA.html"/>
    <id>http://yoursite.com/Hadoop系列001-大数据概论.html</id>
    <published>2018-11-17T02:10:49.000Z</published>
    <updated>2018-11-17T02:10:49.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本人微信公众号，欢迎扫码关注！</p></blockquote><p><img src="http://images.intflag.com/bigdata002.jpg" alt=""></p><h2 id="大数据概论"><a href="#大数据概论" class="headerlink" title="大数据概论"></a>大数据概论</h2><h3 id="1、大数据概念"><a href="#1、大数据概念" class="headerlink" title="1、大数据概念"></a>1、大数据概念</h3><p>大数据（big data），指无法在一定时间范围内用常规软件工具进行捕捉、管理和处理的数据集合，是需要新处理模式才能具有更强的决策力、洞察发现力和流程优化能力的海量、高增长率和多样化的信息资产。</p><p>最小的基本单位是bit，按顺序给出所有单位：bit、Byte、KB、MB、GB、TB、PB、EB、ZB、YB、BB、NB、DB。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1Byte = 8bit1K = 1024bit1MB = 1024K1G = 1024M</span><br><span class="line">1T = 1024G1P = 1024T1E = 1024P1Z = 1024E</span><br><span class="line">1Y = 1024Z1B = 1024Y1N = 1024B1D = 1024N</span><br></pre></td></tr></table></figure><h3 id="2、大数据的特点"><a href="#2、大数据的特点" class="headerlink" title="2、大数据的特点"></a>2、大数据的特点</h3><h4 id="1）Volume（大量）"><a href="#1）Volume（大量）" class="headerlink" title="1）Volume（大量）"></a>1）Volume（大量）</h4><p>截至目前，人类生产的所有印刷材料的数据量是200PB，而历史上全人类总共说过的话的数据量大约是5EB。当前，典型个人计算机硬盘的容量为TB量级，而一些大企业的数据量已经接近EB量级。</p><h4 id="2）Velocity（高速）"><a href="#2）Velocity（高速）" class="headerlink" title="2）Velocity（高速）"></a>2）Velocity（高速）</h4><p>这是大数据区分于传统数据挖掘的最显著特征。根据IDC的“数字宇宙”的报告，预计到2020年，全球数据使用量将达到35.2ZB。在如此海量的数据面前，处理数据的效率就是企业的生命。</p><p>天猫双十一：2016年6分58秒，天猫交易额超过100亿</p><h4 id="3）Variety（多样）"><a href="#3）Variety（多样）" class="headerlink" title="3）Variety（多样）"></a>3）Variety（多样）</h4><p>这种类型的多样性也让数据被分为结构化数据和非结构化数据。相对于以往便于存储的以数据库/文本为主的结构化数据，非结构化数据越来越多，包括网络日志、音频、视频、图片、地理位置信息等，这些多类型的数据对数据的处理能力提出了更高要求。</p><h4 id="4）Value（低价值密度）"><a href="#4）Value（低价值密度）" class="headerlink" title="4）Value（低价值密度）"></a>4）Value（低价值密度）</h4><p>价值密度的高低与数据总量的大小成反比。比如，在一天监控视频中，我们只关心老师晚上在床上健身那一分钟，如何快速对有价值数据“提纯”成为目前大数据背景下待解决的难题。</p><h3 id="3、大数据的应用场景"><a href="#3、大数据的应用场景" class="headerlink" title="3、大数据的应用场景"></a>3、大数据的应用场景</h3><p>1）O2O：百度大数据+平台通过先进的线上线下打通技术和客流分析能力，助力商家精细化运营，提升销量。</p><p>2）零售：探索用户价值，提供个性化服务解决方案；贯穿网络与实体零售，携手创造极致体验。经典案例，子尿布+啤酒。</p><p>3）旅游：深度结合百度独有大数据能力与旅游行业需求，共建旅游产业智慧管理、智慧服务和智慧营销的未来。</p><p>4）商品广告推荐：给用户推荐访问过的商品广告类型</p><p>5） 房产：大数据全面助力房地产行业，打造精准投策与营销，选出更合适的地，建造更合适的楼，卖给更合适的人。</p><p>6）保险：海量数据挖掘及风险预测，助力保险行业精准营销，提升精细化定价能力。</p><p>7）金融：多维度体现用户特征，帮助金融机构推荐优质客户，防范欺诈风险。</p><p>8）移动联通：移动联通：根据用户年龄、职业、消费情况，分析统计哪种套餐适合哪类人群。对市场人群精准定制。</p><p>9）人工智能</p><h3 id="4、大数据的发展前景"><a href="#4、大数据的发展前景" class="headerlink" title="4、大数据的发展前景"></a>4、大数据的发展前景</h3><p>1）党的十八届五中全会提出“实施国家大数据战略”，国务院印发《促进大数据发展行动纲要》，大数据技术和应用处于创新突破期，国内市场需求处于爆发期，我国大数据产业面临重要的发展机遇。</p><p>2）国际数据公司IDC预测，到2020年，企业基于大数据计算分析平台的支出将突破5000亿美元。目前，我国大数据人才只有46万，未来3到5年人才缺口达150万之多。</p><ul><li>人才缺口计算<br>150w-40w=110w<br>110W/5年 = 22w/年<br>22w/12月=1.83w/月<br>自古不变的真理：先入行者吃肉，后入行者喝汤，最后到的买单！</li></ul><p>3）2017年北京大学、中国人民大学、北京邮电大学等25所高校成功申请开设大数据课程。</p><p>4）大数据属于高新技术，大牛少，升职竞争小；</p><p>5）在北京大数据开发工程师的平均薪水已经到17800元（数据统计来职友集），而且目前还保持强劲的发展势头。</p><h3 id="5、企业数据部的业务流程分析"><a href="#5、企业数据部的业务流程分析" class="headerlink" title="5、企业数据部的业务流程分析"></a>5、企业数据部的业务流程分析</h3><p><img src="http://images.intflag.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A6%82%E8%AE%BA001.png" alt=""></p><h3 id="6、企业数据部的一般组织结构"><a href="#6、企业数据部的一般组织结构" class="headerlink" title="6、企业数据部的一般组织结构"></a>6、企业数据部的一般组织结构</h3><p><img src="http://images.intflag.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A6%82%E8%AE%BA002.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;本人微信公众号，欢迎扫码关注！&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;http://images.intflag.com/bigdata002.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;大数据概论&quot;&gt;&lt;a href=
      
    
    </summary>
    
      <category term="Hadoop" scheme="http://yoursite.com/categories/Hadoop/"/>
    
    
      <category term="Hadoop" scheme="http://yoursite.com/tags/Hadoop/"/>
    
      <category term="大数据" scheme="http://yoursite.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>大学里月入1万的经历</title>
    <link href="http://yoursite.com/%E5%A4%A7%E5%AD%A6%E9%87%8C%E6%9C%88%E5%85%A51%E4%B8%87%E7%9A%84%E7%BB%8F%E5%8E%86.html"/>
    <id>http://yoursite.com/大学里月入1万的经历.html</id>
    <published>2018-11-07T02:10:30.000Z</published>
    <updated>2018-11-07T02:10:30.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>转载自本人微信公众号，欢迎扫码关注！</p></blockquote><p><img src="http://images.intflag.com/introduce2.jpg" alt=""></p><p>前几天在一个付费知识星球中结识了一位朋友，他就读于南方一所大学，现在已经毕业了，由于和我学的是同一个专业，所以聊得很投缘。开始我们聊了挺多专业问题，后来聊到了大学赚钱，他从大一开始就属于那种对赚钱有很多想法的人，做过许多兼职，在大三的时候，不到半学期就挣了三万多，平均月入一万，听了他的赚钱经历之后非常感慨，也非常佩服他。</p><p>我不光佩服他能在大学就挣那么多钱，更佩服他的坚持和商业头脑，实话说他所做的那些赚钱项目我也有所了解，有的也见过身边的朋友在做，甚至其中一个我也实践过，但是都没有坚持下来，今天就和大家分享一下这位朋友大学里的赚钱经历，我把我们聊的内容整理了一下，后续内容采用第一人称和大家讲述，后文中的「我」即代表「我的那位朋友」。</p><p>谈话内容：</p><p>从大一开始我就对赚钱比较有想法，应该是比较穷吧，哈哈。。。大一的时候做过几次发传单和服务员的兼职，又累挣得又少，在大二的时候通过学长介绍开始做托福家教，一个小时120，其实我托福也不太好，满分120，我只考了100出头，但是教70分以下的学生还是绰绰有余的。在我们这边，大学生家教，教托福，120一个小时是很正常的收入，如果是专业的老师，比如新东方的老师，哪怕水平一般，要价都要比这贵很多。我每周收入600块，从此过上了优渥的大学生活，哈哈。。。这个兼职一直持续到大三，发现了赚钱更多的门路就不再做了。</p><p>大三的时候，偶然机会，遇到一个朋友做毕业设计中介。问我会不会做Android和J2EE相关毕业设计，这个当然会啦，毕竟学的就是这个专业嘛，平时在学校就和同学做过很多项目，做起来轻车熟路。然后我就推掉了家教的兼职，开始做毕业设计，不到半学期做了30多个，因为有的功能都差不多，稍微改改就行了。价格600-1200不等，带后台就1000以上。听我那个朋友说，厉害的中介，辛苦半年，可以赚100w。这个需求特别大，比如我们学校好多人，在大学几年，完全混过来的。毕业时随便花几百上千块钱，买个作品和论文，答辩就可以过了。</p><p>大三下学期的时候，我一学长在外面接了一所驾校的总代，因为我们学校有多个校区，他想让我帮他做我所在校区的代理，然后我这边的单子分成给我，假设我这边出去的单子，驾校给他10%，我拿其中7%，我当时也是第一次做，不怎么懂，但我是个重朋友的人，就接下了这个活。</p><p>我当时找了几个本校区的朋友，先自己垫钱请大家出来吃饭聊聊，然后说了这个事，哥们都表示支持，然后一些事就是各种宣传了，比如赞助学生会活动横幅啥的，QQ群啥的，到后来我把更多时间放在了学习上，因为我要准备实习的事情了，这件事就交给学弟做了，后来算了下，我这边总共做了100个单子左右，赚了几千块钱吧，赚钱之后首先在一开始的那个哥们群里发了个大红包。</p><p>结束语：</p><p>和这位朋友聊了挺多，赚钱的例子也谈了挺多，上面的属于专业知识比较强的人才能做，而且像代做毕业设计严格来说是违法的，最好不要轻易尝试。后续如果大家感兴趣的话，我把其他不需要太强的专业知识，也能在大学实际操作的赚钱例子跟大家分享一下，今天就到这里，如果大家有什么想法可以在下面留言，或者在公众号后台回复我，和我交流。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;转载自本人微信公众号，欢迎扫码关注！&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;http://images.intflag.com/introduce2.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;前几天在一个付费知识星球中结识了一
      
    
    </summary>
    
      <category term="云端笑猿" scheme="http://yoursite.com/categories/%E4%BA%91%E7%AB%AF%E7%AC%91%E7%8C%BF/"/>
    
    
      <category term="大学" scheme="http://yoursite.com/tags/%E5%A4%A7%E5%AD%A6/"/>
    
      <category term="赚钱" scheme="http://yoursite.com/tags/%E8%B5%9A%E9%92%B1/"/>
    
      <category term="兼职" scheme="http://yoursite.com/tags/%E5%85%BC%E8%81%8C/"/>
    
  </entry>
  
  <entry>
    <title>如何将项目上传到GitHub</title>
    <link href="http://yoursite.com/%E5%A6%82%E4%BD%95%E5%B0%86%E9%A1%B9%E7%9B%AE%E4%B8%8A%E4%BC%A0%E5%88%B0GitHub.html"/>
    <id>http://yoursite.com/如何将项目上传到GitHub.html</id>
    <published>2018-11-01T08:46:04.000Z</published>
    <updated>2018-11-01T08:46:04.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本人微信公众号「intflags」，欢迎扫码关注！</p></blockquote><p><img src="http://images.intflag.com/introduce2.jpg" alt=""></p><h2 id="如何将项目上传到GitHub？"><a href="#如何将项目上传到GitHub？" class="headerlink" title="如何将项目上传到GitHub？"></a>如何将项目上传到GitHub？</h2><h3 id="1、注册GitHub账户"><a href="#1、注册GitHub账户" class="headerlink" title="1、注册GitHub账户"></a>1、注册GitHub账户</h3><ul><li>浏览器输入GitHub官网地址：<a href="https://github.com/" target="_blank" rel="noopener">https://github.com/</a></li><li>进入后点击Sign In<br><img src="http://images.intflag.com/GitHub01.png" alt=""></li><li>然后点击Create an account<br><img src="http://images.intflag.com/GitHub02.png" alt=""></li><li>然后输入用户名、密码、邮箱等信息，用户名一定要简短好记，因为这个用户名关系到以后你的个性域名。<br><img src="http://images.intflag.com/GitHub03.png" alt=""></li><li>按照系统提示，一步步将信息填写完毕后就OK了，如果中途遇到问题，可以复制提示信息到百度翻译查一下。此后遇到类似问题也一样，因为好多工具或者开源框架官网都是英文的。<h3 id="2、安装Git客户端"><a href="#2、安装Git客户端" class="headerlink" title="2、安装Git客户端"></a>2、安装Git客户端</h3></li><li><p>下载Git客户端，官方地址：<a href="https://git-scm.com/download/win" target="_blank" rel="noopener">https://git-scm.com/download/win</a></p></li><li><p>双击安装包进行安装</p><p><img src="http://images.intflag.com/GitHub04.png" alt=""></p><p><img src="http://images.intflag.com/GitHub05.png" alt=""></p><p><img src="http://images.intflag.com/GitHub06.png" alt=""></p><p><img src="http://images.intflag.com/GitHub07.png" alt=""></p><p><img src="http://images.intflag.com/GitHub08.png" alt=""></p><p><img src="http://images.intflag.com/GitHub09.png" alt=""></p><p><img src="http://images.intflag.com/GitHub10.png" alt=""></p><p><img src="http://images.intflag.com/GitHub11.png" alt=""></p><p><img src="http://images.intflag.com/GitHub12.png" alt=""></p></li><li><p>安装完毕</p><h3 id="3、在GitHub上创建项目"><a href="#3、在GitHub上创建项目" class="headerlink" title="3、在GitHub上创建项目"></a>3、在GitHub上创建项目</h3></li><li>新建仓库<br><img src="http://images.intflag.com/GitHub13.png" alt=""></li><li>填写项目信息<br><img src="http://images.intflag.com/GitHub14.png" alt=""></li><li>创建完毕<br><img src="http://images.intflag.com/GitHub15.png" alt=""><h3 id="4、使用Git命令提交项目到GitHub"><a href="#4、使用Git命令提交项目到GitHub" class="headerlink" title="4、使用Git命令提交项目到GitHub"></a>4、使用Git命令提交项目到GitHub</h3></li><li>打开要上传的项目的工作路径，在目录空白处鼠标右键<br><img src="http://images.intflag.com/GitHub16.png" alt=""></li><li>点击Git Bash Here打开Git命令行界面<br><img src="http://images.intflag.com/GitHub17.png" alt=""></li><li>输入命令：<strong>git init</strong> 初始化项目<br><img src="http://images.intflag.com/GitHub18.png" alt=""></li><li>输入命令：<strong>git add .</strong> 将该目录下所有文件加入本地暂存区，注意命令后面有一个.代表将所有文件添加到暂存区，如果只想将个别提交，那么将.换成文件名即可。<br><img src="http://images.intflag.com/GitHub19.png" alt=""></li><li>输入命令：<strong>git status</strong> 查看状态，该命令会将工作空间中的版本与暂存区的版本进行对比，我下面的状态是已经把所有文件加入到了暂存区中，但是还没有提交到本地历史区。<br><img src="http://images.intflag.com/GitHub20.png" alt=""></li><li>输入命令：<strong>git commit -m “项目注释”</strong><br><img src="http://images.intflag.com/GitHub21.png" alt=""></li><li>输入命令：<strong>git remote add origin <a href="https://github.com/intflag/SayLOVE.git" target="_blank" rel="noopener">https://github.com/intflag/SayLOVE.git</a></strong> 该命令是把本地历史区中的文件添加到github服务器的暂存区中。这一步是本地和远程服务器建立联系的一步。执行成功后不会显示任何结果。<br><img src="http://images.intflag.com/GitHub22.png" alt=""></li><li>输入命令：<strong>git pull origin master</strong> 该命令是先把github上的文件拉下来，注意在每次提交之前要首先进行pull，这是防止冲突。<strong>如果报错，只要输入git pull origin master –allow-unrelated-histories 即可</strong><br><img src="http://images.intflag.com/GitHub23.png" alt=""></li><li>上述执行成功后，发现在项目目录下多了一个“README.md”文件，这个文件就是从github上拉下来的。因为我们在github上创建repository的时候就创建了这个“README.md”文件，该文件是对这个repository的说明。<br><img src="http://images.intflag.com/GitHub24.png" alt=""></li><li>输入命令：<strong>git push -u origin master</strong> 这一步是真正向github提交，执行完成后，github上的repository就有和你本地一样的代码文件了。<br><img src="http://images.intflag.com/GitHub25.png" alt=""></li><li>执行完毕后到GitHub上查看结果。<br><img src="http://images.intflag.com/GitHub26.png" alt=""></li><li>此时，项目就提交完毕了。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;本人微信公众号「intflags」，欢迎扫码关注！&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;http://images.intflag.com/introduce2.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;如何将项目
      
    
    </summary>
    
      <category term="IDE&amp;工具" scheme="http://yoursite.com/categories/IDE-%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="GitHub" scheme="http://yoursite.com/tags/GitHub/"/>
    
      <category term="项目上传" scheme="http://yoursite.com/tags/%E9%A1%B9%E7%9B%AE%E4%B8%8A%E4%BC%A0/"/>
    
  </entry>
  
  <entry>
    <title>防民之口，慎于防川！谈谈遇害的沙特记者</title>
    <link href="http://yoursite.com/%E9%98%B2%E6%B0%91%E4%B9%8B%E5%8F%A3%EF%BC%8C%E6%85%8E%E4%BA%8E%E9%98%B2%E5%B7%9D%EF%BC%81%E8%B0%88%E8%B0%88%E9%81%87%E5%AE%B3%E7%9A%84%E6%B2%99%E7%89%B9%E8%AE%B0%E8%80%85.html"/>
    <id>http://yoursite.com/防民之口，慎于防川！谈谈遇害的沙特记者.html</id>
    <published>2018-10-31T10:28:17.000Z</published>
    <updated>2018-10-31T10:28:17.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>转载自本人微信公众号「intflags」，欢迎扫码关注！</p></blockquote><p><img src="http://images.intflag.com/introduce2.jpg" alt=""></p><p>卡舒吉是沙特阿拉伯的一位记者，他的经历很传奇，不仅和老一辈的沙特王室权贵都搭得上，还了解沙特王室的很多秘密，在1980年代和1990年代，他曾几次采访本拉登，为此，他名声大噪。后来拿了美国签证，还成为「华盛顿邮报」的专栏记者。</p><p><img src="http://images.intflag.com/%E5%8D%A1%E8%88%92%E5%90%8904.jpg" alt="2018年9月29日，英国伦敦，沙特记者贾迈勒·卡舒吉出席《中东箴言报》举办的活动。图片来源：视觉中国"></p><p>在任职华盛顿专栏记者期间，他利用美国媒体的影响力，多次公开痛批沙特国王「小萨勒曼」和王储，反对他们的对外政策，并且揭露沙特的腐败，所以沙特国王对他恨之入骨。</p><p>2018年10月2日，卡舒吉进入伊斯坦布尔的沙特领事馆办理离婚证明，以便与土耳其女子结婚，可是进去之后就再也没有出来，他被沙特国王小萨勒曼派出的15名特工残忍杀害，是被肢解的，而且还是在他意识清醒的情况下，让他看着自己的身体被肢解，特别残暴变态。</p><p><img src="http://images.intflag.com/%E5%8D%A1%E8%88%92%E5%90%8903.png" alt="图右：卡舒吉，图片素材来源：新闻片段截图"></p><p>这件事全球都在关注，主要在于人权，在如今的文明社会还会发生这样的暴行简直令人震惊，虽然看起来和我们毫无关系，但是人权是全球的事。</p><p>看了这个新闻以后让我想起著名历史老师「石国鹏」讲过的一个典故「防民之口，甚于防川」，说西周末年的一位君主叫做「周厉王」，为了决定增加赋税，维持花天酒地的生活，他对一些重要物产征收“专利税”。不论是王公大臣还是平民百姓，只要他们采药、砍柴，捕鱼虾、射鸟兽，都必须纳税；甚至喝水、走路也得缴纳钱物。</p><p>周厉王残暴无道，老百姓纷纷责骂他。邵公对厉王说，老百姓已不堪忍受暴虐的政令啦！厉王听了勃然大怒，找到一个卫国的巫者，只要有人说他坏话，就会暗中杀害他们。老百姓怨声载道，不敢说话，用眼神表达自己的愤怒。周厉王自鸣得意，以为这样就可以堵住老百姓的悠悠之口。</p><p>邵公对厉王说：你这样做只能堵住人们的嘴。可是防范老百姓的嘴，比防备河水泛滥更不易。河道因堵塞而造成决口，就会伤害很多人。倘使堵住老百姓的口，后果也将如此。可是厉王根本不听，三年后，百姓忍无可忍，心中的怨气累积到顶点，终于导致国人暴动，周厉王被赶出国都，最后死在了彘[zhì]地。</p><p>中国人在三千年前就说过「防民之口，甚于防川」这样的话。以史为鉴，可以知得失。民意乃最大的天意，像沙特这样失去民意的国家，早晚会自取灭亡。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;转载自本人微信公众号「intflags」，欢迎扫码关注！&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;http://images.intflag.com/introduce2.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;卡舒吉是沙特阿
      
    
    </summary>
    
      <category term="云端笑猿" scheme="http://yoursite.com/categories/%E4%BA%91%E7%AB%AF%E7%AC%91%E7%8C%BF/"/>
    
    
      <category term="沙特" scheme="http://yoursite.com/tags/%E6%B2%99%E7%89%B9/"/>
    
      <category term="卡舒吉" scheme="http://yoursite.com/tags/%E5%8D%A1%E8%88%92%E5%90%89/"/>
    
      <category term="遇害记者" scheme="http://yoursite.com/tags/%E9%81%87%E5%AE%B3%E8%AE%B0%E8%80%85/"/>
    
      <category term="言论自由" scheme="http://yoursite.com/tags/%E8%A8%80%E8%AE%BA%E8%87%AA%E7%94%B1/"/>
    
  </entry>
  
</feed>
