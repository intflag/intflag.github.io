<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>云端笑猿</title>
  
  <subtitle>现实中的那些纷纷扰扰，都无非是过眼云烟；你在人生的战场上追名逐利，不得解脱；我在我的代码世界中，宁静致远，深藏功与名。</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-11-19T06:27:00.000Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>云端笑猿</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Hadoop系列003-Hadoop运行环境搭建</title>
    <link href="http://yoursite.com/Hadoop%E7%B3%BB%E5%88%97003-Hadoop%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA.html"/>
    <id>http://yoursite.com/Hadoop系列003-Hadoop运行环境搭建.html</id>
    <published>2018-11-19T06:27:00.000Z</published>
    <updated>2018-11-19T06:27:00.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本人微信公众号，欢迎扫码关注！</p></blockquote><p><img src="http://phsyg9eyi.bkt.clouddn.com/introduce2.jpg" alt=""></p><h3 id="Hadoop运行环境搭建"><a href="#Hadoop运行环境搭建" class="headerlink" title="Hadoop运行环境搭建"></a>Hadoop运行环境搭建</h3><h4 id="1、虚拟机网络模式设置为NAT"><a href="#1、虚拟机网络模式设置为NAT" class="headerlink" title="1、虚拟机网络模式设置为NAT"></a>1、虚拟机网络模式设置为NAT</h4><h4 id="2、克隆虚拟机"><a href="#2、克隆虚拟机" class="headerlink" title="2、克隆虚拟机"></a>2、克隆虚拟机</h4><h4 id="3、修改为静态ip"><a href="#3、修改为静态ip" class="headerlink" title="3、修改为静态ip"></a>3、修改为静态ip</h4><h4 id="4、-修改主机名"><a href="#4、-修改主机名" class="headerlink" title="4、 修改主机名"></a>4、 修改主机名</h4><h4 id="5、关闭防火墙"><a href="#5、关闭防火墙" class="headerlink" title="5、关闭防火墙"></a>5、关闭防火墙</h4><p>1）查看防火墙开机启动状态</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chkconfig iptables --list</span><br></pre></td></tr></table></figure><p>2）关闭防火墙</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chkconfig iptables off</span><br></pre></td></tr></table></figure><h4 id="6、在opt目录下创建文件"><a href="#6、在opt目录下创建文件" class="headerlink" title="6、在opt目录下创建文件"></a>6、在opt目录下创建文件</h4><h4 id="7、安装JDK"><a href="#7、安装JDK" class="headerlink" title="7、安装JDK"></a>7、安装JDK</h4><p>1）卸载现有jdk</p><ul><li><p>查询是否安装java软件：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rpm –qa|grep java</span><br></pre></td></tr></table></figure></li><li><p>如果安装的版本低于1.7，卸载该jdk：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rpm –e 软件包</span><br></pre></td></tr></table></figure></li></ul><p>2）用filezilla工具将jdk、Hadoop-2.7.2.tar.gz导入到opt目录下面的software文件夹下面</p><p>3）在linux系统下的opt目录中查看软件包是否导入成功。</p><p>4）解压jdk到/opt/module目录下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxf jdk-7u79-linux-x64.gz -C /opt/module/</span><br></pre></td></tr></table></figure><p>5）配置jdk环境变量</p><ul><li><p>先获取jdk路径</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop101jdk1.7.0_67]# pwd</span><br><span class="line">/opt/module/jdk1.7.0_79</span><br></pre></td></tr></table></figure></li><li><p>打开/etc/profile文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop101 jdk1.7.0_79]# vi /etc/profile</span><br><span class="line"></span><br><span class="line">在profie文件末尾添加jdk路径：</span><br><span class="line">##JAVA_HOME</span><br><span class="line">export JAVA_HOME=/opt/module/jdk1.7.0_79</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br></pre></td></tr></table></figure></li><li><p>保存后退出</p></li><li><p>让修改后的文件生效</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop101 jdk1.7.0_79]# source  /etc/profile</span><br></pre></td></tr></table></figure></li><li><p>重启（如果java –version可以用就不用重启）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop101 jdk1.7.0_79]# sync</span><br><span class="line">[root@hadoop101 jdk1.7.0_79]# reboot</span><br></pre></td></tr></table></figure></li></ul><p>6）测试jdk安装成功</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop101 jdk1.7.0_79]# java -version</span><br><span class="line">java version &quot;1.7.0_79&quot;</span><br></pre></td></tr></table></figure><h4 id="8、安装Hadoop"><a href="#8、安装Hadoop" class="headerlink" title="8、安装Hadoop"></a>8、安装Hadoop</h4><p>1）进入到Hadoop安装包路径下</p><p>2）解压安装文件到/opt/module下面</p><p>3）查看是否解压成功</p><p>4）配置hadoop中的hadoop-env.sh</p><ul><li><p>Linux系统中获取jdk的安装路径</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop101 jdk1.7.0_79]# echo $JAVA_HOME</span><br><span class="line">/opt/module/jdk1.7.0_79</span><br></pre></td></tr></table></figure></li><li><p>修改hadoop-env.sh文件中JAVA_HOME 路径</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/module/jdk1.7.0_79</span><br></pre></td></tr></table></figure></li></ul><p>5）将hadoop添加到环境变量</p><ul><li><p>获取hadoop安装路径</p></li><li><p>打开/etc/profile文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">root@ hadoop101 hadoop-2.7.2]# vi /etc/profile</span><br><span class="line">在profie文件末尾添加jdk路径：（shitf+g）</span><br><span class="line"></span><br><span class="line">##HADOOP_HOME</span><br><span class="line">export HADOOP_HOME=/opt/module/hadoop-2.7.2</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/sbin</span><br></pre></td></tr></table></figure></li><li><p>保存后退出</p></li><li><p>让修改后的文件生效</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@ hadoop101 hadoop-2.7.2]# source /etc/profile</span><br></pre></td></tr></table></figure></li><li><p>（5）重启(如果hadoop命令不能用再重启)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@ hadoop101 hadoop-2.7.2]# sync</span><br><span class="line">root@ hadoop101 hadoop-2.7.2]# reboot</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;本人微信公众号，欢迎扫码关注！&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;http://phsyg9eyi.bkt.clouddn.com/introduce2.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;Hadoop运行
      
    
    </summary>
    
      <category term="Hadoop" scheme="http://yoursite.com/categories/Hadoop/"/>
    
    
      <category term="Hadoop" scheme="http://yoursite.com/tags/Hadoop/"/>
    
      <category term="框架" scheme="http://yoursite.com/tags/%E6%A1%86%E6%9E%B6/"/>
    
      <category term="环境搭建" scheme="http://yoursite.com/tags/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop系列004-Hadoop运行模式（上）</title>
    <link href="http://yoursite.com/Hadoop%E7%B3%BB%E5%88%97004-Hadoop%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F.html"/>
    <id>http://yoursite.com/Hadoop系列004-Hadoop运行模式.html</id>
    <published>2018-11-19T06:27:00.000Z</published>
    <updated>2018-11-19T06:27:00.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本人微信公众号，欢迎扫码关注！</p></blockquote><p><img src="http://phsyg9eyi.bkt.clouddn.com/introduce2.jpg" alt=""></p><h3 id="Hadoop运行模式"><a href="#Hadoop运行模式" class="headerlink" title="Hadoop运行模式"></a>Hadoop运行模式</h3><h4 id="1、概述"><a href="#1、概述" class="headerlink" title="1、概述"></a>1、概述</h4><p>1）官方网址</p><ul><li>官方网站：<a href="http://hadoop.apache.org/" target="_blank" rel="noopener">http://hadoop.apache.org/</a></li><li>各个版本归档库地址：<a href="https://archive.apache.org/dist/hadoop/common/hadoop-2.7.2/" target="_blank" rel="noopener">https://archive.apache.org/dist/hadoop/common/hadoop-2.7.2/</a></li><li>hadoop2.7.2版本详情介绍：<a href="http://hadoop.apache.org/docs/r2.7.2/" target="_blank" rel="noopener">http://hadoop.apache.org/docs/r2.7.2/</a></li></ul><p>2）Hadoop运行模式</p><ul><li>本地模式（默认模式）：不需要启用单独进程，直接可以运行，测试和开发时使用。</li><li>伪分布式模式：等同于完全分布式，只有一个节点。</li><li>完全分布式模式：多个节点一起运行。</li></ul><h4 id="2、案例"><a href="#2、案例" class="headerlink" title="2、案例"></a>2、案例</h4><h5 id="2-1、本地文件运行Hadoop-案例"><a href="#2-1、本地文件运行Hadoop-案例" class="headerlink" title="2.1、本地文件运行Hadoop 案例"></a>2.1、本地文件运行Hadoop 案例</h5><ul><li><p>官方grep案例</p><ul><li><p>1）创建在hadoop-2.7.2文件下面创建一个input文件夹</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[intflag@hadoop101 hadoop-2.7.2]$mkdir input</span><br></pre></td></tr></table></figure></li><li><p>2）将hadoop的xml配置文件复制到input</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[intflag@hadoop101 hadoop-2.7.2]$cp etc/hadoop/*.xml input</span><br></pre></td></tr></table></figure></li><li><p>3）执行share目录下的mapreduce程序</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[intflag@hadoop101 hadoop-2.7.2]$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar grep input output &apos;dfs[a-z.]+&apos;</span><br></pre></td></tr></table></figure></li><li><p>4）查看输出结果</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[intflag@hadoop101 hadoop-2.7.2]$ cat output/*</span><br></pre></td></tr></table></figure></li></ul></li><li><p>官方wordcount案例</p><ul><li><p>1）创建在hadoop-2.7.2文件下面创建一个wcinput文件夹</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[intflag@hadoop101 hadoop-2.7.2]$mkdir wcinput</span><br></pre></td></tr></table></figure></li><li><p>2）在wcinput文件下创建一个wc.input文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[intflag@hadoop101 hadoop-2.7.2]$cd wcinput</span><br><span class="line">[intflag@hadoop101 wcinput]$touch wc.input</span><br></pre></td></tr></table></figure></li><li><p>3）编辑wc.input文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[intflag@hadoop101 wcinput]$vim wc.input</span><br><span class="line">在文件中输入如下内容</span><br><span class="line">hadoop yarn</span><br><span class="line">hadoop mapreduce </span><br><span class="line">intflag</span><br><span class="line">intflag</span><br><span class="line"></span><br><span class="line">保存退出：：wq</span><br></pre></td></tr></table></figure></li><li><p>4）回到hadoop目录/opt/module/hadoop-2.7.2</p></li><li><p>5）执行程序</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[intflag@hadoop101 hadoop-2.7.2]$hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount wcinput wcoutput</span><br></pre></td></tr></table></figure></li><li><p>6）查看结果</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[intflag@hadoop101 hadoop-2.7.2]$cat wcoutput/part-r-00000</span><br><span class="line">intflag 2</span><br><span class="line">hadoop  2</span><br><span class="line">mapreduce       1</span><br><span class="line">yarn    1</span><br></pre></td></tr></table></figure></li></ul></li></ul><h5 id="2-2、伪分布式运行Hadoop-案例"><a href="#2-2、伪分布式运行Hadoop-案例" class="headerlink" title="2.2、伪分布式运行Hadoop 案例"></a>2.2、伪分布式运行Hadoop 案例</h5><ul><li><p>HDFS上运行MapReduce 程序</p><ul><li><p>1）分析：</p><ul><li>（1）准备1台客户机</li><li>（2）安装jdk</li><li>（3）配置环境变量</li><li>（4）安装hadoop</li><li>（5）配置环境变量</li><li>（6）配置集群</li><li>（7）启动、测试集群增、删、查</li><li>（8）在HDFS上执行wordcount案例</li></ul></li><li><p>2）执行步骤</p><ul><li><p>（1）配置集群</p><ul><li><p>（a）配置：hadoop-env.sh</p><ul><li><p>Linux系统中获取jdk的安装路径</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@ hadoop101 ~]# echo $JAVA_HOME</span><br><span class="line">/opt/module/jdk1.7.0_79</span><br></pre></td></tr></table></figure></li><li><p>修改JAVA_HOME 路径</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/module/jdk1.7.0_79</span><br></pre></td></tr></table></figure></li></ul></li><li><p>（b）配置：/etc/hadoop/下的core-site.xml</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 指定HDFS中NameNode的地址 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;hdfs://hadoop101:8020&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 指定hadoop运行时产生文件的存储目录 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">&lt;value&gt;/opt/module/hadoop-2.7.2/data/tmp&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></li><li><p>（c）配置：hdfs-site.xml </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 指定HDFS副本的数量 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;1&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>（2）启动集群</p><ul><li><p>（a）格式化namenode（第一次启动时格式化，以后就不要总格式化）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hdfs namenode -format</span><br></pre></td></tr></table></figure></li><li><p>（b）启动namenode</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/hadoop-daemon.sh start namenode</span><br></pre></td></tr></table></figure></li><li><p>（c）启动datanode</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/hadoop-daemon.sh start datanode</span><br></pre></td></tr></table></figure></li></ul></li><li><p>（3）查看集群</p><ul><li><p>（a）查看是否启动成功</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop ~]# jps</span><br><span class="line">13586 NameNode</span><br><span class="line">13668 DataNode</span><br><span class="line">13786 Jps</span><br></pre></td></tr></table></figure></li><li><p>（b）查看产生的log日志</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">当前目录：/opt/module/hadoop-2.7.2/logs</span><br><span class="line"></span><br><span class="line">[root@hadoop101 logs]# ls</span><br><span class="line"></span><br><span class="line">hadoop-root-datanode-hadoop.intflag.com.log</span><br><span class="line">hadoop-root-datanode-hadoop.intflag.com.out</span><br><span class="line">hadoop-root-namenode-hadoop.intflag.com.log</span><br><span class="line">hadoop-root-namenode-hadoop.intflag.com.out</span><br><span class="line">SecurityAuth-intflag.audit</span><br><span class="line"></span><br><span class="line">[root@hadoop101 logs]# cat hadoop-root-datanode-hadoop.intflag.com.log</span><br></pre></td></tr></table></figure></li><li><p>（c）web端查看HDFS文件系统</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">http://192.168.25.101:50070/dfshealth.html#tab-overview</span><br><span class="line"></span><br><span class="line">注意：如果不能查看，看如下帖子处理</span><br><span class="line">http://www.cnblogs.com/zlslch/p/6604189.html</span><br></pre></td></tr></table></figure></li></ul></li><li><p>（4）操作集群</p><ul><li><p>（a）在hdfs文件系统上创建一个input文件夹</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[intflag@hadoop101 hadoop-2.7.2]$ hadoop fs -mkdir -p /user/intflag/input</span><br><span class="line"></span><br><span class="line">或</span><br><span class="line"></span><br><span class="line">[intflag@hadoop101 hadoop-2.7.2]$ hdfs dfs -mkdir -p /user/intflag/input</span><br></pre></td></tr></table></figure></li><li><p>（b）将测试文件内容上传到文件系统上</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[intflag@hadoop101 hadoop-2.7.2]$ hadoop fs -put wcinput/wc.input /user/intflag/input</span><br><span class="line"></span><br><span class="line">或</span><br><span class="line"></span><br><span class="line">[intflag@hadoop101 hadoop-2.7.2]$ hdfs dfs -put wcinput/wc.input  /user/intflag/input</span><br></pre></td></tr></table></figure></li><li><p>（c）查看上传的文件是否正确</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[intflag@hadoop101 hadoop-2.7.2]$ hadoop fs -ls -R /</span><br></pre></td></tr></table></figure></li><li><p>（d）在Hdfs上运行mapreduce程序</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[intflag@hadoop101 hadoop-2.7.2]$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/intflag/input/wc.input /user/intflag/output</span><br></pre></td></tr></table></figure></li><li><p>（e）查看输出结果</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[intflag@hadoop101 hadoop-2.7.2]$ hadoop fs -cat /user/intflag/output/part-r-00000</span><br><span class="line">intflag 2</span><br><span class="line">doop    1</span><br><span class="line">hadoop  1</span><br><span class="line">mapreduce       1</span><br><span class="line">yarn    1</span><br></pre></td></tr></table></figure></li><li><p>（f）将测试文件内容下载到本地</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[intflag@hadoop101 hadoop-2.7.2]$ hadoop fs -get /user/intflag/output/part-r-00000 ./wcoutput/</span><br></pre></td></tr></table></figure></li><li><p>（g）删除输出结果</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[intflag@hadoop101 hadoop-2.7.2]$ hadoop fs -rm -r /user/intflag/output</span><br><span class="line">18/11/21 10:17:43 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.</span><br><span class="line">Deleted /user/intflag/output</span><br></pre></td></tr></table></figure></li><li><p>（H）hadoop fs、hadoop dfs与hdfs dfs命令的区别</p><ul><li>hadoop fs：使用面最广，可以操作任何文件系统。</li><li>hadoop dfs与hdfs dfs：只能操作HDFS文件系统相关（包括与Local FS间的操作），前者已经Deprecated，一般使用后者。</li></ul></li></ul></li></ul></li></ul></li><li><p>YARN上运行MapReduce 程序</p><ul><li><p>1）分析：</p><ul><li>（1）准备1台客户机</li><li>（2）安装jdk</li><li>（3）配置环境变量</li><li>（4）安装hadoop</li><li>（5）配置环境变量</li><li>（6）配置集群yarn上运行</li><li>（7）启动、测试集群增、删、查</li><li>（8）在yarn上执行wordcount案例</li></ul></li><li><p>2）执行步骤</p><ul><li><p>（1）配置集群</p><ul><li><p>（a）配置yarn-env.sh</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">配置一下JAVA_HOME</span><br><span class="line">export JAVA_HOME=/opt/module/jdk1.7.0_79</span><br></pre></td></tr></table></figure></li><li><p>（b）配置：mapred-env.sh</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">配置一下JAVA_HOME</span><br><span class="line">export JAVA_HOME=/opt/module/jdk1.7.0_79</span><br></pre></td></tr></table></figure></li><li><p>（c）配置yarn-site.xml</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- reducer获取数据的方式 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line"> &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line"> &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 指定YARN的ResourceManager的地址 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</span><br><span class="line">&lt;value&gt;hadoop101&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></li><li><p>（d）配置： (对mapred-site.xml.template重新命名为) mapred-site.xml</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 指定mr运行在yarn上 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">&lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>（2）启动集群</p><ul><li><p>（a）启动namenode和datanode（先用jps查看，若已启动则不需要再启）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sbin/hadoop-daemon.sh start namenode</span><br><span class="line">sbin/hadoop-daemon.sh start datanode</span><br></pre></td></tr></table></figure></li><li><p>（b）启动resourcemanager</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/yarn-daemon.sh start resourcemanager</span><br></pre></td></tr></table></figure></li><li><p>（c）启动nodemanager</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/yarn-daemon.sh start nodemanager</span><br></pre></td></tr></table></figure></li></ul></li><li><p>（3）集群操作</p><ul><li><p>（a）yarn的浏览器页面查看：<a href="http://hadoop101:8088/cluster" target="_blank" rel="noopener">http://hadoop101:8088/cluster</a></p></li><li><p>（b）删除文件系统上的output文件（若无则不用删除）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/hdfs dfs -rm -R /user/mapreduce/wordcount/output</span><br></pre></td></tr></table></figure></li><li><p>（c）执行mapreduce程序</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /user/intflag/input /user/intflag/output</span><br></pre></td></tr></table></figure></li><li><p>（d）查看运行结果</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[intflag@hadoop101 hadoop-2.7.2]$ hadoop fs -cat /user/intflag/output/part-r-00000</span><br><span class="line">intflag 2</span><br><span class="line">doop    1</span><br><span class="line">hadoop  1</span><br><span class="line">mapreduce       1</span><br><span class="line">yarn    1</span><br></pre></td></tr></table></figure></li></ul></li></ul></li></ul></li><li><p>修改本地临时文件存储目录</p><ul><li><p>1）停止进程</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[intflag@hadoop101 hadoop-2.7.2]$ sbin/yarn-daemon.sh stop nodemanager</span><br><span class="line">stopping nodemanager</span><br><span class="line">[intflag@hadoop101 hadoop-2.7.2]$ sbin/yarn-daemon.sh stop resourcemanager</span><br><span class="line">stopping resourcemanager</span><br><span class="line">[intflag@hadoop101 hadoop-2.7.2]$ sbin/hadoop-daemon.sh stop namenode</span><br><span class="line">stopping namenode</span><br><span class="line">[intflag@hadoop101 hadoop-2.7.2]$ sbin/hadoop-daemon.sh stop datanode</span><br><span class="line">stopping datanode</span><br><span class="line">[intflag@hadoop101 hadoop-2.7.2]$</span><br></pre></td></tr></table></figure></li><li><p>2）修改hadoop.tmp.dir</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 指定hadoop运行时产生文件的存储目录 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">&lt;value&gt;/opt/module/hadoop-2.7.2/data/tmp&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></li><li><p>3）删除旧的临时文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[intflag@hadoop101 tmp]$ rm -rf hadoop-intflag</span><br><span class="line">[intflag@hadoop101 tmp]$ rm -rf hadoop-intflag-namenode.pid </span><br><span class="line">[intflag@hadoop101 hadoop-2.7.2]$ rm -rf logs/</span><br></pre></td></tr></table></figure></li><li><p>4）格式化NameNode</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[intflag@hadoop101 hadoop-2.7.2]$ hadoop namenode -format</span><br></pre></td></tr></table></figure></li><li><p>5）启动所有进程</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[intflag@hadoop101 hadoop-2.7.2]$ sbin/hadoop-daemon.sh start namenode</span><br><span class="line">[intflag@hadoop101 hadoop-2.7.2]$ sbin/hadoop-daemon.sh start datanode</span><br><span class="line">[intflag@hadoop101 hadoop-2.7.2]$ sbin/yarn-daemon.sh start resourcemanager</span><br><span class="line">[intflag@hadoop101 hadoop-2.7.2]$ sbin/yarn-daemon.sh start nodemanager</span><br></pre></td></tr></table></figure></li><li><p>6）查看/opt/module/hadoop-2.7.2/data/tmp这个目录下的内容。</p></li></ul></li><li><p>Hadoop配置文件说明</p><ul><li><p>Hadoop配置文件分两类：默认配置文件和自定义配置文件，只有用户想修改某一默认配置值时，才需要修改自定义配置文件，更改相应属性值。</p></li><li><p>（1）默认配置文件：存放在hadoop相应的jar包中</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[core-default.xml]</span><br><span class="line">hadoop-common-2.7.2.jar/ core-default.xml</span><br><span class="line"></span><br><span class="line">[hdfs-default.xml]</span><br><span class="line">hadoop-hdfs-2.7.2.jar/ hdfs-default.xml</span><br><span class="line"></span><br><span class="line">[yarn-default.xml]</span><br><span class="line">hadoop-yarn-common-2.7.2.jar/ yarn-default.xml</span><br><span class="line"></span><br><span class="line">[core-default.xml]</span><br><span class="line">hadoop-mapreduce-client-core-2.7.2.jar/ core-default.xml</span><br></pre></td></tr></table></figure></li><li><p>（2）自定义配置文件：存放在$HADOOP_HOME/etc/hadoop</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">core-site.xml</span><br><span class="line"></span><br><span class="line">hdfs-site.xml</span><br><span class="line"></span><br><span class="line">yarn-site.xml</span><br><span class="line"></span><br><span class="line">mapred-site.xml</span><br></pre></td></tr></table></figure></li></ul></li></ul><h5 id="2-3、完全分布式部署Hadoop"><a href="#2-3、完全分布式部署Hadoop" class="headerlink" title="2.3、完全分布式部署Hadoop"></a>2.3、完全分布式部署Hadoop</h5><ul><li>见Hadoop系列005-Hadoop运行模式（下）</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;本人微信公众号，欢迎扫码关注！&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;http://phsyg9eyi.bkt.clouddn.com/introduce2.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;Hadoop运行
      
    
    </summary>
    
      <category term="Hadoop" scheme="http://yoursite.com/categories/Hadoop/"/>
    
    
      <category term="Hadoop" scheme="http://yoursite.com/tags/Hadoop/"/>
    
      <category term="框架" scheme="http://yoursite.com/tags/%E6%A1%86%E6%9E%B6/"/>
    
      <category term="运行模式" scheme="http://yoursite.com/tags/%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop系列002-从Hadoop框架讨论大数据生态</title>
    <link href="http://yoursite.com/Hadoop%E7%B3%BB%E5%88%97002-%E4%BB%8EHadoop%E6%A1%86%E6%9E%B6%E8%AE%A8%E8%AE%BA%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%94%9F%E6%80%81.html"/>
    <id>http://yoursite.com/Hadoop系列002-从Hadoop框架讨论大数据生态.html</id>
    <published>2018-11-19T03:43:00.000Z</published>
    <updated>2018-11-19T03:43:00.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本人微信公众号，欢迎扫码关注！</p></blockquote><p><img src="http://phsyg9eyi.bkt.clouddn.com/introduce2.jpg" alt=""></p><h3 id="从Hadoop框架讨论大数据生态"><a href="#从Hadoop框架讨论大数据生态" class="headerlink" title="从Hadoop框架讨论大数据生态"></a>从Hadoop框架讨论大数据生态</h3><h4 id="1、Hadoop是什么"><a href="#1、Hadoop是什么" class="headerlink" title="1、Hadoop是什么"></a>1、Hadoop是什么</h4><p>1）Hadoop是一个由Apache基金会所开发的分布式系统基础架构</p><p>2）主要解决，海量数据的存储和海量数据的分析计算问题。</p><p>3）广义上来说，HADOOP通常是指一个更广泛的概念——HADOOP生态圈</p><h4 id="2、Hadoop发展历史"><a href="#2、Hadoop发展历史" class="headerlink" title="2、Hadoop发展历史"></a>2、Hadoop发展历史</h4><p>1）Lucene–Doug Cutting开创的开源软件，用java书写代码，实现与Google类似的全文搜索功能，它提供了全文检索引擎的架构，包括完整的查询引擎和索引引擎 </p><p>2）2001年年底成为apache基金会的一个子项目</p><p>3）对于大数量的场景，Lucene面对与Google同样的困难</p><p>4）学习和模仿Google解决这些问题的办法 ：微型版Nutch</p><p>5）可以说Google是hadoop的思想之源(Google在大数据方面的三篇论文)</p><ul><li>GFS —&gt;HDFS</li><li>Map-Reduce —&gt;MR</li><li>BigTable —&gt;Hbase</li></ul><p>6）2003-2004年，Google公开了部分GFS和Mapreduce思想的细节，以此为基础Doug Cutting等人用了2年业余时间实现了DFS和Mapreduce机制，使Nutch性能飙升 </p><p>7）2005 年Hadoop 作为 Lucene的子项目 Nutch的一部分正式引入Apache基金会。2006 年 3 月份，Map-Reduce和Nutch Distributed File System (NDFS) 分别被纳入称为 Hadoop 的项目中 </p><p>8）名字来源于Doug Cutting儿子的玩具大象</p><p>9）Hadoop就此诞生并迅速发展，标志这云计算时代来临</p><h4 id="3、Hadoop三大发行版本"><a href="#3、Hadoop三大发行版本" class="headerlink" title="3、Hadoop三大发行版本"></a>3、Hadoop三大发行版本</h4><p>Apache、Cloudera、Hortonworks</p><p>1）Apache版本最原始（最基础）的版本，对于入门学习最好。</p><p>2）Cloudera在大型互联网企业中用的较多。</p><ul><li><p>2008年成立的Cloudera是最早将Hadoop商用的公司，为合作伙伴提供Hadoop的商用解决方案，主要是包括支持、咨询服务、培训。</p></li><li><p>2009年Hadoop的创始人Doug Cutting也加盟Cloudera公司。Cloudera产品主要为CDH，Cloudera Manager，Cloudera Support</p></li><li>CDH是Cloudera的Hadoop发行版，完全开源，比Apache Hadoop在兼容性，安全性，稳定性上有所增强</li><li>Cloudera Manager是集群的软件分发及管理监控平台，可以在几个小时内部署好一个Hadoop集群，并对集群的节点及服务进行实时监控。Cloudera Support即是对Hadoop的技术支持。</li><li>Cloudera的标价为每年每个节点4000美元。Cloudera开发并贡献了可实时处理大数据的Impala项目。</li></ul><p>3）Hortonworks文档较好。</p><ul><li>2011年成立的Hortonworks是雅虎与硅谷风投公司Benchmark Capital合资组建。</li><li>公司成立之初就吸纳了大约25名至30名专门研究Hadoop的雅虎工程师，上述工程师均在2005年开始协助雅虎开发Hadoop，贡献了Hadoop80%的代码。</li><li>雅虎工程副总裁、雅虎Hadoop开发团队负责人Eric Baldeschwieler出任Hortonworks的首席执行官。</li><li>Hortonworks的主打产品是Hortonworks Data Platform（HDP），也同样是100%开源的产品，HDP除常见的项目外还包括了Ambari，一款开源的安装和管理系统。</li><li>HCatalog，一个元数据管理系统，HCatalog现已集成到Facebook开源的Hive中。Hortonworks的Stinger开创性的极大的优化了Hive项目。Hortonworks为入门提供了一个非常好的，易于使用的沙盒。</li><li>Hortonworks开发了很多增强特性并提交至核心主干，这使得Apache Hadoop能够在包括Window Server和Windows Azure在内的microsoft Windows平台上本地运行。定价以集群为基础，每10个节点每年为12500美元。</li></ul><h4 id="4、Hadoop的优势"><a href="#4、Hadoop的优势" class="headerlink" title="4、Hadoop的优势"></a>4、Hadoop的优势</h4><p>1）<strong>高可靠性</strong>：因为Hadoop假设计算元素和存储会出现故障，因为它维护多个工作数据副本，在出现故障时可以对失败的节点重新分布处理。</p><p>2）<strong>高扩展性</strong>：在集群间分配任务数据，可方便的扩展数以千计的节点。</p><p>3）<strong>高效性</strong>：在MapReduce的思想下，Hadoop是并行工作的，以加快任务处理速度。</p><p>4）<strong>高容错性</strong>：自动保存多份副本数据，并且能够自动将失败的任务重新分配。</p><h4 id="5、Hadoop组成"><a href="#5、Hadoop组成" class="headerlink" title="5、Hadoop组成"></a>5、Hadoop组成</h4><h5 id="5-1-HDFS架构概述"><a href="#5-1-HDFS架构概述" class="headerlink" title="5.1 HDFS架构概述"></a>5.1 HDFS架构概述</h5><p>1）<strong>NameNode（nn）</strong>：存储文件的元数据，如文件名，文件目录结构，文件属性（生成时间、副本数、文件权限），以及每个文件的块列表和块所在的DataNode等。</p><p>2）<strong>DataNode(dn)</strong>：在本地文件系统存储文件块数据，以及块数据的校验和。</p><p>3）<strong>Secondary NameNode(2nn)</strong>：用来监控HDFS状态的辅助后台程序，每隔一段时间获取HDFS元数据的快照。</p><h5 id="5-2-YARN架构概述"><a href="#5-2-YARN架构概述" class="headerlink" title="5.2 YARN架构概述"></a>5.2 YARN架构概述</h5><p>1）<strong>ResourceManager(rm)</strong>：处理客户端请求、启动/监控ApplicationMaster、监控NodeManager、资源分配与调度。</p><p>2）<strong>NodeManager(nm)</strong>：单个节点上的资源管理、处理来自ResourceManager的命令、处理来自ApplicationMaster的命令。</p><p>3）<strong>ApplicationMaster</strong>：数据切分、为应用程序申请资源，并分配给内部任务、任务监控与容错。</p><p>4）<strong>Container</strong>：对任务运行环境的抽象，封装了CPU、内存等多维资源以及环境变量、启动命令等任务运行相关的信息。</p><h5 id="5-3-MapReduce架构概述"><a href="#5-3-MapReduce架构概述" class="headerlink" title="5.3 MapReduce架构概述"></a>5.3 MapReduce架构概述</h5><p>MapReduce将计算过程分为两个阶段：Map和Reduce</p><p>1）Map阶段并行处理输入数据</p><p>2）Reduce阶段对Map结果进行汇总</p><h4 id="6、大数据技术生态体系"><a href="#6、大数据技术生态体系" class="headerlink" title="6、大数据技术生态体系"></a>6、大数据技术生态体系</h4><p><img src="http://phsyg9eyi.bkt.clouddn.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E7%94%9F%E6%80%81%E4%BD%93%E7%B3%BB.jpg" alt=""></p><h4 id="7、推荐系统框架图"><a href="#7、推荐系统框架图" class="headerlink" title="7、推荐系统框架图"></a>7、推荐系统框架图</h4><p><img src="http://phsyg9eyi.bkt.clouddn.com/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E5%9B%BE.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;本人微信公众号，欢迎扫码关注！&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;http://phsyg9eyi.bkt.clouddn.com/introduce2.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;从Hadoop框
      
    
    </summary>
    
      <category term="Hadoop" scheme="http://yoursite.com/categories/Hadoop/"/>
    
    
      <category term="Hadoop" scheme="http://yoursite.com/tags/Hadoop/"/>
    
      <category term="框架" scheme="http://yoursite.com/tags/%E6%A1%86%E6%9E%B6/"/>
    
      <category term="大数据生态" scheme="http://yoursite.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%94%9F%E6%80%81/"/>
    
  </entry>
  
  <entry>
    <title>分享几个能在大学赚钱的案例</title>
    <link href="http://yoursite.com/%E5%88%86%E4%BA%AB%E5%87%A0%E4%B8%AA%E8%83%BD%E5%9C%A8%E5%A4%A7%E5%AD%A6%E8%B5%9A%E9%92%B1%E7%9A%84%E6%A1%88%E4%BE%8B.html"/>
    <id>http://yoursite.com/分享几个能在大学赚钱的案例.html</id>
    <published>2018-11-19T03:02:30.000Z</published>
    <updated>2018-11-19T03:02:30.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>转载自本人微信公众号，欢迎扫码关注！</p></blockquote><p><img src="http://phsyg9eyi.bkt.clouddn.com/introduce2.jpg" alt=""></p><p>上次分享了一位朋友大学期间的赚钱经历，许多人看完之后都特别佩服，其中也包括我。其实在大学能够锻炼自己的机会有很多，有的同学参加了学生会和各种社团，也有的同学参加各种比赛来丰富自己的简历，还有的同学则是在业余时间做各种兼职来锻炼自己，这样不光能赚一些生活费，还能提前接触社会，提升自己各方面的能力。今天就和大家聊一聊我所了解的，能在大学里赚到钱的一些方法和案例。</p><h4 id="1、比赛奖金"><a href="#1、比赛奖金" class="headerlink" title="1、比赛奖金"></a>1、比赛奖金</h4><p>风险指数：无</p><p>难度指数：四颗星</p><p>案例说明：之所以把它放在第一位的原因是，我认为在大学只有把时间和精力花在自己身上才是回报最大的投资，所以，参加比赛无疑是最好的选择之一，它不仅可以锻炼自己各方面的能力，如果获奖的话，除了能丰富简历以外还能拿到素质学分，素质学分高的话就有机会申请国家励志奖学金（5000元），或者国家奖学金（8000元），还有一些校内奖学金等等。凡事有得必有失，这需要你有很强的自我控制能力，合理规划时间的能力，甚至要牺牲自己绝大部分的课余时间，所以我认为还是挺难的，但如果最后能够坚持下来了的话，那你的收获将会是巨大的。</p><h4 id="2、勤工助学"><a href="#2、勤工助学" class="headerlink" title="2、勤工助学"></a>2、勤工助学</h4><p>风险指数：无</p><p>难度指数：二颗星</p><p>案例说明：说到勤工助学，让我想起了中学时期的一位同学，记得有一次我和舍友到食堂有些晚了，吃饭的时候无意中看见他在食堂打扫卫生，他当时也看见了我们，但是让我们惊讶的是他竟然很热心的跟我们几个打了招呼，我当时真的很佩服他，如果换做自己绝对不会那么从容，后来我们才知道，他不是因为家庭条件不好才去做的勤工助学，而是因为他觉得自己已经有能力靠自己养活自己了，不该再向家里要钱了。这种精神真的让我们很敬佩，同样的年纪，思想境界竟然有这么大的差别。</p><p>所以，勤工助学不是一件什么丢人的事，在大学也有很多的勤工助学岗位，比如布置各种考试的考场，维护机房，做老师的助教等等，如果不知道的话，你可以去请教你的学姐学长或者老师。这样你不仅可以改善自己的生活，还可以学习到好多技能，接触一些你从未接触过的事物，对自己也有很大的提高。</p><h4 id="3、补习班、家教"><a href="#3、补习班、家教" class="headerlink" title="3、补习班、家教"></a>3、补习班、家教</h4><p>风险指数：一颗星</p><p>难度指数：三颗星</p><p>案例说明：这个就不用多说了，但是有一点千万要注意，就是学会辨别黑心中介，有些黑心中介打着介绍兼职的旗号专门骗大学生的钱，因为大学生涉世未深，心里防范度低，很容易被骗，如果遇到什么先交押金之类的千万别信，要学会保护自己。最好让你信任的并且做过的同学或者学长学姐推荐，因为他们有经验，所以你听过他们的评价之后再做决定也不迟。</p><h4 id="4、教育机构代理"><a href="#4、教育机构代理" class="headerlink" title="4、教育机构代理"></a>4、教育机构代理</h4><p>风险指数：一颗星</p><p>难度指数：三颗星</p><p>案例说明：这个相信大部分同学也有所了解，我简单再介绍一下，很多考研机构，计算机考试培训机构，公务员考试培训机构，·驾校等等，他们为了招收更多的学生，通常会在学校找一些人做代理，因为学生更了解学生的需求，但是最好做大品牌机构的代理，因为如果他们不靠谱，那么会大大损失你的信誉度，所以千万别坑你的同学，不然你在大学就混不下去了。</p><p>此外，别把代理想象成一件轻松的工作，任何赚钱的工作都不是轻松的，都是需要花费时间和经历的。做代理需要你不停的做宣传，维护你的人脉，和好多人去沟通。同样收入也是很可观的，我大学认识的人里面，做代理月入一万的大有人在。</p><h4 id="5、大学二手教材"><a href="#5、大学二手教材" class="headerlink" title="5、大学二手教材"></a>5、大学二手教材</h4><p>风险指数：二颗星</p><p>难度指数：三颗星</p><p>案例说明：通过废旧的二手教材月入20万，差点儿拿到投资。来自「stormzhang」的付费知识星球。</p><p><img src="http://phsyg9eyi.bkt.clouddn.com/%E5%88%86%E4%BA%AB%E5%87%A0%E4%B8%AA%E8%83%BD%E5%9C%A8%E5%A4%A7%E5%AD%A6%E8%B5%9A%E9%92%B1%E7%9A%84%E6%A1%88%E4%BE%8B005.png" alt=""></p><h4 id="6、新生入学指南"><a href="#6、新生入学指南" class="headerlink" title="6、新生入学指南"></a>6、新生入学指南</h4><p>风险指数：三颗星</p><p>难度指数：四颗星</p><p>案例说明：利用信息差赚钱，月入8万。来自「stormzhang」的付费知识星球。</p><p><img src="http://phsyg9eyi.bkt.clouddn.com/%E5%88%86%E4%BA%AB%E5%87%A0%E4%B8%AA%E8%83%BD%E5%9C%A8%E5%A4%A7%E5%AD%A6%E8%B5%9A%E9%92%B1%E7%9A%84%E6%A1%88%E4%BE%8B004.png" alt=""></p><h4 id="7、游戏"><a href="#7、游戏" class="headerlink" title="7、游戏"></a>7、游戏</h4><p>风险指数：三颗星</p><p>难度指数：五颗星</p><p>案例说明：说到游戏多人都不陌生，有的人甚至大学所有时间都花费在了游戏上面，投入了大量的精力和金钱，那是在玩游戏吗？不是，那是游戏在玩你！你既然那么爱玩游戏怎么不从里面找找商机呢？下面的案例来自「stormzhang」的付费知识星球，利用游戏日入上千。</p><p><img src="http://phsyg9eyi.bkt.clouddn.com/%E5%88%86%E4%BA%AB%E5%87%A0%E4%B8%AA%E8%83%BD%E5%9C%A8%E5%A4%A7%E5%AD%A6%E8%B5%9A%E9%92%B1%E7%9A%84%E6%A1%88%E4%BE%8B003.png" alt=""></p><h4 id="8、薅羊毛"><a href="#8、薅羊毛" class="headerlink" title="8、薅羊毛"></a>8、薅羊毛</h4><p>风险指数：四颗星</p><p>难度指数：五颗星</p><p>案例说明：你眼里普通的优惠券在别人眼里就是能月入30万的生意。来自「stormzhang」的付费知识星球。</p><p><img src="http://phsyg9eyi.bkt.clouddn.com/%E5%88%86%E4%BA%AB%E5%87%A0%E4%B8%AA%E8%83%BD%E5%9C%A8%E5%A4%A7%E5%AD%A6%E8%B5%9A%E9%92%B1%E7%9A%84%E6%A1%88%E4%BE%8B002.jpg" alt=""></p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>有些人在大学往往干什么都是成群结队，即使有自己想做的事最后也因为同伴不愿意而放弃了，然而还有些人总喜欢独来独往，看起来和我们不太一样，但正是这些「独行」的人往往非常优秀，往往更能守住自己的节奏。</p><p>所以，你想到什么就大胆的干吧，一刻也别犹豫，年轻就是资本，年轻就有了更多试错的机会，你本一无所有，还在乎失去吗？大不了重新来过！大学就应该无限精彩，千万别庸庸碌碌的度过。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;转载自本人微信公众号，欢迎扫码关注！&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;http://phsyg9eyi.bkt.clouddn.com/introduce2.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;上次分享了一位朋友大
      
    
    </summary>
    
      <category term="云端笑猿" scheme="http://yoursite.com/categories/%E4%BA%91%E7%AB%AF%E7%AC%91%E7%8C%BF/"/>
    
    
      <category term="大学" scheme="http://yoursite.com/tags/%E5%A4%A7%E5%AD%A6/"/>
    
      <category term="赚钱" scheme="http://yoursite.com/tags/%E8%B5%9A%E9%92%B1/"/>
    
      <category term="兼职" scheme="http://yoursite.com/tags/%E5%85%BC%E8%81%8C/"/>
    
      <category term="案例" scheme="http://yoursite.com/tags/%E6%A1%88%E4%BE%8B/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop系列001-大数据概论</title>
    <link href="http://yoursite.com/Hadoop%E7%B3%BB%E5%88%97001-%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A6%82%E8%AE%BA.html"/>
    <id>http://yoursite.com/Hadoop系列001-大数据概论.html</id>
    <published>2018-11-19T02:10:49.000Z</published>
    <updated>2018-11-19T02:10:49.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本人微信公众号，欢迎扫码关注！</p></blockquote><p><img src="http://phsyg9eyi.bkt.clouddn.com/introduce2.jpg" alt=""></p><h2 id="大数据概论"><a href="#大数据概论" class="headerlink" title="大数据概论"></a>大数据概论</h2><h3 id="1、大数据概念"><a href="#1、大数据概念" class="headerlink" title="1、大数据概念"></a>1、大数据概念</h3><p>大数据（big data），指无法在一定时间范围内用常规软件工具进行捕捉、管理和处理的数据集合，是需要新处理模式才能具有更强的决策力、洞察发现力和流程优化能力的海量、高增长率和多样化的信息资产。</p><p>最小的基本单位是bit，按顺序给出所有单位：bit、Byte、KB、MB、GB、TB、PB、EB、ZB、YB、BB、NB、DB。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1Byte = 8bit1K = 1024bit1MB = 1024K1G = 1024M</span><br><span class="line">1T = 1024G1P = 1024T1E = 1024P1Z = 1024E</span><br><span class="line">1Y = 1024Z1B = 1024Y1N = 1024B1D = 1024N</span><br></pre></td></tr></table></figure><h3 id="2、大数据的特点"><a href="#2、大数据的特点" class="headerlink" title="2、大数据的特点"></a>2、大数据的特点</h3><h4 id="1）Volume（大量）"><a href="#1）Volume（大量）" class="headerlink" title="1）Volume（大量）"></a>1）Volume（大量）</h4><p>截至目前，人类生产的所有印刷材料的数据量是200PB，而历史上全人类总共说过的话的数据量大约是5EB。当前，典型个人计算机硬盘的容量为TB量级，而一些大企业的数据量已经接近EB量级。</p><h4 id="2）Velocity（高速）"><a href="#2）Velocity（高速）" class="headerlink" title="2）Velocity（高速）"></a>2）Velocity（高速）</h4><p>这是大数据区分于传统数据挖掘的最显著特征。根据IDC的“数字宇宙”的报告，预计到2020年，全球数据使用量将达到35.2ZB。在如此海量的数据面前，处理数据的效率就是企业的生命。</p><p>天猫双十一：2016年6分58秒，天猫交易额超过100亿</p><h4 id="3）Variety（多样）"><a href="#3）Variety（多样）" class="headerlink" title="3）Variety（多样）"></a>3）Variety（多样）</h4><p>这种类型的多样性也让数据被分为结构化数据和非结构化数据。相对于以往便于存储的以数据库/文本为主的结构化数据，非结构化数据越来越多，包括网络日志、音频、视频、图片、地理位置信息等，这些多类型的数据对数据的处理能力提出了更高要求。</p><h4 id="4）Value（低价值密度）"><a href="#4）Value（低价值密度）" class="headerlink" title="4）Value（低价值密度）"></a>4）Value（低价值密度）</h4><p>价值密度的高低与数据总量的大小成反比。比如，在一天监控视频中，我们只关心老师晚上在床上健身那一分钟，如何快速对有价值数据“提纯”成为目前大数据背景下待解决的难题。</p><h3 id="3、大数据的应用场景"><a href="#3、大数据的应用场景" class="headerlink" title="3、大数据的应用场景"></a>3、大数据的应用场景</h3><p>1）O2O：百度大数据+平台通过先进的线上线下打通技术和客流分析能力，助力商家精细化运营，提升销量。</p><p>2）零售：探索用户价值，提供个性化服务解决方案；贯穿网络与实体零售，携手创造极致体验。经典案例，子尿布+啤酒。</p><p>3）旅游：深度结合百度独有大数据能力与旅游行业需求，共建旅游产业智慧管理、智慧服务和智慧营销的未来。</p><p>4）商品广告推荐：给用户推荐访问过的商品广告类型</p><p>5） 房产：大数据全面助力房地产行业，打造精准投策与营销，选出更合适的地，建造更合适的楼，卖给更合适的人。</p><p>6）保险：海量数据挖掘及风险预测，助力保险行业精准营销，提升精细化定价能力。</p><p>7）金融：多维度体现用户特征，帮助金融机构推荐优质客户，防范欺诈风险。</p><p>8）移动联通：移动联通：根据用户年龄、职业、消费情况，分析统计哪种套餐适合哪类人群。对市场人群精准定制。</p><p>9）人工智能</p><h3 id="4、大数据的发展前景"><a href="#4、大数据的发展前景" class="headerlink" title="4、大数据的发展前景"></a>4、大数据的发展前景</h3><p>1）党的十八届五中全会提出“实施国家大数据战略”，国务院印发《促进大数据发展行动纲要》，大数据技术和应用处于创新突破期，国内市场需求处于爆发期，我国大数据产业面临重要的发展机遇。</p><p>2）国际数据公司IDC预测，到2020年，企业基于大数据计算分析平台的支出将突破5000亿美元。目前，我国大数据人才只有46万，未来3到5年人才缺口达150万之多。</p><ul><li>人才缺口计算<br>150w-40w=110w<br>110W/5年 = 22w/年<br>22w/12月=1.83w/月<br>自古不变的真理：先入行者吃肉，后入行者喝汤，最后到的买单！</li></ul><p>3）2017年北京大学、中国人民大学、北京邮电大学等25所高校成功申请开设大数据课程。</p><p>4）大数据属于高新技术，大牛少，升职竞争小；</p><p>5）在北京大数据开发工程师的平均薪水已经到17800元（数据统计来职友集），而且目前还保持强劲的发展势头。</p><h3 id="5、企业数据部的业务流程分析"><a href="#5、企业数据部的业务流程分析" class="headerlink" title="5、企业数据部的业务流程分析"></a>5、企业数据部的业务流程分析</h3><p><img src="http://phsyg9eyi.bkt.clouddn.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A6%82%E8%AE%BA001.png" alt=""></p><h3 id="6、企业数据部的一般组织结构"><a href="#6、企业数据部的一般组织结构" class="headerlink" title="6、企业数据部的一般组织结构"></a>6、企业数据部的一般组织结构</h3><p><img src="http://phsyg9eyi.bkt.clouddn.com/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A6%82%E8%AE%BA002.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;本人微信公众号，欢迎扫码关注！&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;http://phsyg9eyi.bkt.clouddn.com/introduce2.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;大数据概论&quot;&gt;&lt;
      
    
    </summary>
    
      <category term="Hadoop" scheme="http://yoursite.com/categories/Hadoop/"/>
    
    
      <category term="Hadoop" scheme="http://yoursite.com/tags/Hadoop/"/>
    
      <category term="大数据" scheme="http://yoursite.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>大学里月入1万的经历</title>
    <link href="http://yoursite.com/%E5%A4%A7%E5%AD%A6%E9%87%8C%E6%9C%88%E5%85%A51%E4%B8%87%E7%9A%84%E7%BB%8F%E5%8E%86.html"/>
    <id>http://yoursite.com/大学里月入1万的经历.html</id>
    <published>2018-11-07T02:10:30.000Z</published>
    <updated>2018-11-07T02:10:30.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>转载自本人微信公众号，欢迎扫码关注！</p></blockquote><p><img src="http://phsyg9eyi.bkt.clouddn.com/introduce2.jpg" alt=""></p><p>前几天在一个付费知识星球中结识了一位朋友，他就读于南方一所大学，现在已经毕业了，由于和我学的是同一个专业，所以聊得很投缘。开始我们聊了挺多专业问题，后来聊到了大学赚钱，他从大一开始就属于那种对赚钱有很多想法的人，做过许多兼职，在大三的时候，不到半学期就挣了三万多，平均月入一万，听了他的赚钱经历之后非常感慨，也非常佩服他。</p><p>我不光佩服他能在大学就挣那么多钱，更佩服他的坚持和商业头脑，实话说他所做的那些赚钱项目我也有所了解，有的也见过身边的朋友在做，甚至其中一个我也实践过，但是都没有坚持下来，今天就和大家分享一下这位朋友大学里的赚钱经历，我把我们聊的内容整理了一下，后续内容采用第一人称和大家讲述，后文中的「我」即代表「我的那位朋友」。</p><p>谈话内容：</p><p>从大一开始我就对赚钱比较有想法，应该是比较穷吧，哈哈。。。大一的时候做过几次发传单和服务员的兼职，又累挣得又少，在大二的时候通过学长介绍开始做托福家教，一个小时120，其实我托福也不太好，满分120，我只考了100出头，但是教70分以下的学生还是绰绰有余的。在我们这边，大学生家教，教托福，120一个小时是很正常的收入，如果是专业的老师，比如新东方的老师，哪怕水平一般，要价都要比这贵很多。我每周收入600块，从此过上了优渥的大学生活，哈哈。。。这个兼职一直持续到大三，发现了赚钱更多的门路就不再做了。</p><p>大三的时候，偶然机会，遇到一个朋友做毕业设计中介。问我会不会做Android和J2EE相关毕业设计，这个当然会啦，毕竟学的就是这个专业嘛，平时在学校就和同学做过很多项目，做起来轻车熟路。然后我就推掉了家教的兼职，开始做毕业设计，不到半学期做了30多个，因为有的功能都差不多，稍微改改就行了。价格600-1200不等，带后台就1000以上。听我那个朋友说，厉害的中介，辛苦半年，可以赚100w。这个需求特别大，比如我们学校好多人，在大学几年，完全混过来的。毕业时随便花几百上千块钱，买个作品和论文，答辩就可以过了。</p><p>大三下学期的时候，我一学长在外面接了一所驾校的总代，因为我们学校有多个校区，他想让我帮他做我所在校区的代理，然后我这边的单子分成给我，假设我这边出去的单子，驾校给他10%，我拿其中7%，我当时也是第一次做，不怎么懂，但我是个重朋友的人，就接下了这个活。</p><p>我当时找了几个本校区的朋友，先自己垫钱请大家出来吃饭聊聊，然后说了这个事，哥们都表示支持，然后一些事就是各种宣传了，比如赞助学生会活动横幅啥的，QQ群啥的，到后来我把更多时间放在了学习上，因为我要准备实习的事情了，这件事就交给学弟做了，后来算了下，我这边总共做了100个单子左右，赚了几千块钱吧，赚钱之后首先在一开始的那个哥们群里发了个大红包。</p><p>结束语：</p><p>和这位朋友聊了挺多，赚钱的例子也谈了挺多，上面的属于专业知识比较强的人才能做，而且像代做毕业设计严格来说是违法的，最好不要轻易尝试。后续如果大家感兴趣的话，我把其他不需要太强的专业知识，也能在大学实际操作的赚钱例子跟大家分享一下，今天就到这里，如果大家有什么想法可以在下面留言，或者在公众号后台回复我，和我交流。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;转载自本人微信公众号，欢迎扫码关注！&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;http://phsyg9eyi.bkt.clouddn.com/introduce2.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;前几天在一个付费知识
      
    
    </summary>
    
      <category term="云端笑猿" scheme="http://yoursite.com/categories/%E4%BA%91%E7%AB%AF%E7%AC%91%E7%8C%BF/"/>
    
    
      <category term="大学" scheme="http://yoursite.com/tags/%E5%A4%A7%E5%AD%A6/"/>
    
      <category term="赚钱" scheme="http://yoursite.com/tags/%E8%B5%9A%E9%92%B1/"/>
    
      <category term="兼职" scheme="http://yoursite.com/tags/%E5%85%BC%E8%81%8C/"/>
    
  </entry>
  
  <entry>
    <title>如何将项目上传到GitHub</title>
    <link href="http://yoursite.com/%E5%A6%82%E4%BD%95%E5%B0%86%E9%A1%B9%E7%9B%AE%E4%B8%8A%E4%BC%A0%E5%88%B0GitHub.html"/>
    <id>http://yoursite.com/如何将项目上传到GitHub.html</id>
    <published>2018-11-01T08:46:04.000Z</published>
    <updated>2018-11-01T08:46:04.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本人微信公众号「intflags」，欢迎扫码关注！</p></blockquote><p><img src="http://phsyg9eyi.bkt.clouddn.com/introduce2.jpg" alt=""></p><h2 id="如何将项目上传到GitHub？"><a href="#如何将项目上传到GitHub？" class="headerlink" title="如何将项目上传到GitHub？"></a>如何将项目上传到GitHub？</h2><h3 id="1、注册GitHub账户"><a href="#1、注册GitHub账户" class="headerlink" title="1、注册GitHub账户"></a>1、注册GitHub账户</h3><ul><li>浏览器输入GitHub官网地址：<a href="https://github.com/" target="_blank" rel="noopener">https://github.com/</a></li><li>进入后点击Sign In<br><img src="http://phsyg9eyi.bkt.clouddn.com/GitHub01.png" alt=""></li><li>然后点击Create an account<br><img src="http://phsyg9eyi.bkt.clouddn.com/GitHub02.png" alt=""></li><li>然后输入用户名、密码、邮箱等信息，用户名一定要简短好记，因为这个用户名关系到以后你的个性域名。<br><img src="http://phsyg9eyi.bkt.clouddn.com/GitHub03.png" alt=""></li><li>按照系统提示，一步步将信息填写完毕后就OK了，如果中途遇到问题，可以复制提示信息到百度翻译查一下。此后遇到类似问题也一样，因为好多工具或者开源框架官网都是英文的。<h3 id="2、安装Git客户端"><a href="#2、安装Git客户端" class="headerlink" title="2、安装Git客户端"></a>2、安装Git客户端</h3></li><li><p>下载Git客户端，官方地址：<a href="https://git-scm.com/download/win" target="_blank" rel="noopener">https://git-scm.com/download/win</a></p></li><li><p>双击安装包进行安装</p><p><img src="http://phsyg9eyi.bkt.clouddn.com/GitHub04.png" alt=""></p><p><img src="http://phsyg9eyi.bkt.clouddn.com/GitHub05.png" alt=""></p><p><img src="http://phsyg9eyi.bkt.clouddn.com/GitHub06.png" alt=""></p><p><img src="http://phsyg9eyi.bkt.clouddn.com/GitHub07.png" alt=""></p><p><img src="http://phsyg9eyi.bkt.clouddn.com/GitHub08.png" alt=""></p><p><img src="http://phsyg9eyi.bkt.clouddn.com/GitHub09.png" alt=""></p><p><img src="http://phsyg9eyi.bkt.clouddn.com/GitHub10.png" alt=""></p><p><img src="http://phsyg9eyi.bkt.clouddn.com/GitHub11.png" alt=""></p><p><img src="http://phsyg9eyi.bkt.clouddn.com/GitHub12.png" alt=""></p></li><li><p>安装完毕</p><h3 id="3、在GitHub上创建项目"><a href="#3、在GitHub上创建项目" class="headerlink" title="3、在GitHub上创建项目"></a>3、在GitHub上创建项目</h3></li><li>新建仓库<br><img src="http://phsyg9eyi.bkt.clouddn.com/GitHub13.png" alt=""></li><li>填写项目信息<br><img src="http://phsyg9eyi.bkt.clouddn.com/GitHub14.png" alt=""></li><li>创建完毕<br><img src="http://phsyg9eyi.bkt.clouddn.com/GitHub15.png" alt=""><h3 id="4、使用Git命令提交项目到GitHub"><a href="#4、使用Git命令提交项目到GitHub" class="headerlink" title="4、使用Git命令提交项目到GitHub"></a>4、使用Git命令提交项目到GitHub</h3></li><li>打开要上传的项目的工作路径，在目录空白处鼠标右键<br><img src="http://phsyg9eyi.bkt.clouddn.com/GitHub16.png" alt=""></li><li>点击Git Bash Here打开Git命令行界面<br><img src="http://phsyg9eyi.bkt.clouddn.com/GitHub17.png" alt=""></li><li>输入命令：<strong>git init</strong> 初始化项目<br><img src="http://phsyg9eyi.bkt.clouddn.com/GitHub18.png" alt=""></li><li>输入命令：<strong>git add .</strong> 将该目录下所有文件加入本地暂存区，注意命令后面有一个.代表将所有文件添加到暂存区，如果只想将个别提交，那么将.换成文件名即可。<br><img src="http://phsyg9eyi.bkt.clouddn.com/GitHub19.png" alt=""></li><li>输入命令：<strong>git status</strong> 查看状态，该命令会将工作空间中的版本与暂存区的版本进行对比，我下面的状态是已经把所有文件加入到了暂存区中，但是还没有提交到本地历史区。<br><img src="http://phsyg9eyi.bkt.clouddn.com/GitHub20.png" alt=""></li><li>输入命令：<strong>git commit -m “项目注释”</strong><br><img src="http://phsyg9eyi.bkt.clouddn.com/GitHub21.png" alt=""></li><li>输入命令：<strong>git remote add origin <a href="https://github.com/intflag/SayLOVE.git" target="_blank" rel="noopener">https://github.com/intflag/SayLOVE.git</a></strong> 该命令是把本地历史区中的文件添加到github服务器的暂存区中。这一步是本地和远程服务器建立联系的一步。执行成功后不会显示任何结果。<br><img src="http://phsyg9eyi.bkt.clouddn.com/GitHub22.png" alt=""></li><li>输入命令：<strong>git pull origin master</strong> 该命令是先把github上的文件拉下来，注意在每次提交之前要首先进行pull，这是防止冲突。<strong>如果报错，只要输入git pull origin master –allow-unrelated-histories 即可</strong><br><img src="http://phsyg9eyi.bkt.clouddn.com/GitHub23.png" alt=""></li><li>上述执行成功后，发现在项目目录下多了一个“README.md”文件，这个文件就是从github上拉下来的。因为我们在github上创建repository的时候就创建了这个“README.md”文件，该文件是对这个repository的说明。<br><img src="http://phsyg9eyi.bkt.clouddn.com/GitHub24.png" alt=""></li><li>输入命令：<strong>git push -u origin master</strong> 这一步是真正向github提交，执行完成后，github上的repository就有和你本地一样的代码文件了。<br><img src="http://phsyg9eyi.bkt.clouddn.com/GitHub25.png" alt=""></li><li>执行完毕后到GitHub上查看结果。<br><img src="http://phsyg9eyi.bkt.clouddn.com/GitHub26.png" alt=""></li><li>此时，项目就提交完毕了。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;本人微信公众号「intflags」，欢迎扫码关注！&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;http://phsyg9eyi.bkt.clouddn.com/introduce2.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h2 id
      
    
    </summary>
    
      <category term="IDE&amp;工具" scheme="http://yoursite.com/categories/IDE-%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="GitHub" scheme="http://yoursite.com/tags/GitHub/"/>
    
      <category term="项目上传" scheme="http://yoursite.com/tags/%E9%A1%B9%E7%9B%AE%E4%B8%8A%E4%BC%A0/"/>
    
  </entry>
  
  <entry>
    <title>防民之口，慎于防川！谈谈遇害的沙特记者</title>
    <link href="http://yoursite.com/%E9%98%B2%E6%B0%91%E4%B9%8B%E5%8F%A3%EF%BC%8C%E6%85%8E%E4%BA%8E%E9%98%B2%E5%B7%9D%EF%BC%81%E8%B0%88%E8%B0%88%E9%81%87%E5%AE%B3%E7%9A%84%E6%B2%99%E7%89%B9%E8%AE%B0%E8%80%85.html"/>
    <id>http://yoursite.com/防民之口，慎于防川！谈谈遇害的沙特记者.html</id>
    <published>2018-10-31T10:28:17.000Z</published>
    <updated>2018-10-31T10:28:17.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>转载自本人微信公众号「intflags」，欢迎扫码关注！</p></blockquote><p><img src="http://phsyg9eyi.bkt.clouddn.com/introduce2.jpg" alt=""></p><p>卡舒吉是沙特阿拉伯的一位记者，他的经历很传奇，不仅和老一辈的沙特王室权贵都搭得上，还了解沙特王室的很多秘密，在1980年代和1990年代，他曾几次采访本拉登，为此，他名声大噪。后来拿了美国签证，还成为「华盛顿邮报」的专栏记者。</p><p><img src="http://phsyg9eyi.bkt.clouddn.com/%E5%8D%A1%E8%88%92%E5%90%8904.jpg" alt="2018年9月29日，英国伦敦，沙特记者贾迈勒·卡舒吉出席《中东箴言报》举办的活动。图片来源：视觉中国"></p><p>在任职华盛顿专栏记者期间，他利用美国媒体的影响力，多次公开痛批沙特国王「小萨勒曼」和王储，反对他们的对外政策，并且揭露沙特的腐败，所以沙特国王对他恨之入骨。</p><p>2018年10月2日，卡舒吉进入伊斯坦布尔的沙特领事馆办理离婚证明，以便与土耳其女子结婚，可是进去之后就再也没有出来，他被沙特国王小萨勒曼派出的15名特工残忍杀害，是被肢解的，而且还是在他意识清醒的情况下，让他看着自己的身体被肢解，特别残暴变态。</p><p><img src="http://phsyg9eyi.bkt.clouddn.com/%E5%8D%A1%E8%88%92%E5%90%8903.png" alt="图右：卡舒吉，图片素材来源：新闻片段截图"></p><p>这件事全球都在关注，主要在于人权，在如今的文明社会还会发生这样的暴行简直令人震惊，虽然看起来和我们毫无关系，但是人权是全球的事。</p><p>看了这个新闻以后让我想起著名历史老师「石国鹏」讲过的一个典故「防民之口，甚于防川」，说西周末年的一位君主叫做「周厉王」，为了决定增加赋税，维持花天酒地的生活，他对一些重要物产征收“专利税”。不论是王公大臣还是平民百姓，只要他们采药、砍柴，捕鱼虾、射鸟兽，都必须纳税；甚至喝水、走路也得缴纳钱物。</p><p>周厉王残暴无道，老百姓纷纷责骂他。邵公对厉王说，老百姓已不堪忍受暴虐的政令啦！厉王听了勃然大怒，找到一个卫国的巫者，只要有人说他坏话，就会暗中杀害他们。老百姓怨声载道，不敢说话，用眼神表达自己的愤怒。周厉王自鸣得意，以为这样就可以堵住老百姓的悠悠之口。</p><p>邵公对厉王说：你这样做只能堵住人们的嘴。可是防范老百姓的嘴，比防备河水泛滥更不易。河道因堵塞而造成决口，就会伤害很多人。倘使堵住老百姓的口，后果也将如此。可是厉王根本不听，三年后，百姓忍无可忍，心中的怨气累积到顶点，终于导致国人暴动，周厉王被赶出国都，最后死在了彘[zhì]地。</p><p>中国人在三千年前就说过「防民之口，甚于防川」这样的话。以史为鉴，可以知得失。民意乃最大的天意，像沙特这样失去民意的国家，早晚会自取灭亡。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;转载自本人微信公众号「intflags」，欢迎扫码关注！&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;http://phsyg9eyi.bkt.clouddn.com/introduce2.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;
      
    
    </summary>
    
      <category term="云端笑猿" scheme="http://yoursite.com/categories/%E4%BA%91%E7%AB%AF%E7%AC%91%E7%8C%BF/"/>
    
    
      <category term="沙特" scheme="http://yoursite.com/tags/%E6%B2%99%E7%89%B9/"/>
    
      <category term="卡舒吉" scheme="http://yoursite.com/tags/%E5%8D%A1%E8%88%92%E5%90%89/"/>
    
      <category term="遇害记者" scheme="http://yoursite.com/tags/%E9%81%87%E5%AE%B3%E8%AE%B0%E8%80%85/"/>
    
      <category term="言论自由" scheme="http://yoursite.com/tags/%E8%A8%80%E8%AE%BA%E8%87%AA%E7%94%B1/"/>
    
  </entry>
  
  <entry>
    <title>我和小伙伴在北京的租房经历</title>
    <link href="http://yoursite.com/%E6%88%91%E5%92%8C%E5%B0%8F%E4%BC%99%E4%BC%B4%E5%9C%A8%E5%8C%97%E4%BA%AC%E7%9A%84%E7%A7%9F%E6%88%BF%E7%BB%8F%E5%8E%86.html"/>
    <id>http://yoursite.com/我和小伙伴在北京的租房经历.html</id>
    <published>2018-10-29T08:19:41.000Z</published>
    <updated>2018-10-29T08:19:41.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>转载自本人微信公众号「intflags」，欢迎扫码关注！</p></blockquote><p><img src="http://phsyg9eyi.bkt.clouddn.com/introduce2.jpg" alt=""></p><p>时间过得真快，来北京生活和工作已经20多天了，虽然之前也有来过，但那是来参赛，有老师的陪同，食宿也都由举办方安排，什么都不用操心，只要专心比赛就行，回想起来简直爽歪歪。</p><p>其实自己独立生活也什么大不了，相信各位和我一样，在上大学之前就已经有好几年的住校经验了。虽然这样说，但租房这件事可非同小可，尽量提前计划好。今天就和大家说说租房的一些注意事项。</p><p>在经济充足的情况下尽量找正规中介，看中介是否具备以下证明手续：工商部门颁发的营业执照、在房地产管理部门办理备案手续的证明、房地产管理部门颁发的房地产经纪机构资质证书、税务部门颁发的税务登记证。如果这些你没办法搞清楚的话，那就找目前市场上规模最大的、口碑最好的。</p><p>中介房源比较多，可供挑选，不用到处奔忙去找房源，只要你把需求提出来，就会给你推荐适合你的房子。中介会和房东协商好价格、压金、租金之类，而且大型的中介公司的房源价格基本是固定的，不用讨价还价，当然价格会高一些。中介公司有比较正规的租房合同，并作为第三方，公平公正的验收房子、查看所租房子里物品、结清之前的物业、水电费等。但条件是要出一个月房租来当中介费。</p><p>中介只是相对来说安全一点儿，不要轻信任何中介，多留点儿心眼，必要时可以用手机录音。</p><p>千万不要找二房东，不安全！如何区分呢？先打电话，直接问他是中介还是房东， 如果他说房东，那就问他这房子是你的吗？有没房产证等等详细的问题，总之尽量避免跟二房东租房，如果万一你把房租交给了他，而他却跑路了，那么你和真正的房东之间就会产生一些不必要的纠纷。</p><p>一定要提前选定租房的位置，在市内还是在郊区，位于几环等等。然后搞清楚交通情况，用地图软件查看距地铁站的时间，到你的工作地点一共需要的时间。尤其在实际的看房过程中要注意周围环境，有没有超市、餐馆、药店或医院等等。但是有一点要清楚，地段越好房租越贵，这是永远不变的真理，所以要结合自身的经济状况去选择租房的位置，开始难免会艰苦一点儿，但这就是生活对你的考验，正因为如此你才更应该努力奋斗，靠自己的能力改变生活环境。放几张图让你们看看北京早高峰时候的地铁。<br><img src="http://phsyg9eyi.bkt.clouddn.com/%E6%88%91%E5%92%8C%E5%B0%8F%E4%BC%99%E4%BC%B4%E5%9C%A8%E5%8C%97%E4%BA%AC%E7%9A%84%E7%A7%9F%E6%88%BF%E7%BB%8F%E5%8E%8605.jpeg" alt="拥挤的地铁"><br><img src="http://phsyg9eyi.bkt.clouddn.com/%E6%88%91%E5%92%8C%E5%B0%8F%E4%BC%99%E4%BC%B4%E5%9C%A8%E5%8C%97%E4%BA%AC%E7%9A%84%E7%A7%9F%E6%88%BF%E7%BB%8F%E5%8E%8602.jpeg" alt="拥挤的地铁"><br>当上面所有事宜你都了解清楚，并去看了房，然后也比较有意向，准备签合同的时候你要注意了，必须要有正规的租房合同，并且看清楚条款，如果不懂可以先在网上看看别人的，千万不要“被贷款”，关于这个话题可以从网查看详细说明。<br><img src="http://phsyg9eyi.bkt.clouddn.com/%E6%88%91%E5%92%8C%E5%B0%8F%E4%BC%99%E4%BC%B4%E5%9C%A8%E5%8C%97%E4%BA%AC%E7%9A%84%E7%A7%9F%E6%88%BF%E7%BB%8F%E5%8E%8603.jpeg" alt="租房被网贷"><br>找房不容易意，租房需谨慎，在没有考虑清楚之前，千万别轻易签合同。没签之前，你是爷，签了之后，人家是爷。一旦上当受骗，要冷静处理，合理维护自身权益！最后把我们租房时记录的详细注意事项分享给大家。<br><img src="http://phsyg9eyi.bkt.clouddn.com/%E6%88%91%E5%92%8C%E5%B0%8F%E4%BC%99%E4%BC%B4%E5%9C%A8%E5%8C%97%E4%BA%AC%E7%9A%84%E7%A7%9F%E6%88%BF%E7%BB%8F%E5%8E%8604.jpeg" alt="租房注意事项"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;转载自本人微信公众号「intflags」，欢迎扫码关注！&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;http://phsyg9eyi.bkt.clouddn.com/introduce2.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;
      
    
    </summary>
    
      <category term="云端笑猿" scheme="http://yoursite.com/categories/%E4%BA%91%E7%AB%AF%E7%AC%91%E7%8C%BF/"/>
    
    
      <category term="北京" scheme="http://yoursite.com/tags/%E5%8C%97%E4%BA%AC/"/>
    
      <category term="租房" scheme="http://yoursite.com/tags/%E7%A7%9F%E6%88%BF/"/>
    
  </entry>
  
  <entry>
    <title>分享一下我的面试和入职经历</title>
    <link href="http://yoursite.com/%E5%88%86%E4%BA%AB%E4%B8%80%E4%B8%8B%E6%88%91%E7%9A%84%E9%9D%A2%E8%AF%95%E5%92%8C%E5%85%A5%E8%81%8C%E7%BB%8F%E5%8E%86.html"/>
    <id>http://yoursite.com/分享一下我的面试和入职经历.html</id>
    <published>2018-10-29T07:50:45.000Z</published>
    <updated>2018-10-29T07:50:45.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>转载自本人微信公众号「intflags」，欢迎扫码关注！</p></blockquote><p><img src="http://phsyg9eyi.bkt.clouddn.com/introduce2.jpg" alt=""></p><p>各位小伙伴大家好，过去的几个月我经历了企业实训、找工作、面试、入职考核，一直没有时间维护公众号，虽然目前刚刚入职，任务很重，但是最起码有了一点空闲时间。</p><p>从今天开始，我会利用下班时间构思写作，每周至少会分享一篇文章，内容不限，但都会是我的亲身经历，或者我了解的内容，我会尽力保证文章的质量，争取对大家有所帮助。</p><p>同时查成绩的服务今后也会完全免费，我会把这个平台提供给部分有时间、可靠的同学，我和他们一起为大家服务。</p><p>回到今天的话题，怎样在面试中脱颖而出？如何从学校思维转换到职场思维？下面我会把自己面试和入职期间的经历分享出来，希望能帮助到大家！</p><p>面试是面试官在短时间内了解你的一个重要过程，所以一定要冷静的回答面试官的问题，千万不要紧张，毕竟工作是一个双向选择的过程，如果面试官看不上你，那你还非要去吗？必须得有自信。此外适当的突出你自己的个性，多讲一些属于你自己的故事，因为他们在面试过程中听了太多套话，早已麻木，如果你把自己一些有趣、又能体现自己某一方面能力的经历分享出来，则会让面试官眼前一亮，加深对你的印象，面试成功的几率会很大。</p><p>比如我在面试过程中就分享了我如何从零开始运营一个公众号，如何创业，如何去拉赞助等等，这些经历能够充分的体现我的思维方式、执行力和沟通交流的能力。不只是这些，任何能体现你自己的故事都可以分享，比如在你在学生会组织筹办活动、在社团学会了某个技能、组织了一场老乡聚会等等，这些都是你面试的加分点，能够大大提高你的面试成功率。</p><p>除此之外你的专业知识也必须熟练掌握，同时精心准备一份能让面试官眼前一亮的简历。简历要做到繁简合理，千万不要长篇大论，还要突出自身优势，把大学期间的职务、获奖经历、语言能力（四六级）等罗列上去，这也是加分项。关于简历的撰写，我有时间会单独写一篇文章，同时我会把自己制作简历时从网上收藏的一些精美简历模版、在线简历制作平台分享给大家。</p><p>最后就是着装方面了，穿着打扮一定要合理，尽量穿的正式一点，这会让面试官觉得你很专业，也很看重这次面试，但千万不要表现太过，尤其女同学不要化太浓的妆，不然适得其反。</p><p>如果你能通过面试，那么恭喜你，你已经成为一个准职场人了，如果你是实习生的话，刚到公司以后都会有一个考核，你的领导会给你分配一位有经验的员工作为导师，让你快速熟悉公司产品和业务，然后给你安排任务，如果你能按时完成且没有太大的错误，那么基本上就会通过考核，通过考核以后就会正式给你发放Offer，然后签定实习合同。<br><img src="http://phsyg9eyi.bkt.clouddn.com/%E5%88%86%E4%BA%AB%E4%B8%80%E4%B8%8B%E6%88%91%E9%9D%A2%E8%AF%95%E5%92%8C%E5%85%A5%E8%81%8C%E7%9A%84%E4%BA%B2%E8%BA%AB%E7%BB%8F%E5%8E%8602.jpg" alt="Offer"></p><p>其实在工作中领导不光会关注你的技术和业务能力，有些非技术方面的能力也很重要，比如为人处事、做事是否踏实、解决问题的能力等，如果让我说这两个层面哪个重要的话，我个人觉得是第二个。</p><p>因为技术层面的东西可以通过学习来弥补和提高的，好的技术确实可以给公司带来价值，但是如果没有团队合作意识、不善于表达自己的想法、没有责任心等等这些非技术层面的东西，也还是不行，那你这辈子也只能做最底层的职员，而这些非技术层面的东西往往却非常关键。</p><p>中国人常常说“枪打出头鸟”，但我个人认为在合适的情况下，要主动去当这个“出头鸟”，这里的出头可不是出风头的意思，而是克服自己心里面的恐惧，勇敢表达出自己的想法。其实大部分人都不敢，如果你能做到那么你就胜了第一步，也是最重要的一步。所以，不光要做一个有技术的人，还要做一个有思想、敢表达自己想法的人。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;转载自本人微信公众号「intflags」，欢迎扫码关注！&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;http://phsyg9eyi.bkt.clouddn.com/introduce2.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;
      
    
    </summary>
    
      <category term="云端笑猿" scheme="http://yoursite.com/categories/%E4%BA%91%E7%AB%AF%E7%AC%91%E7%8C%BF/"/>
    
    
      <category term="北京" scheme="http://yoursite.com/tags/%E5%8C%97%E4%BA%AC/"/>
    
      <category term="面试" scheme="http://yoursite.com/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="入职" scheme="http://yoursite.com/tags/%E5%85%A5%E8%81%8C/"/>
    
  </entry>
  
</feed>
